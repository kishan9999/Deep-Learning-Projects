{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krish\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Krish\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Krish\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Gujrat_company.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166088</td>\n",
       "      <td>137066</td>\n",
       "      <td>473515</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>193764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164221</td>\n",
       "      <td>151682</td>\n",
       "      <td>444422</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>192874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154825</td>\n",
       "      <td>101988</td>\n",
       "      <td>409251</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>191413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144984</td>\n",
       "      <td>119498</td>\n",
       "      <td>386151</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>184043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142519</td>\n",
       "      <td>92208</td>\n",
       "      <td>366170</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>167144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131942</td>\n",
       "      <td>100146</td>\n",
       "      <td>365747</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>158459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135336</td>\n",
       "      <td>148073</td>\n",
       "      <td>128445</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>157582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>131104</td>\n",
       "      <td>146268</td>\n",
       "      <td>326036</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>157289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120624</td>\n",
       "      <td>150191</td>\n",
       "      <td>314293</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>152863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123421</td>\n",
       "      <td>108937</td>\n",
       "      <td>307104</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>150693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>102225</td>\n",
       "      <td>111280</td>\n",
       "      <td>230666</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>147102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101241</td>\n",
       "      <td>92129</td>\n",
       "      <td>251598</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>144759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>94132</td>\n",
       "      <td>127942</td>\n",
       "      <td>252182</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>142902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>92833</td>\n",
       "      <td>135650</td>\n",
       "      <td>254301</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>135620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>121142</td>\n",
       "      <td>156572</td>\n",
       "      <td>257267</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>133676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114899</td>\n",
       "      <td>122697</td>\n",
       "      <td>263570</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>130208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78165</td>\n",
       "      <td>122100</td>\n",
       "      <td>265992</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>127296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>95171</td>\n",
       "      <td>145826</td>\n",
       "      <td>285162</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>125761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>92274</td>\n",
       "      <td>114650</td>\n",
       "      <td>295120</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>124641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86980</td>\n",
       "      <td>154274</td>\n",
       "      <td>0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76302</td>\n",
       "      <td>114054</td>\n",
       "      <td>299501</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>118557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>79091</td>\n",
       "      <td>154417</td>\n",
       "      <td>301627</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>111966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74601</td>\n",
       "      <td>123075</td>\n",
       "      <td>305008</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>110563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>68101</td>\n",
       "      <td>106529</td>\n",
       "      <td>305586</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>109728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77361</td>\n",
       "      <td>99668</td>\n",
       "      <td>140740</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>109034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64877</td>\n",
       "      <td>140427</td>\n",
       "      <td>139008</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>108165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75382</td>\n",
       "      <td>144998</td>\n",
       "      <td>134403</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>106090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72369</td>\n",
       "      <td>129077</td>\n",
       "      <td>353495</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>105642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66242</td>\n",
       "      <td>182987</td>\n",
       "      <td>119317</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>103287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65806</td>\n",
       "      <td>154314</td>\n",
       "      <td>108172</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>101363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>62212</td>\n",
       "      <td>116037</td>\n",
       "      <td>91970</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61289</td>\n",
       "      <td>153138</td>\n",
       "      <td>88291</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>98434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63911</td>\n",
       "      <td>129814</td>\n",
       "      <td>46183</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>97685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55769</td>\n",
       "      <td>103437</td>\n",
       "      <td>215182</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>97164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46480</td>\n",
       "      <td>157740</td>\n",
       "      <td>212606</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>96797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46087</td>\n",
       "      <td>85789</td>\n",
       "      <td>206619</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>97311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28902</td>\n",
       "      <td>127907</td>\n",
       "      <td>202816</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>91468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44309</td>\n",
       "      <td>51314</td>\n",
       "      <td>197133</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>90178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20388</td>\n",
       "      <td>66266</td>\n",
       "      <td>185364</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>81572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38605</td>\n",
       "      <td>83210</td>\n",
       "      <td>175654</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>81232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28797</td>\n",
       "      <td>119599</td>\n",
       "      <td>173187</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>78954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>28015</td>\n",
       "      <td>85495</td>\n",
       "      <td>165658</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>78045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23653</td>\n",
       "      <td>96801</td>\n",
       "      <td>148772</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>71747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15656</td>\n",
       "      <td>127558</td>\n",
       "      <td>35869</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>70420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22359</td>\n",
       "      <td>156023</td>\n",
       "      <td>28484</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>65398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1004</td>\n",
       "      <td>125278</td>\n",
       "      <td>1908</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>65168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1326</td>\n",
       "      <td>116956</td>\n",
       "      <td>298874</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>49528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>136264</td>\n",
       "      <td>0</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>42854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>545</td>\n",
       "      <td>51974</td>\n",
       "      <td>0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>35955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>117699</td>\n",
       "      <td>45190</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>14797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend      State  Profit\n",
       "0      166088          137066           473515     Mumbai  193764\n",
       "1      164221          151682           444422   Banglore  192874\n",
       "2      154825          101988           409251  Ahmedabad  191413\n",
       "3      144984          119498           386151     Mumbai  184043\n",
       "4      142519           92208           366170  Ahmedabad  167144\n",
       "5      131942          100146           365747     Mumbai  158459\n",
       "6      135336          148073           128445   Banglore  157582\n",
       "7      131104          146268           326036  Ahmedabad  157289\n",
       "8      120624          150191           314293     Mumbai  152863\n",
       "9      123421          108937           307104   Banglore  150693\n",
       "10     102225          111280           230666  Ahmedabad  147102\n",
       "11     101241           92129           251598   Banglore  144759\n",
       "12      94132          127942           252182  Ahmedabad  142902\n",
       "13      92833          135650           254301   Banglore  135620\n",
       "14     121142          156572           257267  Ahmedabad  133676\n",
       "15     114899          122697           263570     Mumbai  130208\n",
       "16      78165          122100           265992   Banglore  127296\n",
       "17      95171          145826           285162     Mumbai  125761\n",
       "18      92274          114650           295120  Ahmedabad  124641\n",
       "19      86980          154274                0     Mumbai  123600\n",
       "20      76302          114054           299501   Banglore  118557\n",
       "21      79091          154417           301627     Mumbai  111966\n",
       "22      74601          123075           305008  Ahmedabad  110563\n",
       "23      68101          106529           305586  Ahmedabad  109728\n",
       "24      77361           99668           140740     Mumbai  109034\n",
       "25      64877          140427           139008   Banglore  108165\n",
       "26      75382          144998           134403  Ahmedabad  106090\n",
       "27      72369          129077           353495     Mumbai  105642\n",
       "28      66242          182987           119317  Ahmedabad  103287\n",
       "29      65806          154314           108172     Mumbai  101363\n",
       "30      62212          116037            91970  Ahmedabad  100004\n",
       "31      61289          153138            88291     Mumbai   98434\n",
       "32      63911          129814            46183   Banglore   97685\n",
       "33      55769          103437           215182  Ahmedabad   97164\n",
       "34      46480          157740           212606   Banglore   96797\n",
       "35      46087           85789           206619     Mumbai   97311\n",
       "36      28902          127907           202816  Ahmedabad   91468\n",
       "37      44309           51314           197133   Banglore   90178\n",
       "38      20388           66266           185364     Mumbai   81572\n",
       "39      38605           83210           175654   Banglore   81232\n",
       "40      28797          119599           173187   Banglore   78954\n",
       "41      28015           85495           165658  Ahmedabad   78045\n",
       "42      23653           96801           148772   Banglore   71747\n",
       "43      15656          127558            35869     Mumbai   70420\n",
       "44      22359          156023            28484   Banglore   65398\n",
       "45       1004          125278             1908     Mumbai   65168\n",
       "46       1326          116956           298874  Ahmedabad   49528\n",
       "47          0          136264                0   Banglore   42854\n",
       "48        545           51974                0     Mumbai   35955\n",
       "49          0          117699            45190   Banglore   14797"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = dataset.iloc[:,0:4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[166088, 137066, 473515, 'Mumbai'],\n",
       "       [164221, 151682, 444422, 'Banglore'],\n",
       "       [154825, 101988, 409251, 'Ahmedabad'],\n",
       "       [144984, 119498, 386151, 'Mumbai'],\n",
       "       [142519, 92208, 366170, 'Ahmedabad'],\n",
       "       [131942, 100146, 365747, 'Mumbai'],\n",
       "       [135336, 148073, 128445, 'Banglore'],\n",
       "       [131104, 146268, 326036, 'Ahmedabad'],\n",
       "       [120624, 150191, 314293, 'Mumbai'],\n",
       "       [123421, 108937, 307104, 'Banglore']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([193764, 192874, 191413, 184043, 167144, 158459, 157582, 157289,\n",
       "       152863, 150693], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding for the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder =  OneHotEncoder()\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder',encoder, [3])], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 166088, 137066, 473515],\n",
       "       [0.0, 1.0, 0.0, 164221, 151682, 444422],\n",
       "       [1.0, 0.0, 0.0, 154825, 101988, 409251],\n",
       "       [0.0, 0.0, 1.0, 144984, 119498, 386151],\n",
       "       [1.0, 0.0, 0.0, 142519, 92208, 366170],\n",
       "       [0.0, 0.0, 1.0, 131942, 100146, 365747],\n",
       "       [0.0, 1.0, 0.0, 135336, 148073, 128445],\n",
       "       [1.0, 0.0, 0.0, 131104, 146268, 326036],\n",
       "       [0.0, 0.0, 1.0, 120624, 150191, 314293],\n",
       "       [0.0, 1.0, 0.0, 123421, 108937, 307104]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.68599434 -0.71774056  1.39326109  2.0140025   0.54366019  2.15057805]\n",
      " [-0.68599434  1.39326109 -0.71774056  1.9731388   1.06900519  1.91126466]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.76748518 -0.71715343  1.62195482]\n",
      " [-0.68599434 -0.71774056  1.39326109  1.55209169 -0.08778897  1.43193869]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.49813935 -1.06867739  1.26757885]\n",
      " [-0.68599434 -0.71774056  1.39326109  1.26663676 -0.7833607   1.26409933]\n",
      " [-0.68599434  1.39326109 -0.71774056  1.34092245  0.93928638 -0.687901  ]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.24829515  0.874409    0.93744433]\n",
      " [-0.68599434 -0.71774056  1.39326109  1.01891563  1.01541396  0.84084868]\n",
      " [-0.68599434  1.39326109 -0.71774056  1.08013457 -0.46738452  0.78171336]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.45773797 -0.71774056 -0.71774056 -0.400589   -0.66507182  0.02558078]\n",
      " [-0.68599434 -0.71774056  1.39326109 -0.61250241 -1.29939643 -0.0448568 ]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  0.02868776  0.82876121 -0.63889164]\n",
      " [-0.68599434  1.39326109 -0.71774056 -0.60390067  1.28674876  0.0043911 ]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  0.39840902 -0.26204134  0.6831353 ]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.24829515  0.874409    0.93744433]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.03025328  1.24476716  0.37176384]\n",
      " [-0.68599434 -0.71774056  1.39326109 -1.59925019  0.1199624  -1.72876988]\n",
      " [-0.68599434 -0.71774056  1.39326109 -1.60929649 -2.51481386 -1.74446471]\n",
      " [-0.68599434 -0.71774056  1.39326109 -0.18090558  1.16360754 -0.85466277]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=6, activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(loss='mae', optimizer='adam') # metrics=['accuracy','mse', 'mae', 'mape', 'cosine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,025\n",
      "Trainable params: 1,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 - 0s - loss: 110070.8281 - val_loss: 122795.8984\n",
      "Epoch 2/1000\n",
      "2/2 - 0s - loss: 110070.7734 - val_loss: 122795.8281\n",
      "Epoch 3/1000\n",
      "2/2 - 0s - loss: 110070.7031 - val_loss: 122795.7656\n",
      "Epoch 4/1000\n",
      "2/2 - 0s - loss: 110070.6250 - val_loss: 122795.7109\n",
      "Epoch 5/1000\n",
      "2/2 - 0s - loss: 110070.5625 - val_loss: 122795.6406\n",
      "Epoch 6/1000\n",
      "2/2 - 0s - loss: 110070.5000 - val_loss: 122795.5859\n",
      "Epoch 7/1000\n",
      "2/2 - 0s - loss: 110070.4375 - val_loss: 122795.5234\n",
      "Epoch 8/1000\n",
      "2/2 - 0s - loss: 110070.3750 - val_loss: 122795.4531\n",
      "Epoch 9/1000\n",
      "2/2 - 0s - loss: 110070.3125 - val_loss: 122795.3906\n",
      "Epoch 10/1000\n",
      "2/2 - 0s - loss: 110070.2500 - val_loss: 122795.3359\n",
      "Epoch 11/1000\n",
      "2/2 - 0s - loss: 110070.1719 - val_loss: 122795.2734\n",
      "Epoch 12/1000\n",
      "2/2 - 0s - loss: 110070.1094 - val_loss: 122795.2109\n",
      "Epoch 13/1000\n",
      "2/2 - 0s - loss: 110070.0469 - val_loss: 122795.1484\n",
      "Epoch 14/1000\n",
      "2/2 - 0s - loss: 110069.9844 - val_loss: 122795.0859\n",
      "Epoch 15/1000\n",
      "2/2 - 0s - loss: 110069.9219 - val_loss: 122795.0234\n",
      "Epoch 16/1000\n",
      "2/2 - 0s - loss: 110069.8516 - val_loss: 122794.9609\n",
      "Epoch 17/1000\n",
      "2/2 - 0s - loss: 110069.7891 - val_loss: 122794.8984\n",
      "Epoch 18/1000\n",
      "2/2 - 0s - loss: 110069.7109 - val_loss: 122794.8359\n",
      "Epoch 19/1000\n",
      "2/2 - 0s - loss: 110069.6406 - val_loss: 122794.7734\n",
      "Epoch 20/1000\n",
      "2/2 - 0s - loss: 110069.5781 - val_loss: 122794.7031\n",
      "Epoch 21/1000\n",
      "2/2 - 0s - loss: 110069.5000 - val_loss: 122794.6406\n",
      "Epoch 22/1000\n",
      "2/2 - 0s - loss: 110069.4375 - val_loss: 122794.5781\n",
      "Epoch 23/1000\n",
      "2/2 - 0s - loss: 110069.3594 - val_loss: 122794.5156\n",
      "Epoch 24/1000\n",
      "2/2 - 0s - loss: 110069.2969 - val_loss: 122794.4531\n",
      "Epoch 25/1000\n",
      "2/2 - 0s - loss: 110069.2266 - val_loss: 122794.3906\n",
      "Epoch 26/1000\n",
      "2/2 - 0s - loss: 110069.1484 - val_loss: 122794.3281\n",
      "Epoch 27/1000\n",
      "2/2 - 0s - loss: 110069.0625 - val_loss: 122794.2656\n",
      "Epoch 28/1000\n",
      "2/2 - 0s - loss: 110069.0000 - val_loss: 122794.1875\n",
      "Epoch 29/1000\n",
      "2/2 - 0s - loss: 110068.9141 - val_loss: 122794.1250\n",
      "Epoch 30/1000\n",
      "2/2 - 0s - loss: 110068.8359 - val_loss: 122794.0625\n",
      "Epoch 31/1000\n",
      "2/2 - 0s - loss: 110068.7500 - val_loss: 122793.9844\n",
      "Epoch 32/1000\n",
      "2/2 - 0s - loss: 110068.6719 - val_loss: 122793.9219\n",
      "Epoch 33/1000\n",
      "2/2 - 0s - loss: 110068.5859 - val_loss: 122793.8516\n",
      "Epoch 34/1000\n",
      "2/2 - 0s - loss: 110068.5000 - val_loss: 122793.7891\n",
      "Epoch 35/1000\n",
      "2/2 - 0s - loss: 110068.4219 - val_loss: 122793.7109\n",
      "Epoch 36/1000\n",
      "2/2 - 0s - loss: 110068.3359 - val_loss: 122793.6406\n",
      "Epoch 37/1000\n",
      "2/2 - 0s - loss: 110068.2500 - val_loss: 122793.5781\n",
      "Epoch 38/1000\n",
      "2/2 - 0s - loss: 110068.1484 - val_loss: 122793.5000\n",
      "Epoch 39/1000\n",
      "2/2 - 0s - loss: 110068.0625 - val_loss: 122793.4219\n",
      "Epoch 40/1000\n",
      "2/2 - 0s - loss: 110067.9609 - val_loss: 122793.3516\n",
      "Epoch 41/1000\n",
      "2/2 - 0s - loss: 110067.8750 - val_loss: 122793.2734\n",
      "Epoch 42/1000\n",
      "2/2 - 0s - loss: 110067.7734 - val_loss: 122793.2031\n",
      "Epoch 43/1000\n",
      "2/2 - 0s - loss: 110067.6719 - val_loss: 122793.1250\n",
      "Epoch 44/1000\n",
      "2/2 - 0s - loss: 110067.5625 - val_loss: 122793.0391\n",
      "Epoch 45/1000\n",
      "2/2 - 0s - loss: 110067.4609 - val_loss: 122792.9531\n",
      "Epoch 46/1000\n",
      "2/2 - 0s - loss: 110067.3594 - val_loss: 122792.8750\n",
      "Epoch 47/1000\n",
      "2/2 - 0s - loss: 110067.2500 - val_loss: 122792.7891\n",
      "Epoch 48/1000\n",
      "2/2 - 0s - loss: 110067.1406 - val_loss: 122792.7109\n",
      "Epoch 49/1000\n",
      "2/2 - 0s - loss: 110067.0234 - val_loss: 122792.6250\n",
      "Epoch 50/1000\n",
      "2/2 - 0s - loss: 110066.9141 - val_loss: 122792.5469\n",
      "Epoch 51/1000\n",
      "2/2 - 0s - loss: 110066.7969 - val_loss: 122792.4531\n",
      "Epoch 52/1000\n",
      "2/2 - 0s - loss: 110066.6719 - val_loss: 122792.3516\n",
      "Epoch 53/1000\n",
      "2/2 - 0s - loss: 110066.5625 - val_loss: 122792.2656\n",
      "Epoch 54/1000\n",
      "2/2 - 0s - loss: 110066.4219 - val_loss: 122792.1641\n",
      "Epoch 55/1000\n",
      "2/2 - 0s - loss: 110066.3125 - val_loss: 122792.0781\n",
      "Epoch 56/1000\n",
      "2/2 - 0s - loss: 110066.2031 - val_loss: 122791.9766\n",
      "Epoch 57/1000\n",
      "2/2 - 0s - loss: 110066.0781 - val_loss: 122791.8594\n",
      "Epoch 58/1000\n",
      "2/2 - 0s - loss: 110065.9219 - val_loss: 122791.7656\n",
      "Epoch 59/1000\n",
      "2/2 - 0s - loss: 110065.7969 - val_loss: 122791.6484\n",
      "Epoch 60/1000\n",
      "2/2 - 0s - loss: 110065.6719 - val_loss: 122791.5469\n",
      "Epoch 61/1000\n",
      "2/2 - 0s - loss: 110065.5391 - val_loss: 122791.4531\n",
      "Epoch 62/1000\n",
      "2/2 - 0s - loss: 110065.3906 - val_loss: 122791.3359\n",
      "Epoch 63/1000\n",
      "2/2 - 0s - loss: 110065.2500 - val_loss: 122791.2266\n",
      "Epoch 64/1000\n",
      "2/2 - 0s - loss: 110065.1016 - val_loss: 122791.1016\n",
      "Epoch 65/1000\n",
      "2/2 - 0s - loss: 110064.9531 - val_loss: 122791.0000\n",
      "Epoch 66/1000\n",
      "2/2 - 0s - loss: 110064.7969 - val_loss: 122790.8906\n",
      "Epoch 67/1000\n",
      "2/2 - 0s - loss: 110064.6406 - val_loss: 122790.7734\n",
      "Epoch 68/1000\n",
      "2/2 - 0s - loss: 110064.5000 - val_loss: 122790.6484\n",
      "Epoch 69/1000\n",
      "2/2 - 0s - loss: 110064.3359 - val_loss: 122790.5234\n",
      "Epoch 70/1000\n",
      "2/2 - 0s - loss: 110064.1719 - val_loss: 122790.3906\n",
      "Epoch 71/1000\n",
      "2/2 - 0s - loss: 110064.0000 - val_loss: 122790.2656\n",
      "Epoch 72/1000\n",
      "2/2 - 0s - loss: 110063.8359 - val_loss: 122790.1250\n",
      "Epoch 73/1000\n",
      "2/2 - 0s - loss: 110063.6641 - val_loss: 122790.0000\n",
      "Epoch 74/1000\n",
      "2/2 - 0s - loss: 110063.5000 - val_loss: 122789.8594\n",
      "Epoch 75/1000\n",
      "2/2 - 0s - loss: 110063.3281 - val_loss: 122789.7344\n",
      "Epoch 76/1000\n",
      "2/2 - 0s - loss: 110063.1484 - val_loss: 122789.5859\n",
      "Epoch 77/1000\n",
      "2/2 - 0s - loss: 110062.9609 - val_loss: 122789.4531\n",
      "Epoch 78/1000\n",
      "2/2 - 0s - loss: 110062.7891 - val_loss: 122789.2969\n",
      "Epoch 79/1000\n",
      "2/2 - 0s - loss: 110062.6016 - val_loss: 122789.1641\n",
      "Epoch 80/1000\n",
      "2/2 - 0s - loss: 110062.3984 - val_loss: 122789.0156\n",
      "Epoch 81/1000\n",
      "2/2 - 0s - loss: 110062.2109 - val_loss: 122788.8594\n",
      "Epoch 82/1000\n",
      "2/2 - 0s - loss: 110062.0156 - val_loss: 122788.7031\n",
      "Epoch 83/1000\n",
      "2/2 - 0s - loss: 110061.8281 - val_loss: 122788.5469\n",
      "Epoch 84/1000\n",
      "2/2 - 0s - loss: 110061.6250 - val_loss: 122788.3750\n",
      "Epoch 85/1000\n",
      "2/2 - 0s - loss: 110061.4141 - val_loss: 122788.2266\n",
      "Epoch 86/1000\n",
      "2/2 - 0s - loss: 110061.2031 - val_loss: 122788.0469\n",
      "Epoch 87/1000\n",
      "2/2 - 0s - loss: 110061.0000 - val_loss: 122787.8984\n",
      "Epoch 88/1000\n",
      "2/2 - 0s - loss: 110060.7891 - val_loss: 122787.7266\n",
      "Epoch 89/1000\n",
      "2/2 - 0s - loss: 110060.5625 - val_loss: 122787.5625\n",
      "Epoch 90/1000\n",
      "2/2 - 0s - loss: 110060.3516 - val_loss: 122787.3984\n",
      "Epoch 91/1000\n",
      "2/2 - 0s - loss: 110060.1094 - val_loss: 122787.2266\n",
      "Epoch 92/1000\n",
      "2/2 - 0s - loss: 110059.8906 - val_loss: 122787.0469\n",
      "Epoch 93/1000\n",
      "2/2 - 0s - loss: 110059.6484 - val_loss: 122786.8906\n",
      "Epoch 94/1000\n",
      "2/2 - 0s - loss: 110059.4219 - val_loss: 122786.7031\n",
      "Epoch 95/1000\n",
      "2/2 - 0s - loss: 110059.1719 - val_loss: 122786.5391\n",
      "Epoch 96/1000\n",
      "2/2 - 0s - loss: 110058.9375 - val_loss: 122786.3516\n",
      "Epoch 97/1000\n",
      "2/2 - 0s - loss: 110058.6875 - val_loss: 122786.1719\n",
      "Epoch 98/1000\n",
      "2/2 - 0s - loss: 110058.4375 - val_loss: 122786.0000\n",
      "Epoch 99/1000\n",
      "2/2 - 0s - loss: 110058.1875 - val_loss: 122785.7969\n",
      "Epoch 100/1000\n",
      "2/2 - 0s - loss: 110057.9219 - val_loss: 122785.6250\n",
      "Epoch 101/1000\n",
      "2/2 - 0s - loss: 110057.6719 - val_loss: 122785.4219\n",
      "Epoch 102/1000\n",
      "2/2 - 0s - loss: 110057.4141 - val_loss: 122785.2266\n",
      "Epoch 103/1000\n",
      "2/2 - 0s - loss: 110057.1484 - val_loss: 122785.0234\n",
      "Epoch 104/1000\n",
      "2/2 - 0s - loss: 110056.8750 - val_loss: 122784.8125\n",
      "Epoch 105/1000\n",
      "2/2 - 0s - loss: 110056.6094 - val_loss: 122784.6016\n",
      "Epoch 106/1000\n",
      "2/2 - 0s - loss: 110056.3516 - val_loss: 122784.3984\n",
      "Epoch 107/1000\n",
      "2/2 - 0s - loss: 110056.0469 - val_loss: 122784.1875\n",
      "Epoch 108/1000\n",
      "2/2 - 0s - loss: 110055.7734 - val_loss: 122783.9766\n",
      "Epoch 109/1000\n",
      "2/2 - 0s - loss: 110055.4844 - val_loss: 122783.7656\n",
      "Epoch 110/1000\n",
      "2/2 - 0s - loss: 110055.2031 - val_loss: 122783.5469\n",
      "Epoch 111/1000\n",
      "2/2 - 0s - loss: 110054.9141 - val_loss: 122783.3359\n",
      "Epoch 112/1000\n",
      "2/2 - 0s - loss: 110054.6250 - val_loss: 122783.1250\n",
      "Epoch 113/1000\n",
      "2/2 - 0s - loss: 110054.3125 - val_loss: 122782.8906\n",
      "Epoch 114/1000\n",
      "2/2 - 0s - loss: 110054.0156 - val_loss: 122782.6719\n",
      "Epoch 115/1000\n",
      "2/2 - 0s - loss: 110053.7031 - val_loss: 122782.4531\n",
      "Epoch 116/1000\n",
      "2/2 - 0s - loss: 110053.3984 - val_loss: 122782.2109\n",
      "Epoch 117/1000\n",
      "2/2 - 0s - loss: 110053.0859 - val_loss: 122781.9844\n",
      "Epoch 118/1000\n",
      "2/2 - 0s - loss: 110052.7656 - val_loss: 122781.7500\n",
      "Epoch 119/1000\n",
      "2/2 - 0s - loss: 110052.4531 - val_loss: 122781.5156\n",
      "Epoch 120/1000\n",
      "2/2 - 0s - loss: 110052.1250 - val_loss: 122781.2891\n",
      "Epoch 121/1000\n",
      "2/2 - 0s - loss: 110051.7969 - val_loss: 122781.0469\n",
      "Epoch 122/1000\n",
      "2/2 - 0s - loss: 110051.4531 - val_loss: 122780.8125\n",
      "Epoch 123/1000\n",
      "2/2 - 0s - loss: 110051.1094 - val_loss: 122780.5781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/1000\n",
      "2/2 - 0s - loss: 110050.7734 - val_loss: 122780.3516\n",
      "Epoch 125/1000\n",
      "2/2 - 0s - loss: 110050.4141 - val_loss: 122780.1094\n",
      "Epoch 126/1000\n",
      "2/2 - 0s - loss: 110050.0781 - val_loss: 122779.8750\n",
      "Epoch 127/1000\n",
      "2/2 - 0s - loss: 110049.7031 - val_loss: 122779.6250\n",
      "Epoch 128/1000\n",
      "2/2 - 0s - loss: 110049.3516 - val_loss: 122779.3984\n",
      "Epoch 129/1000\n",
      "2/2 - 0s - loss: 110048.9766 - val_loss: 122779.1484\n",
      "Epoch 130/1000\n",
      "2/2 - 0s - loss: 110048.6250 - val_loss: 122778.8906\n",
      "Epoch 131/1000\n",
      "2/2 - 0s - loss: 110048.2344 - val_loss: 122778.6250\n",
      "Epoch 132/1000\n",
      "2/2 - 0s - loss: 110047.8750 - val_loss: 122778.3750\n",
      "Epoch 133/1000\n",
      "2/2 - 0s - loss: 110047.5000 - val_loss: 122778.1250\n",
      "Epoch 134/1000\n",
      "2/2 - 0s - loss: 110047.1094 - val_loss: 122777.8516\n",
      "Epoch 135/1000\n",
      "2/2 - 0s - loss: 110046.7344 - val_loss: 122777.6016\n",
      "Epoch 136/1000\n",
      "2/2 - 0s - loss: 110046.3516 - val_loss: 122777.3281\n",
      "Epoch 137/1000\n",
      "2/2 - 0s - loss: 110045.9609 - val_loss: 122777.0469\n",
      "Epoch 138/1000\n",
      "2/2 - 0s - loss: 110045.5859 - val_loss: 122776.7656\n",
      "Epoch 139/1000\n",
      "2/2 - 0s - loss: 110045.1875 - val_loss: 122776.4766\n",
      "Epoch 140/1000\n",
      "2/2 - 0s - loss: 110044.8125 - val_loss: 122776.2031\n",
      "Epoch 141/1000\n",
      "2/2 - 0s - loss: 110044.4219 - val_loss: 122775.8906\n",
      "Epoch 142/1000\n",
      "2/2 - 0s - loss: 110044.0234 - val_loss: 122775.6016\n",
      "Epoch 143/1000\n",
      "2/2 - 0s - loss: 110043.6250 - val_loss: 122775.2969\n",
      "Epoch 144/1000\n",
      "2/2 - 0s - loss: 110043.2266 - val_loss: 122774.9844\n",
      "Epoch 145/1000\n",
      "2/2 - 0s - loss: 110042.8125 - val_loss: 122774.6719\n",
      "Epoch 146/1000\n",
      "2/2 - 0s - loss: 110042.4141 - val_loss: 122774.3594\n",
      "Epoch 147/1000\n",
      "2/2 - 0s - loss: 110041.9844 - val_loss: 122774.0391\n",
      "Epoch 148/1000\n",
      "2/2 - 0s - loss: 110041.5859 - val_loss: 122773.7266\n",
      "Epoch 149/1000\n",
      "2/2 - 0s - loss: 110041.1719 - val_loss: 122773.3906\n",
      "Epoch 150/1000\n",
      "2/2 - 0s - loss: 110040.7500 - val_loss: 122773.0469\n",
      "Epoch 151/1000\n",
      "2/2 - 0s - loss: 110040.3359 - val_loss: 122772.7344\n",
      "Epoch 152/1000\n",
      "2/2 - 0s - loss: 110039.8984 - val_loss: 122772.4141\n",
      "Epoch 153/1000\n",
      "2/2 - 0s - loss: 110039.4609 - val_loss: 122772.1016\n",
      "Epoch 154/1000\n",
      "2/2 - 0s - loss: 110039.0234 - val_loss: 122771.7734\n",
      "Epoch 155/1000\n",
      "2/2 - 0s - loss: 110038.5859 - val_loss: 122771.4609\n",
      "Epoch 156/1000\n",
      "2/2 - 0s - loss: 110038.1406 - val_loss: 122771.1406\n",
      "Epoch 157/1000\n",
      "2/2 - 0s - loss: 110037.6875 - val_loss: 122770.8125\n",
      "Epoch 158/1000\n",
      "2/2 - 0s - loss: 110037.2266 - val_loss: 122770.4766\n",
      "Epoch 159/1000\n",
      "2/2 - 0s - loss: 110036.7734 - val_loss: 122770.1484\n",
      "Epoch 160/1000\n",
      "2/2 - 0s - loss: 110036.2969 - val_loss: 122769.8281\n",
      "Epoch 161/1000\n",
      "2/2 - 0s - loss: 110035.8281 - val_loss: 122769.5000\n",
      "Epoch 162/1000\n",
      "2/2 - 0s - loss: 110035.3516 - val_loss: 122769.1719\n",
      "Epoch 163/1000\n",
      "2/2 - 0s - loss: 110034.8750 - val_loss: 122768.8516\n",
      "Epoch 164/1000\n",
      "2/2 - 0s - loss: 110034.3984 - val_loss: 122768.5234\n",
      "Epoch 165/1000\n",
      "2/2 - 0s - loss: 110033.8984 - val_loss: 122768.1875\n",
      "Epoch 166/1000\n",
      "2/2 - 0s - loss: 110033.4141 - val_loss: 122767.8359\n",
      "Epoch 167/1000\n",
      "2/2 - 0s - loss: 110032.9375 - val_loss: 122767.5000\n",
      "Epoch 168/1000\n",
      "2/2 - 0s - loss: 110032.4375 - val_loss: 122767.1484\n",
      "Epoch 169/1000\n",
      "2/2 - 0s - loss: 110031.9531 - val_loss: 122766.7969\n",
      "Epoch 170/1000\n",
      "2/2 - 0s - loss: 110031.4531 - val_loss: 122766.4531\n",
      "Epoch 171/1000\n",
      "2/2 - 0s - loss: 110030.9531 - val_loss: 122766.1016\n",
      "Epoch 172/1000\n",
      "2/2 - 0s - loss: 110030.4375 - val_loss: 122765.7500\n",
      "Epoch 173/1000\n",
      "2/2 - 0s - loss: 110029.9531 - val_loss: 122765.3984\n",
      "Epoch 174/1000\n",
      "2/2 - 0s - loss: 110029.4141 - val_loss: 122765.0469\n",
      "Epoch 175/1000\n",
      "2/2 - 0s - loss: 110028.8984 - val_loss: 122764.7031\n",
      "Epoch 176/1000\n",
      "2/2 - 0s - loss: 110028.3906 - val_loss: 122764.3281\n",
      "Epoch 177/1000\n",
      "2/2 - 0s - loss: 110027.8750 - val_loss: 122763.9609\n",
      "Epoch 178/1000\n",
      "2/2 - 0s - loss: 110027.3359 - val_loss: 122763.5859\n",
      "Epoch 179/1000\n",
      "2/2 - 0s - loss: 110026.8281 - val_loss: 122763.2266\n",
      "Epoch 180/1000\n",
      "2/2 - 0s - loss: 110026.2969 - val_loss: 122762.8516\n",
      "Epoch 181/1000\n",
      "2/2 - 0s - loss: 110025.7734 - val_loss: 122762.4609\n",
      "Epoch 182/1000\n",
      "2/2 - 0s - loss: 110025.2344 - val_loss: 122762.0781\n",
      "Epoch 183/1000\n",
      "2/2 - 0s - loss: 110024.6719 - val_loss: 122761.7031\n",
      "Epoch 184/1000\n",
      "2/2 - 0s - loss: 110024.1484 - val_loss: 122761.3281\n",
      "Epoch 185/1000\n",
      "2/2 - 0s - loss: 110023.5859 - val_loss: 122760.9531\n",
      "Epoch 186/1000\n",
      "2/2 - 0s - loss: 110023.0469 - val_loss: 122760.5781\n",
      "Epoch 187/1000\n",
      "2/2 - 0s - loss: 110022.4766 - val_loss: 122760.2031\n",
      "Epoch 188/1000\n",
      "2/2 - 0s - loss: 110021.9141 - val_loss: 122759.8281\n",
      "Epoch 189/1000\n",
      "2/2 - 0s - loss: 110021.3359 - val_loss: 122759.4375\n",
      "Epoch 190/1000\n",
      "2/2 - 0s - loss: 110020.7734 - val_loss: 122759.0469\n",
      "Epoch 191/1000\n",
      "2/2 - 0s - loss: 110020.2031 - val_loss: 122758.6406\n",
      "Epoch 192/1000\n",
      "2/2 - 0s - loss: 110019.6250 - val_loss: 122758.2266\n",
      "Epoch 193/1000\n",
      "2/2 - 0s - loss: 110019.0469 - val_loss: 122757.7969\n",
      "Epoch 194/1000\n",
      "2/2 - 0s - loss: 110018.4766 - val_loss: 122757.3750\n",
      "Epoch 195/1000\n",
      "2/2 - 0s - loss: 110017.8984 - val_loss: 122756.9531\n",
      "Epoch 196/1000\n",
      "2/2 - 0s - loss: 110017.3281 - val_loss: 122756.5234\n",
      "Epoch 197/1000\n",
      "2/2 - 0s - loss: 110016.7344 - val_loss: 122756.1016\n",
      "Epoch 198/1000\n",
      "2/2 - 0s - loss: 110016.1406 - val_loss: 122755.6719\n",
      "Epoch 199/1000\n",
      "2/2 - 0s - loss: 110015.5469 - val_loss: 122755.2656\n",
      "Epoch 200/1000\n",
      "2/2 - 0s - loss: 110014.9375 - val_loss: 122754.8516\n",
      "Epoch 201/1000\n",
      "2/2 - 0s - loss: 110014.3125 - val_loss: 122754.4219\n",
      "Epoch 202/1000\n",
      "2/2 - 0s - loss: 110013.6875 - val_loss: 122754.0156\n",
      "Epoch 203/1000\n",
      "2/2 - 0s - loss: 110013.0859 - val_loss: 122753.6016\n",
      "Epoch 204/1000\n",
      "2/2 - 0s - loss: 110012.4375 - val_loss: 122753.1719\n",
      "Epoch 205/1000\n",
      "2/2 - 0s - loss: 110011.8281 - val_loss: 122752.7656\n",
      "Epoch 206/1000\n",
      "2/2 - 0s - loss: 110011.1875 - val_loss: 122752.3281\n",
      "Epoch 207/1000\n",
      "2/2 - 0s - loss: 110010.5625 - val_loss: 122751.8750\n",
      "Epoch 208/1000\n",
      "2/2 - 0s - loss: 110009.9219 - val_loss: 122751.4531\n",
      "Epoch 209/1000\n",
      "2/2 - 0s - loss: 110009.2969 - val_loss: 122750.9844\n",
      "Epoch 210/1000\n",
      "2/2 - 0s - loss: 110008.6484 - val_loss: 122750.5391\n",
      "Epoch 211/1000\n",
      "2/2 - 0s - loss: 110008.0234 - val_loss: 122750.0781\n",
      "Epoch 212/1000\n",
      "2/2 - 0s - loss: 110007.3906 - val_loss: 122749.6250\n",
      "Epoch 213/1000\n",
      "2/2 - 0s - loss: 110006.7500 - val_loss: 122749.1719\n",
      "Epoch 214/1000\n",
      "2/2 - 0s - loss: 110006.1016 - val_loss: 122748.7031\n",
      "Epoch 215/1000\n",
      "2/2 - 0s - loss: 110005.4531 - val_loss: 122748.2500\n",
      "Epoch 216/1000\n",
      "2/2 - 0s - loss: 110004.7969 - val_loss: 122747.7891\n",
      "Epoch 217/1000\n",
      "2/2 - 0s - loss: 110004.1250 - val_loss: 122747.3281\n",
      "Epoch 218/1000\n",
      "2/2 - 0s - loss: 110003.4531 - val_loss: 122746.8750\n",
      "Epoch 219/1000\n",
      "2/2 - 0s - loss: 110002.7891 - val_loss: 122746.4219\n",
      "Epoch 220/1000\n",
      "2/2 - 0s - loss: 110002.1094 - val_loss: 122745.9766\n",
      "Epoch 221/1000\n",
      "2/2 - 0s - loss: 110001.4219 - val_loss: 122745.5000\n",
      "Epoch 222/1000\n",
      "2/2 - 0s - loss: 110000.7266 - val_loss: 122745.0469\n",
      "Epoch 223/1000\n",
      "2/2 - 0s - loss: 110000.0469 - val_loss: 122744.5781\n",
      "Epoch 224/1000\n",
      "2/2 - 0s - loss: 109999.3516 - val_loss: 122744.1094\n",
      "Epoch 225/1000\n",
      "2/2 - 0s - loss: 109998.6719 - val_loss: 122743.6250\n",
      "Epoch 226/1000\n",
      "2/2 - 0s - loss: 109997.9766 - val_loss: 122743.1641\n",
      "Epoch 227/1000\n",
      "2/2 - 0s - loss: 109997.2734 - val_loss: 122742.6719\n",
      "Epoch 228/1000\n",
      "2/2 - 0s - loss: 109996.5781 - val_loss: 122742.2031\n",
      "Epoch 229/1000\n",
      "2/2 - 0s - loss: 109995.8906 - val_loss: 122741.7109\n",
      "Epoch 230/1000\n",
      "2/2 - 0s - loss: 109995.1641 - val_loss: 122741.2266\n",
      "Epoch 231/1000\n",
      "2/2 - 0s - loss: 109994.4844 - val_loss: 122740.7031\n",
      "Epoch 232/1000\n",
      "2/2 - 0s - loss: 109993.7656 - val_loss: 122740.2031\n",
      "Epoch 233/1000\n",
      "2/2 - 0s - loss: 109993.0625 - val_loss: 122739.7031\n",
      "Epoch 234/1000\n",
      "2/2 - 0s - loss: 109992.3516 - val_loss: 122739.2031\n",
      "Epoch 235/1000\n",
      "2/2 - 0s - loss: 109991.6406 - val_loss: 122738.6875\n",
      "Epoch 236/1000\n",
      "2/2 - 0s - loss: 109990.9375 - val_loss: 122738.1719\n",
      "Epoch 237/1000\n",
      "2/2 - 0s - loss: 109990.2031 - val_loss: 122737.6484\n",
      "Epoch 238/1000\n",
      "2/2 - 0s - loss: 109989.4766 - val_loss: 122737.1406\n",
      "Epoch 239/1000\n",
      "2/2 - 0s - loss: 109988.7656 - val_loss: 122736.6094\n",
      "Epoch 240/1000\n",
      "2/2 - 0s - loss: 109988.0391 - val_loss: 122736.0781\n",
      "Epoch 241/1000\n",
      "2/2 - 0s - loss: 109987.2969 - val_loss: 122735.5469\n",
      "Epoch 242/1000\n",
      "2/2 - 0s - loss: 109986.5469 - val_loss: 122735.0156\n",
      "Epoch 243/1000\n",
      "2/2 - 0s - loss: 109985.8281 - val_loss: 122734.4844\n",
      "Epoch 244/1000\n",
      "2/2 - 0s - loss: 109985.0781 - val_loss: 122733.9531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/1000\n",
      "2/2 - 0s - loss: 109984.3281 - val_loss: 122733.4219\n",
      "Epoch 246/1000\n",
      "2/2 - 0s - loss: 109983.5781 - val_loss: 122732.9219\n",
      "Epoch 247/1000\n",
      "2/2 - 0s - loss: 109982.7891 - val_loss: 122732.3984\n",
      "Epoch 248/1000\n",
      "2/2 - 0s - loss: 109982.0234 - val_loss: 122731.8906\n",
      "Epoch 249/1000\n",
      "2/2 - 0s - loss: 109981.2734 - val_loss: 122731.3594\n",
      "Epoch 250/1000\n",
      "2/2 - 0s - loss: 109980.4609 - val_loss: 122730.8281\n",
      "Epoch 251/1000\n",
      "2/2 - 0s - loss: 109979.6875 - val_loss: 122730.2969\n",
      "Epoch 252/1000\n",
      "2/2 - 0s - loss: 109978.9141 - val_loss: 122729.7734\n",
      "Epoch 253/1000\n",
      "2/2 - 0s - loss: 109978.1016 - val_loss: 122729.2500\n",
      "Epoch 254/1000\n",
      "2/2 - 0s - loss: 109977.3281 - val_loss: 122728.7266\n",
      "Epoch 255/1000\n",
      "2/2 - 0s - loss: 109976.5156 - val_loss: 122728.1875\n",
      "Epoch 256/1000\n",
      "2/2 - 0s - loss: 109975.7109 - val_loss: 122727.6641\n",
      "Epoch 257/1000\n",
      "2/2 - 0s - loss: 109974.9219 - val_loss: 122727.1484\n",
      "Epoch 258/1000\n",
      "2/2 - 0s - loss: 109974.1016 - val_loss: 122726.6094\n",
      "Epoch 259/1000\n",
      "2/2 - 0s - loss: 109973.2969 - val_loss: 122726.0859\n",
      "Epoch 260/1000\n",
      "2/2 - 0s - loss: 109972.4844 - val_loss: 122725.5469\n",
      "Epoch 261/1000\n",
      "2/2 - 0s - loss: 109971.6719 - val_loss: 122725.0000\n",
      "Epoch 262/1000\n",
      "2/2 - 0s - loss: 109970.8516 - val_loss: 122724.4531\n",
      "Epoch 263/1000\n",
      "2/2 - 0s - loss: 109970.0469 - val_loss: 122723.9219\n",
      "Epoch 264/1000\n",
      "2/2 - 0s - loss: 109969.2109 - val_loss: 122723.3750\n",
      "Epoch 265/1000\n",
      "2/2 - 0s - loss: 109968.3750 - val_loss: 122722.8125\n",
      "Epoch 266/1000\n",
      "2/2 - 0s - loss: 109967.5781 - val_loss: 122722.2500\n",
      "Epoch 267/1000\n",
      "2/2 - 0s - loss: 109966.7266 - val_loss: 122721.6719\n",
      "Epoch 268/1000\n",
      "2/2 - 0s - loss: 109965.9141 - val_loss: 122721.1016\n",
      "Epoch 269/1000\n",
      "2/2 - 0s - loss: 109965.0781 - val_loss: 122720.5156\n",
      "Epoch 270/1000\n",
      "2/2 - 0s - loss: 109964.2500 - val_loss: 122719.9375\n",
      "Epoch 271/1000\n",
      "2/2 - 0s - loss: 109963.4219 - val_loss: 122719.3594\n",
      "Epoch 272/1000\n",
      "2/2 - 0s - loss: 109962.5781 - val_loss: 122718.7891\n",
      "Epoch 273/1000\n",
      "2/2 - 0s - loss: 109961.7500 - val_loss: 122718.2031\n",
      "Epoch 274/1000\n",
      "2/2 - 0s - loss: 109960.8984 - val_loss: 122717.6094\n",
      "Epoch 275/1000\n",
      "2/2 - 0s - loss: 109960.0469 - val_loss: 122717.0234\n",
      "Epoch 276/1000\n",
      "2/2 - 0s - loss: 109959.2031 - val_loss: 122716.4375\n",
      "Epoch 277/1000\n",
      "2/2 - 0s - loss: 109958.3750 - val_loss: 122715.8594\n",
      "Epoch 278/1000\n",
      "2/2 - 0s - loss: 109957.4844 - val_loss: 122715.2656\n",
      "Epoch 279/1000\n",
      "2/2 - 0s - loss: 109956.6719 - val_loss: 122714.6719\n",
      "Epoch 280/1000\n",
      "2/2 - 0s - loss: 109955.8125 - val_loss: 122714.1016\n",
      "Epoch 281/1000\n",
      "2/2 - 0s - loss: 109954.9609 - val_loss: 122713.5000\n",
      "Epoch 282/1000\n",
      "2/2 - 0s - loss: 109954.1016 - val_loss: 122712.8984\n",
      "Epoch 283/1000\n",
      "2/2 - 0s - loss: 109953.2266 - val_loss: 122712.2969\n",
      "Epoch 284/1000\n",
      "2/2 - 0s - loss: 109952.3594 - val_loss: 122711.6719\n",
      "Epoch 285/1000\n",
      "2/2 - 0s - loss: 109951.5000 - val_loss: 122711.0781\n",
      "Epoch 286/1000\n",
      "2/2 - 0s - loss: 109950.6250 - val_loss: 122710.4609\n",
      "Epoch 287/1000\n",
      "2/2 - 0s - loss: 109949.7500 - val_loss: 122709.8516\n",
      "Epoch 288/1000\n",
      "2/2 - 0s - loss: 109948.8359 - val_loss: 122709.2266\n",
      "Epoch 289/1000\n",
      "2/2 - 0s - loss: 109947.9766 - val_loss: 122708.6016\n",
      "Epoch 290/1000\n",
      "2/2 - 0s - loss: 109947.0625 - val_loss: 122708.0000\n",
      "Epoch 291/1000\n",
      "2/2 - 0s - loss: 109946.1641 - val_loss: 122707.3984\n",
      "Epoch 292/1000\n",
      "2/2 - 0s - loss: 109945.2500 - val_loss: 122706.7891\n",
      "Epoch 293/1000\n",
      "2/2 - 0s - loss: 109944.3516 - val_loss: 122706.1719\n",
      "Epoch 294/1000\n",
      "2/2 - 0s - loss: 109943.4219 - val_loss: 122705.5625\n",
      "Epoch 295/1000\n",
      "2/2 - 0s - loss: 109942.5156 - val_loss: 122704.9531\n",
      "Epoch 296/1000\n",
      "2/2 - 0s - loss: 109941.6016 - val_loss: 122704.3359\n",
      "Epoch 297/1000\n",
      "2/2 - 0s - loss: 109940.6875 - val_loss: 122703.7266\n",
      "Epoch 298/1000\n",
      "2/2 - 0s - loss: 109939.7656 - val_loss: 122703.1016\n",
      "Epoch 299/1000\n",
      "2/2 - 0s - loss: 109938.8359 - val_loss: 122702.4766\n",
      "Epoch 300/1000\n",
      "2/2 - 0s - loss: 109937.9219 - val_loss: 122701.8516\n",
      "Epoch 301/1000\n",
      "2/2 - 0s - loss: 109936.9766 - val_loss: 122701.2344\n",
      "Epoch 302/1000\n",
      "2/2 - 0s - loss: 109936.0469 - val_loss: 122700.6250\n",
      "Epoch 303/1000\n",
      "2/2 - 0s - loss: 109935.1016 - val_loss: 122700.0234\n",
      "Epoch 304/1000\n",
      "2/2 - 0s - loss: 109934.1484 - val_loss: 122699.3984\n",
      "Epoch 305/1000\n",
      "2/2 - 0s - loss: 109933.2031 - val_loss: 122698.7891\n",
      "Epoch 306/1000\n",
      "2/2 - 0s - loss: 109932.2344 - val_loss: 122698.1719\n",
      "Epoch 307/1000\n",
      "2/2 - 0s - loss: 109931.2734 - val_loss: 122697.5469\n",
      "Epoch 308/1000\n",
      "2/2 - 0s - loss: 109930.3281 - val_loss: 122696.9219\n",
      "Epoch 309/1000\n",
      "2/2 - 0s - loss: 109929.3516 - val_loss: 122696.2891\n",
      "Epoch 310/1000\n",
      "2/2 - 0s - loss: 109928.4141 - val_loss: 122695.6484\n",
      "Epoch 311/1000\n",
      "2/2 - 0s - loss: 109927.4219 - val_loss: 122694.9766\n",
      "Epoch 312/1000\n",
      "2/2 - 0s - loss: 109926.4609 - val_loss: 122694.3281\n",
      "Epoch 313/1000\n",
      "2/2 - 0s - loss: 109925.4766 - val_loss: 122693.6719\n",
      "Epoch 314/1000\n",
      "2/2 - 0s - loss: 109924.5234 - val_loss: 122693.0156\n",
      "Epoch 315/1000\n",
      "2/2 - 0s - loss: 109923.5391 - val_loss: 122692.3750\n",
      "Epoch 316/1000\n",
      "2/2 - 0s - loss: 109922.5391 - val_loss: 122691.7031\n",
      "Epoch 317/1000\n",
      "2/2 - 0s - loss: 109921.5469 - val_loss: 122691.0469\n",
      "Epoch 318/1000\n",
      "2/2 - 0s - loss: 109920.5625 - val_loss: 122690.4141\n",
      "Epoch 319/1000\n",
      "2/2 - 0s - loss: 109919.5859 - val_loss: 122689.7656\n",
      "Epoch 320/1000\n",
      "2/2 - 0s - loss: 109918.5781 - val_loss: 122689.1016\n",
      "Epoch 321/1000\n",
      "2/2 - 0s - loss: 109917.5781 - val_loss: 122688.4531\n",
      "Epoch 322/1000\n",
      "2/2 - 0s - loss: 109916.5859 - val_loss: 122687.7734\n",
      "Epoch 323/1000\n",
      "2/2 - 0s - loss: 109915.6094 - val_loss: 122687.1250\n",
      "Epoch 324/1000\n",
      "2/2 - 0s - loss: 109914.6016 - val_loss: 122686.4609\n",
      "Epoch 325/1000\n",
      "2/2 - 0s - loss: 109913.6016 - val_loss: 122685.7969\n",
      "Epoch 326/1000\n",
      "2/2 - 0s - loss: 109912.5859 - val_loss: 122685.1250\n",
      "Epoch 327/1000\n",
      "2/2 - 0s - loss: 109911.5859 - val_loss: 122684.4609\n",
      "Epoch 328/1000\n",
      "2/2 - 0s - loss: 109910.5469 - val_loss: 122683.7891\n",
      "Epoch 329/1000\n",
      "2/2 - 0s - loss: 109909.5234 - val_loss: 122683.1016\n",
      "Epoch 330/1000\n",
      "2/2 - 0s - loss: 109908.4844 - val_loss: 122682.4375\n",
      "Epoch 331/1000\n",
      "2/2 - 0s - loss: 109907.4766 - val_loss: 122681.7656\n",
      "Epoch 332/1000\n",
      "2/2 - 0s - loss: 109906.4219 - val_loss: 122681.1016\n",
      "Epoch 333/1000\n",
      "2/2 - 0s - loss: 109905.3984 - val_loss: 122680.4531\n",
      "Epoch 334/1000\n",
      "2/2 - 0s - loss: 109904.3281 - val_loss: 122679.7969\n",
      "Epoch 335/1000\n",
      "2/2 - 0s - loss: 109903.2891 - val_loss: 122679.1641\n",
      "Epoch 336/1000\n",
      "2/2 - 0s - loss: 109902.2344 - val_loss: 122678.5156\n",
      "Epoch 337/1000\n",
      "2/2 - 0s - loss: 109901.1875 - val_loss: 122677.8516\n",
      "Epoch 338/1000\n",
      "2/2 - 0s - loss: 109900.1250 - val_loss: 122677.1875\n",
      "Epoch 339/1000\n",
      "2/2 - 0s - loss: 109899.0625 - val_loss: 122676.5156\n",
      "Epoch 340/1000\n",
      "2/2 - 0s - loss: 109898.0156 - val_loss: 122675.8516\n",
      "Epoch 341/1000\n",
      "2/2 - 0s - loss: 109896.9531 - val_loss: 122675.1719\n",
      "Epoch 342/1000\n",
      "2/2 - 0s - loss: 109895.8906 - val_loss: 122674.4844\n",
      "Epoch 343/1000\n",
      "2/2 - 0s - loss: 109894.8359 - val_loss: 122673.7891\n",
      "Epoch 344/1000\n",
      "2/2 - 0s - loss: 109893.7891 - val_loss: 122673.0781\n",
      "Epoch 345/1000\n",
      "2/2 - 0s - loss: 109892.7500 - val_loss: 122672.3750\n",
      "Epoch 346/1000\n",
      "2/2 - 0s - loss: 109891.7031 - val_loss: 122671.6719\n",
      "Epoch 347/1000\n",
      "2/2 - 0s - loss: 109890.6250 - val_loss: 122670.9766\n",
      "Epoch 348/1000\n",
      "2/2 - 0s - loss: 109889.5469 - val_loss: 122670.2969\n",
      "Epoch 349/1000\n",
      "2/2 - 0s - loss: 109888.5156 - val_loss: 122669.6250\n",
      "Epoch 350/1000\n",
      "2/2 - 0s - loss: 109887.4141 - val_loss: 122668.9531\n",
      "Epoch 351/1000\n",
      "2/2 - 0s - loss: 109886.3125 - val_loss: 122668.2500\n",
      "Epoch 352/1000\n",
      "2/2 - 0s - loss: 109885.2266 - val_loss: 122667.5469\n",
      "Epoch 353/1000\n",
      "2/2 - 0s - loss: 109884.1250 - val_loss: 122666.8516\n",
      "Epoch 354/1000\n",
      "2/2 - 0s - loss: 109883.0234 - val_loss: 122666.1484\n",
      "Epoch 355/1000\n",
      "2/2 - 0s - loss: 109881.9375 - val_loss: 122665.4609\n",
      "Epoch 356/1000\n",
      "2/2 - 0s - loss: 109880.8516 - val_loss: 122664.7734\n",
      "Epoch 357/1000\n",
      "2/2 - 0s - loss: 109879.7109 - val_loss: 122664.0859\n",
      "Epoch 358/1000\n",
      "2/2 - 0s - loss: 109878.6250 - val_loss: 122663.3984\n",
      "Epoch 359/1000\n",
      "2/2 - 0s - loss: 109877.4766 - val_loss: 122662.7266\n",
      "Epoch 360/1000\n",
      "2/2 - 0s - loss: 109876.3906 - val_loss: 122662.0391\n",
      "Epoch 361/1000\n",
      "2/2 - 0s - loss: 109875.2266 - val_loss: 122661.3359\n",
      "Epoch 362/1000\n",
      "2/2 - 0s - loss: 109874.1406 - val_loss: 122660.6250\n",
      "Epoch 363/1000\n",
      "2/2 - 0s - loss: 109873.0000 - val_loss: 122659.8984\n",
      "Epoch 364/1000\n",
      "2/2 - 0s - loss: 109871.8516 - val_loss: 122659.1719\n",
      "Epoch 365/1000\n",
      "2/2 - 0s - loss: 109870.7656 - val_loss: 122658.4609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/1000\n",
      "2/2 - 0s - loss: 109869.6094 - val_loss: 122657.7656\n",
      "Epoch 367/1000\n",
      "2/2 - 0s - loss: 109868.5000 - val_loss: 122657.0625\n",
      "Epoch 368/1000\n",
      "2/2 - 0s - loss: 109867.3516 - val_loss: 122656.3359\n",
      "Epoch 369/1000\n",
      "2/2 - 0s - loss: 109866.2266 - val_loss: 122655.6094\n",
      "Epoch 370/1000\n",
      "2/2 - 0s - loss: 109865.0781 - val_loss: 122654.8750\n",
      "Epoch 371/1000\n",
      "2/2 - 0s - loss: 109863.9219 - val_loss: 122654.1250\n",
      "Epoch 372/1000\n",
      "2/2 - 0s - loss: 109862.7969 - val_loss: 122653.3750\n",
      "Epoch 373/1000\n",
      "2/2 - 0s - loss: 109861.6484 - val_loss: 122652.6250\n",
      "Epoch 374/1000\n",
      "2/2 - 0s - loss: 109860.4844 - val_loss: 122651.8750\n",
      "Epoch 375/1000\n",
      "2/2 - 0s - loss: 109859.3516 - val_loss: 122651.1250\n",
      "Epoch 376/1000\n",
      "2/2 - 0s - loss: 109858.1875 - val_loss: 122650.3516\n",
      "Epoch 377/1000\n",
      "2/2 - 0s - loss: 109857.0234 - val_loss: 122649.5625\n",
      "Epoch 378/1000\n",
      "2/2 - 0s - loss: 109855.8594 - val_loss: 122648.7969\n",
      "Epoch 379/1000\n",
      "2/2 - 0s - loss: 109854.6875 - val_loss: 122648.0234\n",
      "Epoch 380/1000\n",
      "2/2 - 0s - loss: 109853.5000 - val_loss: 122647.2734\n",
      "Epoch 381/1000\n",
      "2/2 - 0s - loss: 109852.2969 - val_loss: 122646.5156\n",
      "Epoch 382/1000\n",
      "2/2 - 0s - loss: 109851.1250 - val_loss: 122645.7734\n",
      "Epoch 383/1000\n",
      "2/2 - 0s - loss: 109849.9375 - val_loss: 122645.0391\n",
      "Epoch 384/1000\n",
      "2/2 - 0s - loss: 109848.7266 - val_loss: 122644.2891\n",
      "Epoch 385/1000\n",
      "2/2 - 0s - loss: 109847.4844 - val_loss: 122643.5234\n",
      "Epoch 386/1000\n",
      "2/2 - 0s - loss: 109846.2734 - val_loss: 122642.7734\n",
      "Epoch 387/1000\n",
      "2/2 - 0s - loss: 109845.0781 - val_loss: 122642.0234\n",
      "Epoch 388/1000\n",
      "2/2 - 0s - loss: 109843.8594 - val_loss: 122641.2734\n",
      "Epoch 389/1000\n",
      "2/2 - 0s - loss: 109842.5859 - val_loss: 122640.5000\n",
      "Epoch 390/1000\n",
      "2/2 - 0s - loss: 109841.3984 - val_loss: 122639.7266\n",
      "Epoch 391/1000\n",
      "2/2 - 0s - loss: 109840.1719 - val_loss: 122638.9531\n",
      "Epoch 392/1000\n",
      "2/2 - 0s - loss: 109838.9531 - val_loss: 122638.1641\n",
      "Epoch 393/1000\n",
      "2/2 - 0s - loss: 109837.7109 - val_loss: 122637.3516\n",
      "Epoch 394/1000\n",
      "2/2 - 0s - loss: 109836.5234 - val_loss: 122636.5391\n",
      "Epoch 395/1000\n",
      "2/2 - 0s - loss: 109835.2891 - val_loss: 122635.7266\n",
      "Epoch 396/1000\n",
      "2/2 - 0s - loss: 109834.1016 - val_loss: 122634.8984\n",
      "Epoch 397/1000\n",
      "2/2 - 0s - loss: 109832.8750 - val_loss: 122634.0781\n",
      "Epoch 398/1000\n",
      "2/2 - 0s - loss: 109831.6484 - val_loss: 122633.2344\n",
      "Epoch 399/1000\n",
      "2/2 - 0s - loss: 109830.4531 - val_loss: 122632.4141\n",
      "Epoch 400/1000\n",
      "2/2 - 0s - loss: 109829.1875 - val_loss: 122631.5859\n",
      "Epoch 401/1000\n",
      "2/2 - 0s - loss: 109827.9844 - val_loss: 122630.7500\n",
      "Epoch 402/1000\n",
      "2/2 - 0s - loss: 109826.7266 - val_loss: 122629.9375\n",
      "Epoch 403/1000\n",
      "2/2 - 0s - loss: 109825.5156 - val_loss: 122629.1016\n",
      "Epoch 404/1000\n",
      "2/2 - 0s - loss: 109824.2734 - val_loss: 122628.2734\n",
      "Epoch 405/1000\n",
      "2/2 - 0s - loss: 109823.0000 - val_loss: 122627.4219\n",
      "Epoch 406/1000\n",
      "2/2 - 0s - loss: 109821.7734 - val_loss: 122626.5469\n",
      "Epoch 407/1000\n",
      "2/2 - 0s - loss: 109820.5156 - val_loss: 122625.7109\n",
      "Epoch 408/1000\n",
      "2/2 - 0s - loss: 109819.2891 - val_loss: 122624.8750\n",
      "Epoch 409/1000\n",
      "2/2 - 0s - loss: 109818.0000 - val_loss: 122624.0234\n",
      "Epoch 410/1000\n",
      "2/2 - 0s - loss: 109816.7344 - val_loss: 122623.2031\n",
      "Epoch 411/1000\n",
      "2/2 - 0s - loss: 109815.4531 - val_loss: 122622.3984\n",
      "Epoch 412/1000\n",
      "2/2 - 0s - loss: 109814.1406 - val_loss: 122621.6016\n",
      "Epoch 413/1000\n",
      "2/2 - 0s - loss: 109812.8516 - val_loss: 122620.7969\n",
      "Epoch 414/1000\n",
      "2/2 - 0s - loss: 109811.5469 - val_loss: 122620.0000\n",
      "Epoch 415/1000\n",
      "2/2 - 0s - loss: 109810.2344 - val_loss: 122619.2031\n",
      "Epoch 416/1000\n",
      "2/2 - 0s - loss: 109808.9375 - val_loss: 122618.3984\n",
      "Epoch 417/1000\n",
      "2/2 - 0s - loss: 109807.6641 - val_loss: 122617.6016\n",
      "Epoch 418/1000\n",
      "2/2 - 0s - loss: 109806.3125 - val_loss: 122616.7734\n",
      "Epoch 419/1000\n",
      "2/2 - 0s - loss: 109805.0625 - val_loss: 122615.9844\n",
      "Epoch 420/1000\n",
      "2/2 - 0s - loss: 109803.7734 - val_loss: 122615.2031\n",
      "Epoch 421/1000\n",
      "2/2 - 0s - loss: 109802.4531 - val_loss: 122614.3984\n",
      "Epoch 422/1000\n",
      "2/2 - 0s - loss: 109801.1406 - val_loss: 122613.6016\n",
      "Epoch 423/1000\n",
      "2/2 - 0s - loss: 109799.8516 - val_loss: 122612.7969\n",
      "Epoch 424/1000\n",
      "2/2 - 0s - loss: 109798.5625 - val_loss: 122611.9766\n",
      "Epoch 425/1000\n",
      "2/2 - 0s - loss: 109797.2031 - val_loss: 122611.1484\n",
      "Epoch 426/1000\n",
      "2/2 - 0s - loss: 109795.9219 - val_loss: 122610.3125\n",
      "Epoch 427/1000\n",
      "2/2 - 0s - loss: 109794.5859 - val_loss: 122609.4766\n",
      "Epoch 428/1000\n",
      "2/2 - 0s - loss: 109793.2734 - val_loss: 122608.6484\n",
      "Epoch 429/1000\n",
      "2/2 - 0s - loss: 109791.9219 - val_loss: 122607.8281\n",
      "Epoch 430/1000\n",
      "2/2 - 0s - loss: 109790.6094 - val_loss: 122607.0000\n",
      "Epoch 431/1000\n",
      "2/2 - 0s - loss: 109789.2734 - val_loss: 122606.1484\n",
      "Epoch 432/1000\n",
      "2/2 - 0s - loss: 109787.9531 - val_loss: 122605.3125\n",
      "Epoch 433/1000\n",
      "2/2 - 0s - loss: 109786.6250 - val_loss: 122604.4766\n",
      "Epoch 434/1000\n",
      "2/2 - 0s - loss: 109785.2969 - val_loss: 122603.6016\n",
      "Epoch 435/1000\n",
      "2/2 - 0s - loss: 109783.9766 - val_loss: 122602.7266\n",
      "Epoch 436/1000\n",
      "2/2 - 0s - loss: 109782.6484 - val_loss: 122601.8516\n",
      "Epoch 437/1000\n",
      "2/2 - 0s - loss: 109781.2734 - val_loss: 122600.9766\n",
      "Epoch 438/1000\n",
      "2/2 - 0s - loss: 109779.9844 - val_loss: 122600.1094\n",
      "Epoch 439/1000\n",
      "2/2 - 0s - loss: 109778.6406 - val_loss: 122599.2344\n",
      "Epoch 440/1000\n",
      "2/2 - 0s - loss: 109777.2969 - val_loss: 122598.3516\n",
      "Epoch 441/1000\n",
      "2/2 - 0s - loss: 109775.9219 - val_loss: 122597.4766\n",
      "Epoch 442/1000\n",
      "2/2 - 0s - loss: 109774.6016 - val_loss: 122596.6016\n",
      "Epoch 443/1000\n",
      "2/2 - 0s - loss: 109773.2500 - val_loss: 122595.7109\n",
      "Epoch 444/1000\n",
      "2/2 - 0s - loss: 109771.9141 - val_loss: 122594.8125\n",
      "Epoch 445/1000\n",
      "2/2 - 0s - loss: 109770.5391 - val_loss: 122593.9141\n",
      "Epoch 446/1000\n",
      "2/2 - 0s - loss: 109769.2031 - val_loss: 122593.0000\n",
      "Epoch 447/1000\n",
      "2/2 - 0s - loss: 109767.8125 - val_loss: 122592.1016\n",
      "Epoch 448/1000\n",
      "2/2 - 0s - loss: 109766.4609 - val_loss: 122591.2266\n",
      "Epoch 449/1000\n",
      "2/2 - 0s - loss: 109765.0781 - val_loss: 122590.3516\n",
      "Epoch 450/1000\n",
      "2/2 - 0s - loss: 109763.6406 - val_loss: 122589.4609\n",
      "Epoch 451/1000\n",
      "2/2 - 0s - loss: 109762.2500 - val_loss: 122588.5859\n",
      "Epoch 452/1000\n",
      "2/2 - 0s - loss: 109760.8359 - val_loss: 122587.7109\n",
      "Epoch 453/1000\n",
      "2/2 - 0s - loss: 109759.4375 - val_loss: 122586.8281\n",
      "Epoch 454/1000\n",
      "2/2 - 0s - loss: 109758.0000 - val_loss: 122585.9531\n",
      "Epoch 455/1000\n",
      "2/2 - 0s - loss: 109756.5781 - val_loss: 122585.0781\n",
      "Epoch 456/1000\n",
      "2/2 - 0s - loss: 109755.2266 - val_loss: 122584.2031\n",
      "Epoch 457/1000\n",
      "2/2 - 0s - loss: 109753.7500 - val_loss: 122583.2969\n",
      "Epoch 458/1000\n",
      "2/2 - 0s - loss: 109752.3594 - val_loss: 122582.3906\n",
      "Epoch 459/1000\n",
      "2/2 - 0s - loss: 109750.9766 - val_loss: 122581.4766\n",
      "Epoch 460/1000\n",
      "2/2 - 0s - loss: 109749.5781 - val_loss: 122580.5625\n",
      "Epoch 461/1000\n",
      "2/2 - 0s - loss: 109748.1719 - val_loss: 122579.6250\n",
      "Epoch 462/1000\n",
      "2/2 - 0s - loss: 109746.7500 - val_loss: 122578.7031\n",
      "Epoch 463/1000\n",
      "2/2 - 0s - loss: 109745.3984 - val_loss: 122577.7891\n",
      "Epoch 464/1000\n",
      "2/2 - 0s - loss: 109743.9844 - val_loss: 122576.8594\n",
      "Epoch 465/1000\n",
      "2/2 - 0s - loss: 109742.5469 - val_loss: 122575.9219\n",
      "Epoch 466/1000\n",
      "2/2 - 0s - loss: 109741.1719 - val_loss: 122575.0000\n",
      "Epoch 467/1000\n",
      "2/2 - 0s - loss: 109739.7344 - val_loss: 122574.0469\n",
      "Epoch 468/1000\n",
      "2/2 - 0s - loss: 109738.3359 - val_loss: 122573.1250\n",
      "Epoch 469/1000\n",
      "2/2 - 0s - loss: 109736.9375 - val_loss: 122572.1875\n",
      "Epoch 470/1000\n",
      "2/2 - 0s - loss: 109735.4844 - val_loss: 122571.2500\n",
      "Epoch 471/1000\n",
      "2/2 - 0s - loss: 109734.0391 - val_loss: 122570.3281\n",
      "Epoch 472/1000\n",
      "2/2 - 0s - loss: 109732.6094 - val_loss: 122569.3984\n",
      "Epoch 473/1000\n",
      "2/2 - 0s - loss: 109731.1484 - val_loss: 122568.4766\n",
      "Epoch 474/1000\n",
      "2/2 - 0s - loss: 109729.6719 - val_loss: 122567.5391\n",
      "Epoch 475/1000\n",
      "2/2 - 0s - loss: 109728.2109 - val_loss: 122566.6016\n",
      "Epoch 476/1000\n",
      "2/2 - 0s - loss: 109726.7734 - val_loss: 122565.6484\n",
      "Epoch 477/1000\n",
      "2/2 - 0s - loss: 109725.2734 - val_loss: 122564.6875\n",
      "Epoch 478/1000\n",
      "2/2 - 0s - loss: 109723.8281 - val_loss: 122563.7266\n",
      "Epoch 479/1000\n",
      "2/2 - 0s - loss: 109722.4141 - val_loss: 122562.7500\n",
      "Epoch 480/1000\n",
      "2/2 - 0s - loss: 109720.9531 - val_loss: 122561.7734\n",
      "Epoch 481/1000\n",
      "2/2 - 0s - loss: 109719.5234 - val_loss: 122560.7891\n",
      "Epoch 482/1000\n",
      "2/2 - 0s - loss: 109718.1016 - val_loss: 122559.7969\n",
      "Epoch 483/1000\n",
      "2/2 - 0s - loss: 109716.6641 - val_loss: 122558.7969\n",
      "Epoch 484/1000\n",
      "2/2 - 0s - loss: 109715.2266 - val_loss: 122557.8125\n",
      "Epoch 485/1000\n",
      "2/2 - 0s - loss: 109713.7734 - val_loss: 122556.8281\n",
      "Epoch 486/1000\n",
      "2/2 - 0s - loss: 109712.3594 - val_loss: 122555.8516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/1000\n",
      "2/2 - 0s - loss: 109710.8984 - val_loss: 122554.8750\n",
      "Epoch 488/1000\n",
      "2/2 - 0s - loss: 109709.4375 - val_loss: 122553.8906\n",
      "Epoch 489/1000\n",
      "2/2 - 0s - loss: 109707.9609 - val_loss: 122552.8984\n",
      "Epoch 490/1000\n",
      "2/2 - 0s - loss: 109706.5000 - val_loss: 122551.9375\n",
      "Epoch 491/1000\n",
      "2/2 - 0s - loss: 109705.0391 - val_loss: 122550.9766\n",
      "Epoch 492/1000\n",
      "2/2 - 0s - loss: 109703.5469 - val_loss: 122550.0000\n",
      "Epoch 493/1000\n",
      "2/2 - 0s - loss: 109702.0625 - val_loss: 122549.0234\n",
      "Epoch 494/1000\n",
      "2/2 - 0s - loss: 109700.5781 - val_loss: 122548.0469\n",
      "Epoch 495/1000\n",
      "2/2 - 0s - loss: 109699.0781 - val_loss: 122547.0469\n",
      "Epoch 496/1000\n",
      "2/2 - 0s - loss: 109697.6094 - val_loss: 122546.0469\n",
      "Epoch 497/1000\n",
      "2/2 - 0s - loss: 109696.1094 - val_loss: 122545.0469\n",
      "Epoch 498/1000\n",
      "2/2 - 0s - loss: 109694.6484 - val_loss: 122544.0781\n",
      "Epoch 499/1000\n",
      "2/2 - 0s - loss: 109693.1016 - val_loss: 122543.1016\n",
      "Epoch 500/1000\n",
      "2/2 - 0s - loss: 109691.6250 - val_loss: 122542.1406\n",
      "Epoch 501/1000\n",
      "2/2 - 0s - loss: 109690.1250 - val_loss: 122541.1406\n",
      "Epoch 502/1000\n",
      "2/2 - 0s - loss: 109688.5859 - val_loss: 122540.1406\n",
      "Epoch 503/1000\n",
      "2/2 - 0s - loss: 109687.1016 - val_loss: 122539.1250\n",
      "Epoch 504/1000\n",
      "2/2 - 0s - loss: 109685.5625 - val_loss: 122538.1016\n",
      "Epoch 505/1000\n",
      "2/2 - 0s - loss: 109684.0469 - val_loss: 122537.1094\n",
      "Epoch 506/1000\n",
      "2/2 - 0s - loss: 109682.5391 - val_loss: 122536.1250\n",
      "Epoch 507/1000\n",
      "2/2 - 0s - loss: 109680.9766 - val_loss: 122535.1719\n",
      "Epoch 508/1000\n",
      "2/2 - 0s - loss: 109679.4531 - val_loss: 122534.2031\n",
      "Epoch 509/1000\n",
      "2/2 - 0s - loss: 109677.9141 - val_loss: 122533.2266\n",
      "Epoch 510/1000\n",
      "2/2 - 0s - loss: 109676.3906 - val_loss: 122532.2500\n",
      "Epoch 511/1000\n",
      "2/2 - 0s - loss: 109674.8281 - val_loss: 122531.2500\n",
      "Epoch 512/1000\n",
      "2/2 - 0s - loss: 109673.2656 - val_loss: 122530.2500\n",
      "Epoch 513/1000\n",
      "2/2 - 0s - loss: 109671.7500 - val_loss: 122529.2500\n",
      "Epoch 514/1000\n",
      "2/2 - 0s - loss: 109670.2031 - val_loss: 122528.2656\n",
      "Epoch 515/1000\n",
      "2/2 - 0s - loss: 109668.6719 - val_loss: 122527.2656\n",
      "Epoch 516/1000\n",
      "2/2 - 0s - loss: 109667.1016 - val_loss: 122526.2500\n",
      "Epoch 517/1000\n",
      "2/2 - 0s - loss: 109665.5781 - val_loss: 122525.2500\n",
      "Epoch 518/1000\n",
      "2/2 - 0s - loss: 109664.0156 - val_loss: 122524.2344\n",
      "Epoch 519/1000\n",
      "2/2 - 0s - loss: 109662.4531 - val_loss: 122523.2266\n",
      "Epoch 520/1000\n",
      "2/2 - 0s - loss: 109660.8984 - val_loss: 122522.2031\n",
      "Epoch 521/1000\n",
      "2/2 - 0s - loss: 109659.2969 - val_loss: 122521.1875\n",
      "Epoch 522/1000\n",
      "2/2 - 0s - loss: 109657.7344 - val_loss: 122520.1719\n",
      "Epoch 523/1000\n",
      "2/2 - 0s - loss: 109656.2031 - val_loss: 122519.1484\n",
      "Epoch 524/1000\n",
      "2/2 - 0s - loss: 109654.6094 - val_loss: 122518.1094\n",
      "Epoch 525/1000\n",
      "2/2 - 0s - loss: 109653.0156 - val_loss: 122517.0781\n",
      "Epoch 526/1000\n",
      "2/2 - 0s - loss: 109651.4375 - val_loss: 122516.0234\n",
      "Epoch 527/1000\n",
      "2/2 - 0s - loss: 109649.8984 - val_loss: 122515.0000\n",
      "Epoch 528/1000\n",
      "2/2 - 0s - loss: 109648.2891 - val_loss: 122513.9609\n",
      "Epoch 529/1000\n",
      "2/2 - 0s - loss: 109646.7344 - val_loss: 122512.9375\n",
      "Epoch 530/1000\n",
      "2/2 - 0s - loss: 109645.1719 - val_loss: 122511.8984\n",
      "Epoch 531/1000\n",
      "2/2 - 0s - loss: 109643.5781 - val_loss: 122510.8359\n",
      "Epoch 532/1000\n",
      "2/2 - 0s - loss: 109642.0156 - val_loss: 122509.7969\n",
      "Epoch 533/1000\n",
      "2/2 - 0s - loss: 109640.4609 - val_loss: 122508.7500\n",
      "Epoch 534/1000\n",
      "2/2 - 0s - loss: 109638.9141 - val_loss: 122507.7031\n",
      "Epoch 535/1000\n",
      "2/2 - 0s - loss: 109637.3281 - val_loss: 122506.6484\n",
      "Epoch 536/1000\n",
      "2/2 - 0s - loss: 109635.7500 - val_loss: 122505.6250\n",
      "Epoch 537/1000\n",
      "2/2 - 0s - loss: 109634.1719 - val_loss: 122504.6016\n",
      "Epoch 538/1000\n",
      "2/2 - 0s - loss: 109632.5625 - val_loss: 122503.6016\n",
      "Epoch 539/1000\n",
      "2/2 - 0s - loss: 109630.9609 - val_loss: 122502.6250\n",
      "Epoch 540/1000\n",
      "2/2 - 0s - loss: 109629.3281 - val_loss: 122501.6484\n",
      "Epoch 541/1000\n",
      "2/2 - 0s - loss: 109627.6875 - val_loss: 122500.6875\n",
      "Epoch 542/1000\n",
      "2/2 - 0s - loss: 109626.0781 - val_loss: 122499.7266\n",
      "Epoch 543/1000\n",
      "2/2 - 0s - loss: 109624.3906 - val_loss: 122498.7344\n",
      "Epoch 544/1000\n",
      "2/2 - 0s - loss: 109622.7734 - val_loss: 122497.7344\n",
      "Epoch 545/1000\n",
      "2/2 - 0s - loss: 109621.1484 - val_loss: 122496.7266\n",
      "Epoch 546/1000\n",
      "2/2 - 0s - loss: 109619.5000 - val_loss: 122495.7031\n",
      "Epoch 547/1000\n",
      "2/2 - 0s - loss: 109617.8906 - val_loss: 122494.7031\n",
      "Epoch 548/1000\n",
      "2/2 - 0s - loss: 109616.2734 - val_loss: 122493.7031\n",
      "Epoch 549/1000\n",
      "2/2 - 0s - loss: 109614.6484 - val_loss: 122492.6875\n",
      "Epoch 550/1000\n",
      "2/2 - 0s - loss: 109613.0391 - val_loss: 122491.6641\n",
      "Epoch 551/1000\n",
      "2/2 - 0s - loss: 109611.3984 - val_loss: 122490.6016\n",
      "Epoch 552/1000\n",
      "2/2 - 0s - loss: 109609.7891 - val_loss: 122489.5234\n",
      "Epoch 553/1000\n",
      "2/2 - 0s - loss: 109608.2031 - val_loss: 122488.4531\n",
      "Epoch 554/1000\n",
      "2/2 - 0s - loss: 109606.5625 - val_loss: 122487.3906\n",
      "Epoch 555/1000\n",
      "2/2 - 0s - loss: 109604.9531 - val_loss: 122486.3281\n",
      "Epoch 556/1000\n",
      "2/2 - 0s - loss: 109603.2891 - val_loss: 122485.2500\n",
      "Epoch 557/1000\n",
      "2/2 - 0s - loss: 109601.6484 - val_loss: 122484.1719\n",
      "Epoch 558/1000\n",
      "2/2 - 0s - loss: 109600.0391 - val_loss: 122483.1016\n",
      "Epoch 559/1000\n",
      "2/2 - 0s - loss: 109598.3594 - val_loss: 122482.0000\n",
      "Epoch 560/1000\n",
      "2/2 - 0s - loss: 109596.7109 - val_loss: 122480.8750\n",
      "Epoch 561/1000\n",
      "2/2 - 0s - loss: 109595.1016 - val_loss: 122479.7656\n",
      "Epoch 562/1000\n",
      "2/2 - 0s - loss: 109593.4219 - val_loss: 122478.6484\n",
      "Epoch 563/1000\n",
      "2/2 - 0s - loss: 109591.7969 - val_loss: 122477.5391\n",
      "Epoch 564/1000\n",
      "2/2 - 0s - loss: 109590.1406 - val_loss: 122476.3984\n",
      "Epoch 565/1000\n",
      "2/2 - 0s - loss: 109588.4844 - val_loss: 122475.2734\n",
      "Epoch 566/1000\n",
      "2/2 - 0s - loss: 109586.8281 - val_loss: 122474.1250\n",
      "Epoch 567/1000\n",
      "2/2 - 0s - loss: 109585.1484 - val_loss: 122473.0000\n",
      "Epoch 568/1000\n",
      "2/2 - 0s - loss: 109583.5000 - val_loss: 122471.8516\n",
      "Epoch 569/1000\n",
      "2/2 - 0s - loss: 109581.8281 - val_loss: 122470.7266\n",
      "Epoch 570/1000\n",
      "2/2 - 0s - loss: 109580.1875 - val_loss: 122469.5781\n",
      "Epoch 571/1000\n",
      "2/2 - 0s - loss: 109578.4766 - val_loss: 122468.4531\n",
      "Epoch 572/1000\n",
      "2/2 - 0s - loss: 109576.7969 - val_loss: 122467.3125\n",
      "Epoch 573/1000\n",
      "2/2 - 0s - loss: 109575.1250 - val_loss: 122466.2031\n",
      "Epoch 574/1000\n",
      "2/2 - 0s - loss: 109573.4219 - val_loss: 122465.0781\n",
      "Epoch 575/1000\n",
      "2/2 - 0s - loss: 109571.7656 - val_loss: 122463.9531\n",
      "Epoch 576/1000\n",
      "2/2 - 0s - loss: 109570.0469 - val_loss: 122462.8125\n",
      "Epoch 577/1000\n",
      "2/2 - 0s - loss: 109568.3125 - val_loss: 122461.7031\n",
      "Epoch 578/1000\n",
      "2/2 - 0s - loss: 109566.6406 - val_loss: 122460.6016\n",
      "Epoch 579/1000\n",
      "2/2 - 0s - loss: 109564.8750 - val_loss: 122459.5156\n",
      "Epoch 580/1000\n",
      "2/2 - 0s - loss: 109563.1875 - val_loss: 122458.3984\n",
      "Epoch 581/1000\n",
      "2/2 - 0s - loss: 109561.4531 - val_loss: 122457.2969\n",
      "Epoch 582/1000\n",
      "2/2 - 0s - loss: 109559.6719 - val_loss: 122456.1875\n",
      "Epoch 583/1000\n",
      "2/2 - 0s - loss: 109557.9375 - val_loss: 122455.0781\n",
      "Epoch 584/1000\n",
      "2/2 - 0s - loss: 109556.2109 - val_loss: 122454.0000\n",
      "Epoch 585/1000\n",
      "2/2 - 0s - loss: 109554.4766 - val_loss: 122452.8984\n",
      "Epoch 586/1000\n",
      "2/2 - 0s - loss: 109552.7266 - val_loss: 122451.7734\n",
      "Epoch 587/1000\n",
      "2/2 - 0s - loss: 109550.9766 - val_loss: 122450.6641\n",
      "Epoch 588/1000\n",
      "2/2 - 0s - loss: 109549.2656 - val_loss: 122449.5234\n",
      "Epoch 589/1000\n",
      "2/2 - 0s - loss: 109547.5469 - val_loss: 122448.3594\n",
      "Epoch 590/1000\n",
      "2/2 - 0s - loss: 109545.8281 - val_loss: 122447.2031\n",
      "Epoch 591/1000\n",
      "2/2 - 0s - loss: 109544.1016 - val_loss: 122446.0469\n",
      "Epoch 592/1000\n",
      "2/2 - 0s - loss: 109542.3281 - val_loss: 122444.8984\n",
      "Epoch 593/1000\n",
      "2/2 - 0s - loss: 109540.6016 - val_loss: 122443.7656\n",
      "Epoch 594/1000\n",
      "2/2 - 0s - loss: 109538.8516 - val_loss: 122442.6484\n",
      "Epoch 595/1000\n",
      "2/2 - 0s - loss: 109537.1250 - val_loss: 122441.5391\n",
      "Epoch 596/1000\n",
      "2/2 - 0s - loss: 109535.2656 - val_loss: 122440.4141\n",
      "Epoch 597/1000\n",
      "2/2 - 0s - loss: 109533.5625 - val_loss: 122439.2969\n",
      "Epoch 598/1000\n",
      "2/2 - 0s - loss: 109531.7734 - val_loss: 122438.1875\n",
      "Epoch 599/1000\n",
      "2/2 - 0s - loss: 109530.0000 - val_loss: 122437.0625\n",
      "Epoch 600/1000\n",
      "2/2 - 0s - loss: 109528.2031 - val_loss: 122435.9375\n",
      "Epoch 601/1000\n",
      "2/2 - 0s - loss: 109526.4375 - val_loss: 122434.8359\n",
      "Epoch 602/1000\n",
      "2/2 - 0s - loss: 109524.6484 - val_loss: 122433.7266\n",
      "Epoch 603/1000\n",
      "2/2 - 0s - loss: 109522.8359 - val_loss: 122432.6094\n",
      "Epoch 604/1000\n",
      "2/2 - 0s - loss: 109521.0234 - val_loss: 122431.5000\n",
      "Epoch 605/1000\n",
      "2/2 - 0s - loss: 109519.2500 - val_loss: 122430.3750\n",
      "Epoch 606/1000\n",
      "2/2 - 0s - loss: 109517.4375 - val_loss: 122429.2500\n",
      "Epoch 607/1000\n",
      "2/2 - 0s - loss: 109515.6094 - val_loss: 122428.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608/1000\n",
      "2/2 - 0s - loss: 109513.7344 - val_loss: 122426.9844\n",
      "Epoch 609/1000\n",
      "2/2 - 0s - loss: 109511.9375 - val_loss: 122425.8594\n",
      "Epoch 610/1000\n",
      "2/2 - 0s - loss: 109510.1016 - val_loss: 122424.7656\n",
      "Epoch 611/1000\n",
      "2/2 - 0s - loss: 109508.2656 - val_loss: 122423.6484\n",
      "Epoch 612/1000\n",
      "2/2 - 0s - loss: 109506.4531 - val_loss: 122422.5234\n",
      "Epoch 613/1000\n",
      "2/2 - 0s - loss: 109504.5469 - val_loss: 122421.3594\n",
      "Epoch 614/1000\n",
      "2/2 - 0s - loss: 109502.7656 - val_loss: 122420.1875\n",
      "Epoch 615/1000\n",
      "2/2 - 0s - loss: 109500.8984 - val_loss: 122419.0000\n",
      "Epoch 616/1000\n",
      "2/2 - 0s - loss: 109499.1016 - val_loss: 122417.7969\n",
      "Epoch 617/1000\n",
      "2/2 - 0s - loss: 109497.2656 - val_loss: 122416.6094\n",
      "Epoch 618/1000\n",
      "2/2 - 0s - loss: 109495.4219 - val_loss: 122415.4219\n",
      "Epoch 619/1000\n",
      "2/2 - 0s - loss: 109493.6250 - val_loss: 122414.2266\n",
      "Epoch 620/1000\n",
      "2/2 - 0s - loss: 109491.8281 - val_loss: 122413.0234\n",
      "Epoch 621/1000\n",
      "2/2 - 0s - loss: 109489.9766 - val_loss: 122411.8125\n",
      "Epoch 622/1000\n",
      "2/2 - 0s - loss: 109488.1719 - val_loss: 122410.6016\n",
      "Epoch 623/1000\n",
      "2/2 - 0s - loss: 109486.3594 - val_loss: 122409.3906\n",
      "Epoch 624/1000\n",
      "2/2 - 0s - loss: 109484.5781 - val_loss: 122408.1719\n",
      "Epoch 625/1000\n",
      "2/2 - 0s - loss: 109482.7656 - val_loss: 122406.9766\n",
      "Epoch 626/1000\n",
      "2/2 - 0s - loss: 109480.9141 - val_loss: 122405.7734\n",
      "Epoch 627/1000\n",
      "2/2 - 0s - loss: 109479.1250 - val_loss: 122404.5781\n",
      "Epoch 628/1000\n",
      "2/2 - 0s - loss: 109477.3125 - val_loss: 122403.3984\n",
      "Epoch 629/1000\n",
      "2/2 - 0s - loss: 109475.5000 - val_loss: 122402.1875\n",
      "Epoch 630/1000\n",
      "2/2 - 0s - loss: 109473.6406 - val_loss: 122400.9766\n",
      "Epoch 631/1000\n",
      "2/2 - 0s - loss: 109471.8125 - val_loss: 122399.7734\n",
      "Epoch 632/1000\n",
      "2/2 - 0s - loss: 109470.0391 - val_loss: 122398.5781\n",
      "Epoch 633/1000\n",
      "2/2 - 0s - loss: 109468.1641 - val_loss: 122397.3750\n",
      "Epoch 634/1000\n",
      "2/2 - 0s - loss: 109466.3516 - val_loss: 122396.1484\n",
      "Epoch 635/1000\n",
      "2/2 - 0s - loss: 109464.4766 - val_loss: 122394.9375\n",
      "Epoch 636/1000\n",
      "2/2 - 0s - loss: 109462.6250 - val_loss: 122393.7500\n",
      "Epoch 637/1000\n",
      "2/2 - 0s - loss: 109460.7734 - val_loss: 122392.5781\n",
      "Epoch 638/1000\n",
      "2/2 - 0s - loss: 109458.8516 - val_loss: 122391.4219\n",
      "Epoch 639/1000\n",
      "2/2 - 0s - loss: 109457.0000 - val_loss: 122390.2656\n",
      "Epoch 640/1000\n",
      "2/2 - 0s - loss: 109455.1250 - val_loss: 122389.0781\n",
      "Epoch 641/1000\n",
      "2/2 - 0s - loss: 109453.2031 - val_loss: 122387.8516\n",
      "Epoch 642/1000\n",
      "2/2 - 0s - loss: 109451.2969 - val_loss: 122386.6484\n",
      "Epoch 643/1000\n",
      "2/2 - 0s - loss: 109449.4766 - val_loss: 122385.4219\n",
      "Epoch 644/1000\n",
      "2/2 - 0s - loss: 109447.5781 - val_loss: 122384.2031\n",
      "Epoch 645/1000\n",
      "2/2 - 0s - loss: 109445.7734 - val_loss: 122382.9766\n",
      "Epoch 646/1000\n",
      "2/2 - 0s - loss: 109443.8984 - val_loss: 122381.7109\n",
      "Epoch 647/1000\n",
      "2/2 - 0s - loss: 109442.0469 - val_loss: 122380.4609\n",
      "Epoch 648/1000\n",
      "2/2 - 0s - loss: 109440.2109 - val_loss: 122379.2109\n",
      "Epoch 649/1000\n",
      "2/2 - 0s - loss: 109438.3750 - val_loss: 122377.9531\n",
      "Epoch 650/1000\n",
      "2/2 - 0s - loss: 109436.4844 - val_loss: 122376.6719\n",
      "Epoch 651/1000\n",
      "2/2 - 0s - loss: 109434.6719 - val_loss: 122375.3984\n",
      "Epoch 652/1000\n",
      "2/2 - 0s - loss: 109432.7500 - val_loss: 122374.1406\n",
      "Epoch 653/1000\n",
      "2/2 - 0s - loss: 109430.8906 - val_loss: 122372.8750\n",
      "Epoch 654/1000\n",
      "2/2 - 0s - loss: 109429.0469 - val_loss: 122371.6484\n",
      "Epoch 655/1000\n",
      "2/2 - 0s - loss: 109427.0781 - val_loss: 122370.4219\n",
      "Epoch 656/1000\n",
      "2/2 - 0s - loss: 109425.2656 - val_loss: 122369.2344\n",
      "Epoch 657/1000\n",
      "2/2 - 0s - loss: 109423.2734 - val_loss: 122368.0234\n",
      "Epoch 658/1000\n",
      "2/2 - 0s - loss: 109421.4219 - val_loss: 122366.8281\n",
      "Epoch 659/1000\n",
      "2/2 - 0s - loss: 109419.4844 - val_loss: 122365.6094\n",
      "Epoch 660/1000\n",
      "2/2 - 0s - loss: 109417.5234 - val_loss: 122364.3984\n",
      "Epoch 661/1000\n",
      "2/2 - 0s - loss: 109415.6719 - val_loss: 122363.2031\n",
      "Epoch 662/1000\n",
      "2/2 - 0s - loss: 109413.6719 - val_loss: 122361.9766\n",
      "Epoch 663/1000\n",
      "2/2 - 0s - loss: 109411.7500 - val_loss: 122360.7500\n",
      "Epoch 664/1000\n",
      "2/2 - 0s - loss: 109409.7656 - val_loss: 122359.5234\n",
      "Epoch 665/1000\n",
      "2/2 - 0s - loss: 109407.7969 - val_loss: 122358.2969\n",
      "Epoch 666/1000\n",
      "2/2 - 0s - loss: 109405.8594 - val_loss: 122357.1094\n",
      "Epoch 667/1000\n",
      "2/2 - 0s - loss: 109403.8750 - val_loss: 122355.9141\n",
      "Epoch 668/1000\n",
      "2/2 - 0s - loss: 109401.8750 - val_loss: 122354.7031\n",
      "Epoch 669/1000\n",
      "2/2 - 0s - loss: 109399.9219 - val_loss: 122353.5000\n",
      "Epoch 670/1000\n",
      "2/2 - 0s - loss: 109397.9219 - val_loss: 122352.2969\n",
      "Epoch 671/1000\n",
      "2/2 - 0s - loss: 109395.9141 - val_loss: 122351.1094\n",
      "Epoch 672/1000\n",
      "2/2 - 0s - loss: 109393.9219 - val_loss: 122349.9531\n",
      "Epoch 673/1000\n",
      "2/2 - 0s - loss: 109391.9766 - val_loss: 122348.7734\n",
      "Epoch 674/1000\n",
      "2/2 - 0s - loss: 109389.9531 - val_loss: 122347.5859\n",
      "Epoch 675/1000\n",
      "2/2 - 0s - loss: 109387.9219 - val_loss: 122346.3750\n",
      "Epoch 676/1000\n",
      "2/2 - 0s - loss: 109385.9844 - val_loss: 122345.1484\n",
      "Epoch 677/1000\n",
      "2/2 - 0s - loss: 109383.9609 - val_loss: 122343.8906\n",
      "Epoch 678/1000\n",
      "2/2 - 0s - loss: 109382.0234 - val_loss: 122342.6094\n",
      "Epoch 679/1000\n",
      "2/2 - 0s - loss: 109380.0469 - val_loss: 122341.3281\n",
      "Epoch 680/1000\n",
      "2/2 - 0s - loss: 109378.1094 - val_loss: 122340.0234\n",
      "Epoch 681/1000\n",
      "2/2 - 0s - loss: 109376.1875 - val_loss: 122338.7500\n",
      "Epoch 682/1000\n",
      "2/2 - 0s - loss: 109374.1719 - val_loss: 122337.4844\n",
      "Epoch 683/1000\n",
      "2/2 - 0s - loss: 109372.2266 - val_loss: 122336.2266\n",
      "Epoch 684/1000\n",
      "2/2 - 0s - loss: 109370.3125 - val_loss: 122334.9531\n",
      "Epoch 685/1000\n",
      "2/2 - 0s - loss: 109368.3281 - val_loss: 122333.6641\n",
      "Epoch 686/1000\n",
      "2/2 - 0s - loss: 109366.3906 - val_loss: 122332.3516\n",
      "Epoch 687/1000\n",
      "2/2 - 0s - loss: 109364.4375 - val_loss: 122331.0469\n",
      "Epoch 688/1000\n",
      "2/2 - 0s - loss: 109362.4766 - val_loss: 122329.7656\n",
      "Epoch 689/1000\n",
      "2/2 - 0s - loss: 109360.5156 - val_loss: 122328.4766\n",
      "Epoch 690/1000\n",
      "2/2 - 0s - loss: 109358.5469 - val_loss: 122327.2109\n",
      "Epoch 691/1000\n",
      "2/2 - 0s - loss: 109356.5781 - val_loss: 122325.9531\n",
      "Epoch 692/1000\n",
      "2/2 - 0s - loss: 109354.5391 - val_loss: 122324.6875\n",
      "Epoch 693/1000\n",
      "2/2 - 0s - loss: 109352.5156 - val_loss: 122323.4531\n",
      "Epoch 694/1000\n",
      "2/2 - 0s - loss: 109350.5469 - val_loss: 122322.1875\n",
      "Epoch 695/1000\n",
      "2/2 - 0s - loss: 109348.4766 - val_loss: 122320.9219\n",
      "Epoch 696/1000\n",
      "2/2 - 0s - loss: 109346.4219 - val_loss: 122319.7031\n",
      "Epoch 697/1000\n",
      "2/2 - 0s - loss: 109344.3984 - val_loss: 122318.4844\n",
      "Epoch 698/1000\n",
      "2/2 - 0s - loss: 109342.3281 - val_loss: 122317.2500\n",
      "Epoch 699/1000\n",
      "2/2 - 0s - loss: 109340.2891 - val_loss: 122316.0234\n",
      "Epoch 700/1000\n",
      "2/2 - 0s - loss: 109338.2031 - val_loss: 122314.7891\n",
      "Epoch 701/1000\n",
      "2/2 - 0s - loss: 109336.2031 - val_loss: 122313.5469\n",
      "Epoch 702/1000\n",
      "2/2 - 0s - loss: 109334.0859 - val_loss: 122312.2891\n",
      "Epoch 703/1000\n",
      "2/2 - 0s - loss: 109332.0781 - val_loss: 122311.0469\n",
      "Epoch 704/1000\n",
      "2/2 - 0s - loss: 109330.0781 - val_loss: 122309.7969\n",
      "Epoch 705/1000\n",
      "2/2 - 0s - loss: 109328.0000 - val_loss: 122308.5234\n",
      "Epoch 706/1000\n",
      "2/2 - 0s - loss: 109325.9609 - val_loss: 122307.2734\n",
      "Epoch 707/1000\n",
      "2/2 - 0s - loss: 109323.9609 - val_loss: 122306.0156\n",
      "Epoch 708/1000\n",
      "2/2 - 0s - loss: 109321.8750 - val_loss: 122304.7266\n",
      "Epoch 709/1000\n",
      "2/2 - 0s - loss: 109319.8594 - val_loss: 122303.4219\n",
      "Epoch 710/1000\n",
      "2/2 - 0s - loss: 109317.7500 - val_loss: 122302.1094\n",
      "Epoch 711/1000\n",
      "2/2 - 0s - loss: 109315.7656 - val_loss: 122300.8281\n",
      "Epoch 712/1000\n",
      "2/2 - 0s - loss: 109313.6016 - val_loss: 122299.5234\n",
      "Epoch 713/1000\n",
      "2/2 - 0s - loss: 109311.5859 - val_loss: 122298.2344\n",
      "Epoch 714/1000\n",
      "2/2 - 0s - loss: 109309.5391 - val_loss: 122296.9531\n",
      "Epoch 715/1000\n",
      "2/2 - 0s - loss: 109307.3984 - val_loss: 122295.6406\n",
      "Epoch 716/1000\n",
      "2/2 - 0s - loss: 109305.3594 - val_loss: 122294.3516\n",
      "Epoch 717/1000\n",
      "2/2 - 0s - loss: 109303.2656 - val_loss: 122293.0625\n",
      "Epoch 718/1000\n",
      "2/2 - 0s - loss: 109301.2266 - val_loss: 122291.7734\n",
      "Epoch 719/1000\n",
      "2/2 - 0s - loss: 109299.2031 - val_loss: 122290.4766\n",
      "Epoch 720/1000\n",
      "2/2 - 0s - loss: 109297.1016 - val_loss: 122289.1719\n",
      "Epoch 721/1000\n",
      "2/2 - 0s - loss: 109295.0469 - val_loss: 122287.8516\n",
      "Epoch 722/1000\n",
      "2/2 - 0s - loss: 109292.9766 - val_loss: 122286.5391\n",
      "Epoch 723/1000\n",
      "2/2 - 0s - loss: 109290.9531 - val_loss: 122285.2344\n",
      "Epoch 724/1000\n",
      "2/2 - 0s - loss: 109288.8906 - val_loss: 122283.9531\n",
      "Epoch 725/1000\n",
      "2/2 - 0s - loss: 109286.8281 - val_loss: 122282.6406\n",
      "Epoch 726/1000\n",
      "2/2 - 0s - loss: 109284.7891 - val_loss: 122281.3281\n",
      "Epoch 727/1000\n",
      "2/2 - 0s - loss: 109282.7031 - val_loss: 122279.9766\n",
      "Epoch 728/1000\n",
      "2/2 - 0s - loss: 109280.6641 - val_loss: 122278.6484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "2/2 - 0s - loss: 109278.5625 - val_loss: 122277.3594\n",
      "Epoch 730/1000\n",
      "2/2 - 0s - loss: 109276.5469 - val_loss: 122276.1016\n",
      "Epoch 731/1000\n",
      "2/2 - 0s - loss: 109274.4531 - val_loss: 122274.8281\n",
      "Epoch 732/1000\n",
      "2/2 - 0s - loss: 109272.3594 - val_loss: 122273.5469\n",
      "Epoch 733/1000\n",
      "2/2 - 0s - loss: 109270.2109 - val_loss: 122272.2891\n",
      "Epoch 734/1000\n",
      "2/2 - 0s - loss: 109268.2266 - val_loss: 122271.0156\n",
      "Epoch 735/1000\n",
      "2/2 - 0s - loss: 109266.0625 - val_loss: 122269.7109\n",
      "Epoch 736/1000\n",
      "2/2 - 0s - loss: 109263.9609 - val_loss: 122268.3984\n",
      "Epoch 737/1000\n",
      "2/2 - 0s - loss: 109261.8359 - val_loss: 122267.1016\n",
      "Epoch 738/1000\n",
      "2/2 - 0s - loss: 109259.6875 - val_loss: 122265.8125\n",
      "Epoch 739/1000\n",
      "2/2 - 0s - loss: 109257.6484 - val_loss: 122264.5391\n",
      "Epoch 740/1000\n",
      "2/2 - 0s - loss: 109255.4375 - val_loss: 122263.2344\n",
      "Epoch 741/1000\n",
      "2/2 - 0s - loss: 109253.3125 - val_loss: 122261.9531\n",
      "Epoch 742/1000\n",
      "2/2 - 0s - loss: 109251.1719 - val_loss: 122260.6250\n",
      "Epoch 743/1000\n",
      "2/2 - 0s - loss: 109248.9766 - val_loss: 122259.2969\n",
      "Epoch 744/1000\n",
      "2/2 - 0s - loss: 109246.8594 - val_loss: 122257.9766\n",
      "Epoch 745/1000\n",
      "2/2 - 0s - loss: 109244.6875 - val_loss: 122256.6484\n",
      "Epoch 746/1000\n",
      "2/2 - 0s - loss: 109242.6094 - val_loss: 122255.2969\n",
      "Epoch 747/1000\n",
      "2/2 - 0s - loss: 109240.3750 - val_loss: 122253.9219\n",
      "Epoch 748/1000\n",
      "2/2 - 0s - loss: 109238.2344 - val_loss: 122252.5625\n",
      "Epoch 749/1000\n",
      "2/2 - 0s - loss: 109236.1406 - val_loss: 122251.2031\n",
      "Epoch 750/1000\n",
      "2/2 - 0s - loss: 109234.0469 - val_loss: 122249.8281\n",
      "Epoch 751/1000\n",
      "2/2 - 0s - loss: 109231.8750 - val_loss: 122248.4609\n",
      "Epoch 752/1000\n",
      "2/2 - 0s - loss: 109229.7500 - val_loss: 122247.1094\n",
      "Epoch 753/1000\n",
      "2/2 - 0s - loss: 109227.6094 - val_loss: 122245.7500\n",
      "Epoch 754/1000\n",
      "2/2 - 0s - loss: 109225.4766 - val_loss: 122244.4141\n",
      "Epoch 755/1000\n",
      "2/2 - 0s - loss: 109223.3516 - val_loss: 122243.1016\n",
      "Epoch 756/1000\n",
      "2/2 - 0s - loss: 109221.1875 - val_loss: 122241.7969\n",
      "Epoch 757/1000\n",
      "2/2 - 0s - loss: 109219.0391 - val_loss: 122240.5000\n",
      "Epoch 758/1000\n",
      "2/2 - 0s - loss: 109216.8281 - val_loss: 122239.1641\n",
      "Epoch 759/1000\n",
      "2/2 - 0s - loss: 109214.7344 - val_loss: 122237.8125\n",
      "Epoch 760/1000\n",
      "2/2 - 0s - loss: 109212.5469 - val_loss: 122236.4531\n",
      "Epoch 761/1000\n",
      "2/2 - 0s - loss: 109210.3594 - val_loss: 122235.0781\n",
      "Epoch 762/1000\n",
      "2/2 - 0s - loss: 109208.2266 - val_loss: 122233.7109\n",
      "Epoch 763/1000\n",
      "2/2 - 0s - loss: 109206.1016 - val_loss: 122232.3359\n",
      "Epoch 764/1000\n",
      "2/2 - 0s - loss: 109204.0000 - val_loss: 122230.9531\n",
      "Epoch 765/1000\n",
      "2/2 - 0s - loss: 109201.7969 - val_loss: 122229.5234\n",
      "Epoch 766/1000\n",
      "2/2 - 0s - loss: 109199.7344 - val_loss: 122228.1094\n",
      "Epoch 767/1000\n",
      "2/2 - 0s - loss: 109197.5859 - val_loss: 122226.6719\n",
      "Epoch 768/1000\n",
      "2/2 - 0s - loss: 109195.4609 - val_loss: 122225.2344\n",
      "Epoch 769/1000\n",
      "2/2 - 0s - loss: 109193.3125 - val_loss: 122223.8281\n",
      "Epoch 770/1000\n",
      "2/2 - 0s - loss: 109191.2031 - val_loss: 122222.4375\n",
      "Epoch 771/1000\n",
      "2/2 - 0s - loss: 109189.0391 - val_loss: 122221.0391\n",
      "Epoch 772/1000\n",
      "2/2 - 0s - loss: 109186.8594 - val_loss: 122219.6250\n",
      "Epoch 773/1000\n",
      "2/2 - 0s - loss: 109184.6719 - val_loss: 122218.2031\n",
      "Epoch 774/1000\n",
      "2/2 - 0s - loss: 109182.5156 - val_loss: 122216.7734\n",
      "Epoch 775/1000\n",
      "2/2 - 0s - loss: 109180.3359 - val_loss: 122215.3359\n",
      "Epoch 776/1000\n",
      "2/2 - 0s - loss: 109178.1484 - val_loss: 122213.9141\n",
      "Epoch 777/1000\n",
      "2/2 - 0s - loss: 109175.9766 - val_loss: 122212.5234\n",
      "Epoch 778/1000\n",
      "2/2 - 0s - loss: 109173.7969 - val_loss: 122211.1484\n",
      "Epoch 779/1000\n",
      "2/2 - 0s - loss: 109171.6094 - val_loss: 122209.7734\n",
      "Epoch 780/1000\n",
      "2/2 - 0s - loss: 109169.3750 - val_loss: 122208.3906\n",
      "Epoch 781/1000\n",
      "2/2 - 0s - loss: 109167.1484 - val_loss: 122207.0469\n",
      "Epoch 782/1000\n",
      "2/2 - 0s - loss: 109164.9141 - val_loss: 122205.7266\n",
      "Epoch 783/1000\n",
      "2/2 - 0s - loss: 109162.7031 - val_loss: 122204.3750\n",
      "Epoch 784/1000\n",
      "2/2 - 0s - loss: 109160.4141 - val_loss: 122203.0469\n",
      "Epoch 785/1000\n",
      "2/2 - 0s - loss: 109158.1641 - val_loss: 122201.7344\n",
      "Epoch 786/1000\n",
      "2/2 - 0s - loss: 109155.9609 - val_loss: 122200.3984\n",
      "Epoch 787/1000\n",
      "2/2 - 0s - loss: 109153.7031 - val_loss: 122199.0234\n",
      "Epoch 788/1000\n",
      "2/2 - 0s - loss: 109151.4375 - val_loss: 122197.6484\n",
      "Epoch 789/1000\n",
      "2/2 - 0s - loss: 109149.2656 - val_loss: 122196.2344\n",
      "Epoch 790/1000\n",
      "2/2 - 0s - loss: 109146.9766 - val_loss: 122194.8516\n",
      "Epoch 791/1000\n",
      "2/2 - 0s - loss: 109144.7656 - val_loss: 122193.4609\n",
      "Epoch 792/1000\n",
      "2/2 - 0s - loss: 109142.5469 - val_loss: 122192.0781\n",
      "Epoch 793/1000\n",
      "2/2 - 0s - loss: 109140.2500 - val_loss: 122190.6875\n",
      "Epoch 794/1000\n",
      "2/2 - 0s - loss: 109138.0781 - val_loss: 122189.3281\n",
      "Epoch 795/1000\n",
      "2/2 - 0s - loss: 109135.7109 - val_loss: 122187.9531\n",
      "Epoch 796/1000\n",
      "2/2 - 0s - loss: 109133.4219 - val_loss: 122186.6016\n",
      "Epoch 797/1000\n",
      "2/2 - 0s - loss: 109131.2344 - val_loss: 122185.2344\n",
      "Epoch 798/1000\n",
      "2/2 - 0s - loss: 109128.9219 - val_loss: 122183.8594\n",
      "Epoch 799/1000\n",
      "2/2 - 0s - loss: 109126.7031 - val_loss: 122182.4609\n",
      "Epoch 800/1000\n",
      "2/2 - 0s - loss: 109124.3594 - val_loss: 122181.0469\n",
      "Epoch 801/1000\n",
      "2/2 - 0s - loss: 109122.2266 - val_loss: 122179.6250\n",
      "Epoch 802/1000\n",
      "2/2 - 0s - loss: 109119.8594 - val_loss: 122178.1875\n",
      "Epoch 803/1000\n",
      "2/2 - 0s - loss: 109117.6016 - val_loss: 122176.7734\n",
      "Epoch 804/1000\n",
      "2/2 - 0s - loss: 109115.3906 - val_loss: 122175.3516\n",
      "Epoch 805/1000\n",
      "2/2 - 0s - loss: 109113.0625 - val_loss: 122173.9375\n",
      "Epoch 806/1000\n",
      "2/2 - 0s - loss: 109110.7969 - val_loss: 122172.5234\n",
      "Epoch 807/1000\n",
      "2/2 - 0s - loss: 109108.4844 - val_loss: 122171.1250\n",
      "Epoch 808/1000\n",
      "2/2 - 0s - loss: 109106.1719 - val_loss: 122169.7266\n",
      "Epoch 809/1000\n",
      "2/2 - 0s - loss: 109104.0156 - val_loss: 122168.3125\n",
      "Epoch 810/1000\n",
      "2/2 - 0s - loss: 109101.6641 - val_loss: 122166.8516\n",
      "Epoch 811/1000\n",
      "2/2 - 0s - loss: 109099.4375 - val_loss: 122165.4141\n",
      "Epoch 812/1000\n",
      "2/2 - 0s - loss: 109097.2266 - val_loss: 122163.9531\n",
      "Epoch 813/1000\n",
      "2/2 - 0s - loss: 109094.9844 - val_loss: 122162.4766\n",
      "Epoch 814/1000\n",
      "2/2 - 0s - loss: 109092.7500 - val_loss: 122161.0156\n",
      "Epoch 815/1000\n",
      "2/2 - 0s - loss: 109090.6016 - val_loss: 122159.5469\n",
      "Epoch 816/1000\n",
      "2/2 - 0s - loss: 109088.2969 - val_loss: 122158.0781\n",
      "Epoch 817/1000\n",
      "2/2 - 0s - loss: 109086.0781 - val_loss: 122156.6250\n",
      "Epoch 818/1000\n",
      "2/2 - 0s - loss: 109083.7891 - val_loss: 122155.1719\n",
      "Epoch 819/1000\n",
      "2/2 - 0s - loss: 109081.5391 - val_loss: 122153.7500\n",
      "Epoch 820/1000\n",
      "2/2 - 0s - loss: 109079.2344 - val_loss: 122152.3516\n",
      "Epoch 821/1000\n",
      "2/2 - 0s - loss: 109076.9844 - val_loss: 122150.9609\n",
      "Epoch 822/1000\n",
      "2/2 - 0s - loss: 109074.6484 - val_loss: 122149.5625\n",
      "Epoch 823/1000\n",
      "2/2 - 0s - loss: 109072.3750 - val_loss: 122148.1484\n",
      "Epoch 824/1000\n",
      "2/2 - 0s - loss: 109070.0781 - val_loss: 122146.7344\n",
      "Epoch 825/1000\n",
      "2/2 - 0s - loss: 109067.7891 - val_loss: 122145.3281\n",
      "Epoch 826/1000\n",
      "2/2 - 0s - loss: 109065.4609 - val_loss: 122143.9141\n",
      "Epoch 827/1000\n",
      "2/2 - 0s - loss: 109063.1719 - val_loss: 122142.4844\n",
      "Epoch 828/1000\n",
      "2/2 - 0s - loss: 109060.8984 - val_loss: 122141.0469\n",
      "Epoch 829/1000\n",
      "2/2 - 0s - loss: 109058.6094 - val_loss: 122139.6094\n",
      "Epoch 830/1000\n",
      "2/2 - 0s - loss: 109056.3281 - val_loss: 122138.1719\n",
      "Epoch 831/1000\n",
      "2/2 - 0s - loss: 109054.1406 - val_loss: 122136.7031\n",
      "Epoch 832/1000\n",
      "2/2 - 0s - loss: 109051.8281 - val_loss: 122135.2031\n",
      "Epoch 833/1000\n",
      "2/2 - 0s - loss: 109049.6016 - val_loss: 122133.7344\n",
      "Epoch 834/1000\n",
      "2/2 - 0s - loss: 109047.3281 - val_loss: 122132.2734\n",
      "Epoch 835/1000\n",
      "2/2 - 0s - loss: 109045.0469 - val_loss: 122130.8359\n",
      "Epoch 836/1000\n",
      "2/2 - 0s - loss: 109042.7266 - val_loss: 122129.4219\n",
      "Epoch 837/1000\n",
      "2/2 - 0s - loss: 109040.3750 - val_loss: 122128.0234\n",
      "Epoch 838/1000\n",
      "2/2 - 0s - loss: 109038.0469 - val_loss: 122126.6094\n",
      "Epoch 839/1000\n",
      "2/2 - 0s - loss: 109035.7031 - val_loss: 122125.2031\n",
      "Epoch 840/1000\n",
      "2/2 - 0s - loss: 109033.3359 - val_loss: 122123.7500\n",
      "Epoch 841/1000\n",
      "2/2 - 0s - loss: 109030.9375 - val_loss: 122122.2969\n",
      "Epoch 842/1000\n",
      "2/2 - 0s - loss: 109028.6250 - val_loss: 122120.8516\n",
      "Epoch 843/1000\n",
      "2/2 - 0s - loss: 109026.2891 - val_loss: 122119.3906\n",
      "Epoch 844/1000\n",
      "2/2 - 0s - loss: 109023.8906 - val_loss: 122117.8984\n",
      "Epoch 845/1000\n",
      "2/2 - 0s - loss: 109021.5625 - val_loss: 122116.4375\n",
      "Epoch 846/1000\n",
      "2/2 - 0s - loss: 109019.2031 - val_loss: 122114.9766\n",
      "Epoch 847/1000\n",
      "2/2 - 0s - loss: 109016.8594 - val_loss: 122113.5234\n",
      "Epoch 848/1000\n",
      "2/2 - 0s - loss: 109014.4609 - val_loss: 122112.0781\n",
      "Epoch 849/1000\n",
      "2/2 - 0s - loss: 109012.2031 - val_loss: 122110.6094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850/1000\n",
      "2/2 - 0s - loss: 109009.7891 - val_loss: 122109.1016\n",
      "Epoch 851/1000\n",
      "2/2 - 0s - loss: 109007.4766 - val_loss: 122107.5859\n",
      "Epoch 852/1000\n",
      "2/2 - 0s - loss: 109005.1484 - val_loss: 122106.0391\n",
      "Epoch 853/1000\n",
      "2/2 - 0s - loss: 109002.7891 - val_loss: 122104.4766\n",
      "Epoch 854/1000\n",
      "2/2 - 0s - loss: 109000.4844 - val_loss: 122102.9219\n",
      "Epoch 855/1000\n",
      "2/2 - 0s - loss: 108998.1719 - val_loss: 122101.3750\n",
      "Epoch 856/1000\n",
      "2/2 - 0s - loss: 108995.7891 - val_loss: 122099.8359\n",
      "Epoch 857/1000\n",
      "2/2 - 0s - loss: 108993.4766 - val_loss: 122098.3281\n",
      "Epoch 858/1000\n",
      "2/2 - 0s - loss: 108991.0234 - val_loss: 122096.8281\n",
      "Epoch 859/1000\n",
      "2/2 - 0s - loss: 108988.6719 - val_loss: 122095.3750\n",
      "Epoch 860/1000\n",
      "2/2 - 0s - loss: 108986.2109 - val_loss: 122093.9219\n",
      "Epoch 861/1000\n",
      "2/2 - 0s - loss: 108983.7500 - val_loss: 122092.4766\n",
      "Epoch 862/1000\n",
      "2/2 - 0s - loss: 108981.3359 - val_loss: 122091.0234\n",
      "Epoch 863/1000\n",
      "2/2 - 0s - loss: 108978.8750 - val_loss: 122089.5781\n",
      "Epoch 864/1000\n",
      "2/2 - 0s - loss: 108976.3984 - val_loss: 122088.1016\n",
      "Epoch 865/1000\n",
      "2/2 - 0s - loss: 108974.0000 - val_loss: 122086.6016\n",
      "Epoch 866/1000\n",
      "2/2 - 0s - loss: 108971.5859 - val_loss: 122085.1016\n",
      "Epoch 867/1000\n",
      "2/2 - 0s - loss: 108969.1641 - val_loss: 122083.6016\n",
      "Epoch 868/1000\n",
      "2/2 - 0s - loss: 108966.6719 - val_loss: 122082.1094\n",
      "Epoch 869/1000\n",
      "2/2 - 0s - loss: 108964.3516 - val_loss: 122080.6641\n",
      "Epoch 870/1000\n",
      "2/2 - 0s - loss: 108961.9141 - val_loss: 122079.2031\n",
      "Epoch 871/1000\n",
      "2/2 - 0s - loss: 108959.4531 - val_loss: 122077.7109\n",
      "Epoch 872/1000\n",
      "2/2 - 0s - loss: 108957.0781 - val_loss: 122076.2344\n",
      "Epoch 873/1000\n",
      "2/2 - 0s - loss: 108954.6641 - val_loss: 122074.7500\n",
      "Epoch 874/1000\n",
      "2/2 - 0s - loss: 108952.2500 - val_loss: 122073.2344\n",
      "Epoch 875/1000\n",
      "2/2 - 0s - loss: 108949.8281 - val_loss: 122071.7109\n",
      "Epoch 876/1000\n",
      "2/2 - 0s - loss: 108947.4375 - val_loss: 122070.1719\n",
      "Epoch 877/1000\n",
      "2/2 - 0s - loss: 108945.0000 - val_loss: 122068.5859\n",
      "Epoch 878/1000\n",
      "2/2 - 0s - loss: 108942.6016 - val_loss: 122067.0234\n",
      "Epoch 879/1000\n",
      "2/2 - 0s - loss: 108940.2031 - val_loss: 122065.4531\n",
      "Epoch 880/1000\n",
      "2/2 - 0s - loss: 108937.8281 - val_loss: 122063.8750\n",
      "Epoch 881/1000\n",
      "2/2 - 0s - loss: 108935.3750 - val_loss: 122062.3125\n",
      "Epoch 882/1000\n",
      "2/2 - 0s - loss: 108933.0000 - val_loss: 122060.7734\n",
      "Epoch 883/1000\n",
      "2/2 - 0s - loss: 108930.5781 - val_loss: 122059.2656\n",
      "Epoch 884/1000\n",
      "2/2 - 0s - loss: 108928.1250 - val_loss: 122057.7266\n",
      "Epoch 885/1000\n",
      "2/2 - 0s - loss: 108925.7266 - val_loss: 122056.1875\n",
      "Epoch 886/1000\n",
      "2/2 - 0s - loss: 108923.2500 - val_loss: 122054.6250\n",
      "Epoch 887/1000\n",
      "2/2 - 0s - loss: 108920.8359 - val_loss: 122053.0781\n",
      "Epoch 888/1000\n",
      "2/2 - 0s - loss: 108918.3984 - val_loss: 122051.5234\n",
      "Epoch 889/1000\n",
      "2/2 - 0s - loss: 108915.9219 - val_loss: 122049.9844\n",
      "Epoch 890/1000\n",
      "2/2 - 0s - loss: 108913.4219 - val_loss: 122048.4531\n",
      "Epoch 891/1000\n",
      "2/2 - 0s - loss: 108910.9531 - val_loss: 122046.9766\n",
      "Epoch 892/1000\n",
      "2/2 - 0s - loss: 108908.4766 - val_loss: 122045.5000\n",
      "Epoch 893/1000\n",
      "2/2 - 0s - loss: 108905.9531 - val_loss: 122044.0156\n",
      "Epoch 894/1000\n",
      "2/2 - 0s - loss: 108903.4609 - val_loss: 122042.5000\n",
      "Epoch 895/1000\n",
      "2/2 - 0s - loss: 108900.9531 - val_loss: 122040.9844\n",
      "Epoch 896/1000\n",
      "2/2 - 0s - loss: 108898.4609 - val_loss: 122039.5000\n",
      "Epoch 897/1000\n",
      "2/2 - 0s - loss: 108896.0391 - val_loss: 122037.9844\n",
      "Epoch 898/1000\n",
      "2/2 - 0s - loss: 108893.4766 - val_loss: 122036.4531\n",
      "Epoch 899/1000\n",
      "2/2 - 0s - loss: 108891.1016 - val_loss: 122034.9141\n",
      "Epoch 900/1000\n",
      "2/2 - 0s - loss: 108888.5625 - val_loss: 122033.3750\n",
      "Epoch 901/1000\n",
      "2/2 - 0s - loss: 108886.1484 - val_loss: 122031.8359\n",
      "Epoch 902/1000\n",
      "2/2 - 0s - loss: 108883.6484 - val_loss: 122030.2891\n",
      "Epoch 903/1000\n",
      "2/2 - 0s - loss: 108881.2344 - val_loss: 122028.7344\n",
      "Epoch 904/1000\n",
      "2/2 - 0s - loss: 108878.7500 - val_loss: 122027.1641\n",
      "Epoch 905/1000\n",
      "2/2 - 0s - loss: 108876.2969 - val_loss: 122025.5859\n",
      "Epoch 906/1000\n",
      "2/2 - 0s - loss: 108873.7969 - val_loss: 122024.0000\n",
      "Epoch 907/1000\n",
      "2/2 - 0s - loss: 108871.4141 - val_loss: 122022.4531\n",
      "Epoch 908/1000\n",
      "2/2 - 0s - loss: 108868.8359 - val_loss: 122020.9141\n",
      "Epoch 909/1000\n",
      "2/2 - 0s - loss: 108866.4375 - val_loss: 122019.3750\n",
      "Epoch 910/1000\n",
      "2/2 - 0s - loss: 108863.8984 - val_loss: 122017.7969\n",
      "Epoch 911/1000\n",
      "2/2 - 0s - loss: 108861.4219 - val_loss: 122016.2500\n",
      "Epoch 912/1000\n",
      "2/2 - 0s - loss: 108858.8984 - val_loss: 122014.6875\n",
      "Epoch 913/1000\n",
      "2/2 - 0s - loss: 108856.4375 - val_loss: 122013.1484\n",
      "Epoch 914/1000\n",
      "2/2 - 0s - loss: 108853.9531 - val_loss: 122011.6016\n",
      "Epoch 915/1000\n",
      "2/2 - 0s - loss: 108851.3516 - val_loss: 122010.0391\n",
      "Epoch 916/1000\n",
      "2/2 - 0s - loss: 108848.9531 - val_loss: 122008.4766\n",
      "Epoch 917/1000\n",
      "2/2 - 0s - loss: 108846.3984 - val_loss: 122006.8984\n",
      "Epoch 918/1000\n",
      "2/2 - 0s - loss: 108843.8359 - val_loss: 122005.3281\n",
      "Epoch 919/1000\n",
      "2/2 - 0s - loss: 108841.3594 - val_loss: 122003.7500\n",
      "Epoch 920/1000\n",
      "2/2 - 0s - loss: 108838.8906 - val_loss: 122002.1719\n",
      "Epoch 921/1000\n",
      "2/2 - 0s - loss: 108836.3125 - val_loss: 122000.6250\n",
      "Epoch 922/1000\n",
      "2/2 - 0s - loss: 108833.8359 - val_loss: 121999.0469\n",
      "Epoch 923/1000\n",
      "2/2 - 0s - loss: 108831.3281 - val_loss: 121997.4766\n",
      "Epoch 924/1000\n",
      "2/2 - 0s - loss: 108828.8516 - val_loss: 121995.8516\n",
      "Epoch 925/1000\n",
      "2/2 - 0s - loss: 108826.3516 - val_loss: 121994.2500\n",
      "Epoch 926/1000\n",
      "2/2 - 0s - loss: 108823.8281 - val_loss: 121992.6250\n",
      "Epoch 927/1000\n",
      "2/2 - 0s - loss: 108821.3516 - val_loss: 121991.0469\n",
      "Epoch 928/1000\n",
      "2/2 - 0s - loss: 108818.9531 - val_loss: 121989.5000\n",
      "Epoch 929/1000\n",
      "2/2 - 0s - loss: 108816.3359 - val_loss: 121987.9375\n",
      "Epoch 930/1000\n",
      "2/2 - 0s - loss: 108813.7969 - val_loss: 121986.3906\n",
      "Epoch 931/1000\n",
      "2/2 - 0s - loss: 108811.3125 - val_loss: 121984.8516\n",
      "Epoch 932/1000\n",
      "2/2 - 0s - loss: 108808.7109 - val_loss: 121983.2891\n",
      "Epoch 933/1000\n",
      "2/2 - 0s - loss: 108806.2500 - val_loss: 121981.7266\n",
      "Epoch 934/1000\n",
      "2/2 - 0s - loss: 108803.7031 - val_loss: 121980.1875\n",
      "Epoch 935/1000\n",
      "2/2 - 0s - loss: 108801.1719 - val_loss: 121978.6016\n",
      "Epoch 936/1000\n",
      "2/2 - 0s - loss: 108798.6719 - val_loss: 121977.0156\n",
      "Epoch 937/1000\n",
      "2/2 - 0s - loss: 108796.1406 - val_loss: 121975.4141\n",
      "Epoch 938/1000\n",
      "2/2 - 0s - loss: 108793.6094 - val_loss: 121973.8281\n",
      "Epoch 939/1000\n",
      "2/2 - 0s - loss: 108791.1016 - val_loss: 121972.2344\n",
      "Epoch 940/1000\n",
      "2/2 - 0s - loss: 108788.5469 - val_loss: 121970.6641\n",
      "Epoch 941/1000\n",
      "2/2 - 0s - loss: 108786.0469 - val_loss: 121969.1094\n",
      "Epoch 942/1000\n",
      "2/2 - 0s - loss: 108783.4531 - val_loss: 121967.5625\n",
      "Epoch 943/1000\n",
      "2/2 - 0s - loss: 108780.8516 - val_loss: 121966.0234\n",
      "Epoch 944/1000\n",
      "2/2 - 0s - loss: 108778.2344 - val_loss: 121964.4844\n",
      "Epoch 945/1000\n",
      "2/2 - 0s - loss: 108775.7266 - val_loss: 121962.9375\n",
      "Epoch 946/1000\n",
      "2/2 - 0s - loss: 108773.0859 - val_loss: 121961.3750\n",
      "Epoch 947/1000\n",
      "2/2 - 0s - loss: 108770.4766 - val_loss: 121959.7969\n",
      "Epoch 948/1000\n",
      "2/2 - 0s - loss: 108767.9375 - val_loss: 121958.1875\n",
      "Epoch 949/1000\n",
      "2/2 - 0s - loss: 108765.3359 - val_loss: 121956.5781\n",
      "Epoch 950/1000\n",
      "2/2 - 0s - loss: 108762.7969 - val_loss: 121954.9766\n",
      "Epoch 951/1000\n",
      "2/2 - 0s - loss: 108760.2344 - val_loss: 121953.3516\n",
      "Epoch 952/1000\n",
      "2/2 - 0s - loss: 108757.6875 - val_loss: 121951.7500\n",
      "Epoch 953/1000\n",
      "2/2 - 0s - loss: 108755.1094 - val_loss: 121950.1484\n",
      "Epoch 954/1000\n",
      "2/2 - 0s - loss: 108752.5859 - val_loss: 121948.5625\n",
      "Epoch 955/1000\n",
      "2/2 - 0s - loss: 108749.9609 - val_loss: 121946.9766\n",
      "Epoch 956/1000\n",
      "2/2 - 0s - loss: 108747.3750 - val_loss: 121945.3594\n",
      "Epoch 957/1000\n",
      "2/2 - 0s - loss: 108744.8281 - val_loss: 121943.7344\n",
      "Epoch 958/1000\n",
      "2/2 - 0s - loss: 108742.1641 - val_loss: 121942.0859\n",
      "Epoch 959/1000\n",
      "2/2 - 0s - loss: 108739.6484 - val_loss: 121940.4531\n",
      "Epoch 960/1000\n",
      "2/2 - 0s - loss: 108737.0156 - val_loss: 121938.8359\n",
      "Epoch 961/1000\n",
      "2/2 - 0s - loss: 108734.4609 - val_loss: 121937.2344\n",
      "Epoch 962/1000\n",
      "2/2 - 0s - loss: 108731.8984 - val_loss: 121935.6406\n",
      "Epoch 963/1000\n",
      "2/2 - 0s - loss: 108729.2734 - val_loss: 121934.0234\n",
      "Epoch 964/1000\n",
      "2/2 - 0s - loss: 108726.7500 - val_loss: 121932.4219\n",
      "Epoch 965/1000\n",
      "2/2 - 0s - loss: 108724.1641 - val_loss: 121930.8125\n",
      "Epoch 966/1000\n",
      "2/2 - 0s - loss: 108721.5234 - val_loss: 121929.1484\n",
      "Epoch 967/1000\n",
      "2/2 - 0s - loss: 108719.0234 - val_loss: 121927.5000\n",
      "Epoch 968/1000\n",
      "2/2 - 0s - loss: 108716.4219 - val_loss: 121925.8359\n",
      "Epoch 969/1000\n",
      "2/2 - 0s - loss: 108713.8125 - val_loss: 121924.2031\n",
      "Epoch 970/1000\n",
      "2/2 - 0s - loss: 108711.2031 - val_loss: 121922.5781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 971/1000\n",
      "2/2 - 0s - loss: 108708.5859 - val_loss: 121920.9844\n",
      "Epoch 972/1000\n",
      "2/2 - 0s - loss: 108706.0469 - val_loss: 121919.3516\n",
      "Epoch 973/1000\n",
      "2/2 - 0s - loss: 108703.3516 - val_loss: 121917.7031\n",
      "Epoch 974/1000\n",
      "2/2 - 0s - loss: 108700.7734 - val_loss: 121916.0469\n",
      "Epoch 975/1000\n",
      "2/2 - 0s - loss: 108698.1484 - val_loss: 121914.3750\n",
      "Epoch 976/1000\n",
      "2/2 - 0s - loss: 108695.5469 - val_loss: 121912.6719\n",
      "Epoch 977/1000\n",
      "2/2 - 0s - loss: 108692.9531 - val_loss: 121910.9844\n",
      "Epoch 978/1000\n",
      "2/2 - 0s - loss: 108690.2969 - val_loss: 121909.3516\n",
      "Epoch 979/1000\n",
      "2/2 - 0s - loss: 108687.7734 - val_loss: 121907.7734\n",
      "Epoch 980/1000\n",
      "2/2 - 0s - loss: 108685.0781 - val_loss: 121906.1719\n",
      "Epoch 981/1000\n",
      "2/2 - 0s - loss: 108682.4844 - val_loss: 121904.6016\n",
      "Epoch 982/1000\n",
      "2/2 - 0s - loss: 108679.8281 - val_loss: 121903.0234\n",
      "Epoch 983/1000\n",
      "2/2 - 0s - loss: 108677.1484 - val_loss: 121901.4219\n",
      "Epoch 984/1000\n",
      "2/2 - 0s - loss: 108674.5625 - val_loss: 121899.8359\n",
      "Epoch 985/1000\n",
      "2/2 - 0s - loss: 108671.8516 - val_loss: 121898.2344\n",
      "Epoch 986/1000\n",
      "2/2 - 0s - loss: 108669.2734 - val_loss: 121896.6094\n",
      "Epoch 987/1000\n",
      "2/2 - 0s - loss: 108666.5469 - val_loss: 121894.9609\n",
      "Epoch 988/1000\n",
      "2/2 - 0s - loss: 108663.8984 - val_loss: 121893.3359\n",
      "Epoch 989/1000\n",
      "2/2 - 0s - loss: 108661.3281 - val_loss: 121891.7031\n",
      "Epoch 990/1000\n",
      "2/2 - 0s - loss: 108658.6641 - val_loss: 121890.0625\n",
      "Epoch 991/1000\n",
      "2/2 - 0s - loss: 108655.9219 - val_loss: 121888.4219\n",
      "Epoch 992/1000\n",
      "2/2 - 0s - loss: 108653.3516 - val_loss: 121886.7969\n",
      "Epoch 993/1000\n",
      "2/2 - 0s - loss: 108650.6875 - val_loss: 121885.1641\n",
      "Epoch 994/1000\n",
      "2/2 - 0s - loss: 108648.0234 - val_loss: 121883.5469\n",
      "Epoch 995/1000\n",
      "2/2 - 0s - loss: 108645.3984 - val_loss: 121881.8984\n",
      "Epoch 996/1000\n",
      "2/2 - 0s - loss: 108642.7344 - val_loss: 121880.2734\n",
      "Epoch 997/1000\n",
      "2/2 - 0s - loss: 108640.0859 - val_loss: 121878.6484\n",
      "Epoch 998/1000\n",
      "2/2 - 0s - loss: 108637.4609 - val_loss: 121877.0156\n",
      "Epoch 999/1000\n",
      "2/2 - 0s - loss: 108634.7891 - val_loss: 121875.3906\n",
      "Epoch 1000/1000\n",
      "2/2 - 0s - loss: 108632.1406 - val_loss: 121873.7734\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train, batch_size=32, validation_data=(X_test,y_test), epochs=1000,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('history: the CNN model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.54718281142132"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121873.78505249023"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16146062530.320782"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917097725977628"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [100]\n",
    "y_pred = [98]\n",
    "mean_absolute_percentage_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1 = ct.transform([[66242, 182987, 119317,'Mumbai']])\n",
    "x1 = scaler.fit_transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = model.predict(x1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853.3823\n"
     ]
    }
   ],
   "source": [
    "print(y1[0][0])  #list value  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('w123.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(128, input_dim=6, activation='relu'))\n",
    "model2.add(Dense(1,activation='linear'))\n",
    "model2.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('w123.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/quantbruce/real-estate-price-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/swathiachath/kc-housesales-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
