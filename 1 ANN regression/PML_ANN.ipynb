{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Gujrat_company.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166088</td>\n",
       "      <td>137066</td>\n",
       "      <td>473515</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>193764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164221</td>\n",
       "      <td>151682</td>\n",
       "      <td>444422</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>192874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154825</td>\n",
       "      <td>101988</td>\n",
       "      <td>409251</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>191413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144984</td>\n",
       "      <td>119498</td>\n",
       "      <td>386151</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>184043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142519</td>\n",
       "      <td>92208</td>\n",
       "      <td>366170</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>167144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131942</td>\n",
       "      <td>100146</td>\n",
       "      <td>365747</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>158459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135336</td>\n",
       "      <td>148073</td>\n",
       "      <td>128445</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>157582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>131104</td>\n",
       "      <td>146268</td>\n",
       "      <td>326036</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>157289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120624</td>\n",
       "      <td>150191</td>\n",
       "      <td>314293</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>152863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123421</td>\n",
       "      <td>108937</td>\n",
       "      <td>307104</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>150693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>102225</td>\n",
       "      <td>111280</td>\n",
       "      <td>230666</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>147102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101241</td>\n",
       "      <td>92129</td>\n",
       "      <td>251598</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>144759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>94132</td>\n",
       "      <td>127942</td>\n",
       "      <td>252182</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>142902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>92833</td>\n",
       "      <td>135650</td>\n",
       "      <td>254301</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>135620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>121142</td>\n",
       "      <td>156572</td>\n",
       "      <td>257267</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>133676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114899</td>\n",
       "      <td>122697</td>\n",
       "      <td>263570</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>130208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78165</td>\n",
       "      <td>122100</td>\n",
       "      <td>265992</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>127296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>95171</td>\n",
       "      <td>145826</td>\n",
       "      <td>285162</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>125761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>92274</td>\n",
       "      <td>114650</td>\n",
       "      <td>295120</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>124641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86980</td>\n",
       "      <td>154274</td>\n",
       "      <td>0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76302</td>\n",
       "      <td>114054</td>\n",
       "      <td>299501</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>118557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>79091</td>\n",
       "      <td>154417</td>\n",
       "      <td>301627</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>111966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74601</td>\n",
       "      <td>123075</td>\n",
       "      <td>305008</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>110563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>68101</td>\n",
       "      <td>106529</td>\n",
       "      <td>305586</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>109728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77361</td>\n",
       "      <td>99668</td>\n",
       "      <td>140740</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>109034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64877</td>\n",
       "      <td>140427</td>\n",
       "      <td>139008</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>108165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75382</td>\n",
       "      <td>144998</td>\n",
       "      <td>134403</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>106090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72369</td>\n",
       "      <td>129077</td>\n",
       "      <td>353495</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>105642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66242</td>\n",
       "      <td>182987</td>\n",
       "      <td>119317</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>103287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65806</td>\n",
       "      <td>154314</td>\n",
       "      <td>108172</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>101363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>62212</td>\n",
       "      <td>116037</td>\n",
       "      <td>91970</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61289</td>\n",
       "      <td>153138</td>\n",
       "      <td>88291</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>98434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63911</td>\n",
       "      <td>129814</td>\n",
       "      <td>46183</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>97685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55769</td>\n",
       "      <td>103437</td>\n",
       "      <td>215182</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>97164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46480</td>\n",
       "      <td>157740</td>\n",
       "      <td>212606</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>96797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46087</td>\n",
       "      <td>85789</td>\n",
       "      <td>206619</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>97311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28902</td>\n",
       "      <td>127907</td>\n",
       "      <td>202816</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>91468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44309</td>\n",
       "      <td>51314</td>\n",
       "      <td>197133</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>90178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20388</td>\n",
       "      <td>66266</td>\n",
       "      <td>185364</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>81572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38605</td>\n",
       "      <td>83210</td>\n",
       "      <td>175654</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>81232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28797</td>\n",
       "      <td>119599</td>\n",
       "      <td>173187</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>78954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>28015</td>\n",
       "      <td>85495</td>\n",
       "      <td>165658</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>78045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23653</td>\n",
       "      <td>96801</td>\n",
       "      <td>148772</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>71747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15656</td>\n",
       "      <td>127558</td>\n",
       "      <td>35869</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>70420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22359</td>\n",
       "      <td>156023</td>\n",
       "      <td>28484</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>65398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1004</td>\n",
       "      <td>125278</td>\n",
       "      <td>1908</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>65168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1326</td>\n",
       "      <td>116956</td>\n",
       "      <td>298874</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>49528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>136264</td>\n",
       "      <td>0</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>42854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>545</td>\n",
       "      <td>51974</td>\n",
       "      <td>0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>35955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>117699</td>\n",
       "      <td>45190</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>14797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend      State  Profit\n",
       "0      166088          137066           473515     Mumbai  193764\n",
       "1      164221          151682           444422   Banglore  192874\n",
       "2      154825          101988           409251  Ahmedabad  191413\n",
       "3      144984          119498           386151     Mumbai  184043\n",
       "4      142519           92208           366170  Ahmedabad  167144\n",
       "5      131942          100146           365747     Mumbai  158459\n",
       "6      135336          148073           128445   Banglore  157582\n",
       "7      131104          146268           326036  Ahmedabad  157289\n",
       "8      120624          150191           314293     Mumbai  152863\n",
       "9      123421          108937           307104   Banglore  150693\n",
       "10     102225          111280           230666  Ahmedabad  147102\n",
       "11     101241           92129           251598   Banglore  144759\n",
       "12      94132          127942           252182  Ahmedabad  142902\n",
       "13      92833          135650           254301   Banglore  135620\n",
       "14     121142          156572           257267  Ahmedabad  133676\n",
       "15     114899          122697           263570     Mumbai  130208\n",
       "16      78165          122100           265992   Banglore  127296\n",
       "17      95171          145826           285162     Mumbai  125761\n",
       "18      92274          114650           295120  Ahmedabad  124641\n",
       "19      86980          154274                0     Mumbai  123600\n",
       "20      76302          114054           299501   Banglore  118557\n",
       "21      79091          154417           301627     Mumbai  111966\n",
       "22      74601          123075           305008  Ahmedabad  110563\n",
       "23      68101          106529           305586  Ahmedabad  109728\n",
       "24      77361           99668           140740     Mumbai  109034\n",
       "25      64877          140427           139008   Banglore  108165\n",
       "26      75382          144998           134403  Ahmedabad  106090\n",
       "27      72369          129077           353495     Mumbai  105642\n",
       "28      66242          182987           119317  Ahmedabad  103287\n",
       "29      65806          154314           108172     Mumbai  101363\n",
       "30      62212          116037            91970  Ahmedabad  100004\n",
       "31      61289          153138            88291     Mumbai   98434\n",
       "32      63911          129814            46183   Banglore   97685\n",
       "33      55769          103437           215182  Ahmedabad   97164\n",
       "34      46480          157740           212606   Banglore   96797\n",
       "35      46087           85789           206619     Mumbai   97311\n",
       "36      28902          127907           202816  Ahmedabad   91468\n",
       "37      44309           51314           197133   Banglore   90178\n",
       "38      20388           66266           185364     Mumbai   81572\n",
       "39      38605           83210           175654   Banglore   81232\n",
       "40      28797          119599           173187   Banglore   78954\n",
       "41      28015           85495           165658  Ahmedabad   78045\n",
       "42      23653           96801           148772   Banglore   71747\n",
       "43      15656          127558            35869     Mumbai   70420\n",
       "44      22359          156023            28484   Banglore   65398\n",
       "45       1004          125278             1908     Mumbai   65168\n",
       "46       1326          116956           298874  Ahmedabad   49528\n",
       "47          0          136264                0   Banglore   42854\n",
       "48        545           51974                0     Mumbai   35955\n",
       "49          0          117699            45190   Banglore   14797"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = dataset.iloc[:,0:4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[166088, 137066, 473515, 'Mumbai'],\n",
       "       [164221, 151682, 444422, 'Banglore'],\n",
       "       [154825, 101988, 409251, 'Ahmedabad'],\n",
       "       [144984, 119498, 386151, 'Mumbai'],\n",
       "       [142519, 92208, 366170, 'Ahmedabad'],\n",
       "       [131942, 100146, 365747, 'Mumbai'],\n",
       "       [135336, 148073, 128445, 'Banglore'],\n",
       "       [131104, 146268, 326036, 'Ahmedabad'],\n",
       "       [120624, 150191, 314293, 'Mumbai'],\n",
       "       [123421, 108937, 307104, 'Banglore']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([193764, 192874, 191413, 184043, 167144, 158459, 157582, 157289,\n",
       "       152863, 150693], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding for the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder =  OneHotEncoder()\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder',encoder, [3])], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 166088, 137066, 473515],\n",
       "       [0.0, 1.0, 0.0, 164221, 151682, 444422],\n",
       "       [1.0, 0.0, 0.0, 154825, 101988, 409251],\n",
       "       [0.0, 0.0, 1.0, 144984, 119498, 386151],\n",
       "       [1.0, 0.0, 0.0, 142519, 92208, 366170],\n",
       "       [0.0, 0.0, 1.0, 131942, 100146, 365747],\n",
       "       [0.0, 1.0, 0.0, 135336, 148073, 128445],\n",
       "       [1.0, 0.0, 0.0, 131104, 146268, 326036],\n",
       "       [0.0, 0.0, 1.0, 120624, 150191, 314293],\n",
       "       [0.0, 1.0, 0.0, 123421, 108937, 307104]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.68599434 -0.71774056  1.39326109  2.0140025   0.54366019  2.15057805]\n",
      " [-0.68599434  1.39326109 -0.71774056  1.9731388   1.06900519  1.91126466]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.76748518 -0.71715343  1.62195482]\n",
      " [-0.68599434 -0.71774056  1.39326109  1.55209169 -0.08778897  1.43193869]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.49813935 -1.06867739  1.26757885]\n",
      " [-0.68599434 -0.71774056  1.39326109  1.26663676 -0.7833607   1.26409933]\n",
      " [-0.68599434  1.39326109 -0.71774056  1.34092245  0.93928638 -0.687901  ]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.24829515  0.874409    0.93744433]\n",
      " [-0.68599434 -0.71774056  1.39326109  1.01891563  1.01541396  0.84084868]\n",
      " [-0.68599434  1.39326109 -0.71774056  1.08013457 -0.46738452  0.78171336]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.45773797 -0.71774056 -0.71774056 -0.400589   -0.66507182  0.02558078]\n",
      " [-0.68599434 -0.71774056  1.39326109 -0.61250241 -1.29939643 -0.0448568 ]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  0.02868776  0.82876121 -0.63889164]\n",
      " [-0.68599434  1.39326109 -0.71774056 -0.60390067  1.28674876  0.0043911 ]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  0.39840902 -0.26204134  0.6831353 ]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.24829515  0.874409    0.93744433]\n",
      " [ 1.45773797 -0.71774056 -0.71774056  1.03025328  1.24476716  0.37176384]\n",
      " [-0.68599434 -0.71774056  1.39326109 -1.59925019  0.1199624  -1.72876988]\n",
      " [-0.68599434 -0.71774056  1.39326109 -1.60929649 -2.51481386 -1.74446471]\n",
      " [-0.68599434 -0.71774056  1.39326109 -0.18090558  1.16360754 -0.85466277]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=6, activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(loss='mae', optimizer='adam') # metrics=['accuracy','mse', 'mae', 'mape', 'cosine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 110070.7734 - val_loss: 122795.9766\n",
      "Epoch 2/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.7266 - val_loss: 122795.9375\n",
      "Epoch 3/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.7031 - val_loss: 122795.8984\n",
      "Epoch 4/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.6641 - val_loss: 122795.8750\n",
      "Epoch 5/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.6094 - val_loss: 122795.8281\n",
      "Epoch 6/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.5469 - val_loss: 122795.7734\n",
      "Epoch 7/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.5000 - val_loss: 122795.7266\n",
      "Epoch 8/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.4375 - val_loss: 122795.6641\n",
      "Epoch 9/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.3594 - val_loss: 122795.6016\n",
      "Epoch 10/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.2969 - val_loss: 122795.5234\n",
      "Epoch 11/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.1875 - val_loss: 122795.4375\n",
      "Epoch 12/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110070.0859 - val_loss: 122795.3516\n",
      "Epoch 13/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110069.9766 - val_loss: 122795.2500\n",
      "Epoch 14/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110069.8281 - val_loss: 122795.1250\n",
      "Epoch 15/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110069.6719 - val_loss: 122795.0000\n",
      "Epoch 16/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110069.5000 - val_loss: 122794.8359\n",
      "Epoch 17/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110069.2969 - val_loss: 122794.6719\n",
      "Epoch 18/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110069.0781 - val_loss: 122794.4766\n",
      "Epoch 19/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110068.7969 - val_loss: 122794.2500\n",
      "Epoch 20/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110068.5000 - val_loss: 122794.0234\n",
      "Epoch 21/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110068.1719 - val_loss: 122793.7500\n",
      "Epoch 22/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110067.7891 - val_loss: 122793.4375\n",
      "Epoch 23/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110067.3750 - val_loss: 122793.1016\n",
      "Epoch 24/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110066.9141 - val_loss: 122792.6875\n",
      "Epoch 25/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110066.3281 - val_loss: 122792.2344\n",
      "Epoch 26/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110065.7266 - val_loss: 122791.7266\n",
      "Epoch 27/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110065.0391 - val_loss: 122791.1484\n",
      "Epoch 28/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110064.2500 - val_loss: 122790.5000\n",
      "Epoch 29/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110063.3359 - val_loss: 122789.7734\n",
      "Epoch 30/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110062.3281 - val_loss: 122788.9531\n",
      "Epoch 31/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110061.1875 - val_loss: 122788.0000\n",
      "Epoch 32/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110059.8906 - val_loss: 122786.9531\n",
      "Epoch 33/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110058.4844 - val_loss: 122785.7266\n",
      "Epoch 34/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110056.8516 - val_loss: 122784.3594\n",
      "Epoch 35/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110055.0156 - val_loss: 122782.8594\n",
      "Epoch 36/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110053.1016 - val_loss: 122781.2344\n",
      "Epoch 37/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110050.8516 - val_loss: 122779.3906\n",
      "Epoch 38/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110048.4531 - val_loss: 122777.3906\n",
      "Epoch 39/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110045.8594 - val_loss: 122775.2109\n",
      "Epoch 40/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110043.0391 - val_loss: 122772.8594\n",
      "Epoch 41/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110039.7891 - val_loss: 122770.2969\n",
      "Epoch 42/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110036.3984 - val_loss: 122767.4766\n",
      "Epoch 43/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110032.6875 - val_loss: 122764.4141\n",
      "Epoch 44/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110028.7734 - val_loss: 122761.1016\n",
      "Epoch 45/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110024.3516 - val_loss: 122757.5000\n",
      "Epoch 46/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110019.7109 - val_loss: 122753.6719\n",
      "Epoch 47/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110014.6406 - val_loss: 122749.5156\n",
      "Epoch 48/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110009.2109 - val_loss: 122745.0781\n",
      "Epoch 49/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 110003.4844 - val_loss: 122740.5000\n",
      "Epoch 50/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109997.5156 - val_loss: 122735.3594\n",
      "Epoch 51/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109990.7344 - val_loss: 122729.9531\n",
      "Epoch 52/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109983.7500 - val_loss: 122724.2891\n",
      "Epoch 53/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109976.2500 - val_loss: 122718.1719\n",
      "Epoch 54/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109968.4844 - val_loss: 122711.6641\n",
      "Epoch 55/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109959.8594 - val_loss: 122704.7656\n",
      "Epoch 56/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109950.7500 - val_loss: 122697.5234\n",
      "Epoch 57/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109941.3750 - val_loss: 122689.8984\n",
      "Epoch 58/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109931.5234 - val_loss: 122681.5781\n",
      "Epoch 59/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109920.3594 - val_loss: 122673.1484\n",
      "Epoch 60/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109909.5234 - val_loss: 122664.0781\n",
      "Epoch 61/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109897.6875 - val_loss: 122654.3516\n",
      "Epoch 62/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109884.9609 - val_loss: 122644.3281\n",
      "Epoch 63/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109871.5469 - val_loss: 122633.6094\n",
      "Epoch 64/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109858.0469 - val_loss: 122622.3516\n",
      "Epoch 65/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109843.1719 - val_loss: 122610.7344\n",
      "Epoch 66/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109828.0469 - val_loss: 122598.3594\n",
      "Epoch 67/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109812.1719 - val_loss: 122585.5625\n",
      "Epoch 68/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109795.3125 - val_loss: 122571.9531\n",
      "Epoch 69/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109777.6094 - val_loss: 122558.0234\n",
      "Epoch 70/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109759.7031 - val_loss: 122543.1016\n",
      "Epoch 71/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109740.2031 - val_loss: 122527.7031\n",
      "Epoch 72/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109719.9609 - val_loss: 122511.7891\n",
      "Epoch 73/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109699.3125 - val_loss: 122495.3281\n",
      "Epoch 74/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109677.6250 - val_loss: 122477.4844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109654.6250 - val_loss: 122459.5000\n",
      "Epoch 76/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109630.4766 - val_loss: 122440.5000\n",
      "Epoch 77/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109606.0000 - val_loss: 122420.9219\n",
      "Epoch 78/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109580.6094 - val_loss: 122400.5859\n",
      "Epoch 79/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109553.5391 - val_loss: 122379.2734\n",
      "Epoch 80/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109525.5469 - val_loss: 122357.1875\n",
      "Epoch 81/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109496.9766 - val_loss: 122334.1250\n",
      "Epoch 82/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109466.4766 - val_loss: 122310.8516\n",
      "Epoch 83/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109436.5859 - val_loss: 122286.7344\n",
      "Epoch 84/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109403.9141 - val_loss: 122261.2891\n",
      "Epoch 85/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109370.2344 - val_loss: 122235.2500\n",
      "Epoch 86/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109336.2969 - val_loss: 122208.6406\n",
      "Epoch 87/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109302.3594 - val_loss: 122180.8281\n",
      "Epoch 88/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109264.9375 - val_loss: 122151.5625\n",
      "Epoch 89/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109228.1016 - val_loss: 122122.5781\n",
      "Epoch 90/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109188.1875 - val_loss: 122091.9219\n",
      "Epoch 91/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109148.6094 - val_loss: 122060.3750\n",
      "Epoch 92/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109107.5156 - val_loss: 122027.7109\n",
      "Epoch 93/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109064.8516 - val_loss: 121994.4531\n",
      "Epoch 94/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 109020.4766 - val_loss: 121959.7344\n",
      "Epoch 95/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108976.0000 - val_loss: 121924.5625\n",
      "Epoch 96/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108929.1875 - val_loss: 121887.7344\n",
      "Epoch 97/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108881.0234 - val_loss: 121850.6484\n",
      "Epoch 98/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108831.6250 - val_loss: 121812.3359\n",
      "Epoch 99/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108780.6406 - val_loss: 121772.6094\n",
      "Epoch 100/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108730.5234 - val_loss: 121731.4141\n",
      "Epoch 101/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108673.4766 - val_loss: 121689.8750\n",
      "Epoch 102/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108620.9844 - val_loss: 121646.0000\n",
      "Epoch 103/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108562.9375 - val_loss: 121602.3516\n",
      "Epoch 104/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108504.5781 - val_loss: 121556.8750\n",
      "Epoch 105/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108444.9531 - val_loss: 121509.7734\n",
      "Epoch 106/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108384.3750 - val_loss: 121462.7734\n",
      "Epoch 107/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108319.9531 - val_loss: 121413.5781\n",
      "Epoch 108/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108255.3516 - val_loss: 121363.3594\n",
      "Epoch 109/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108190.0000 - val_loss: 121311.6719\n",
      "Epoch 110/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108121.7734 - val_loss: 121258.4219\n",
      "Epoch 111/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 108050.9219 - val_loss: 121204.7109\n",
      "Epoch 112/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107980.0391 - val_loss: 121149.7266\n",
      "Epoch 113/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107906.9141 - val_loss: 121092.6875\n",
      "Epoch 114/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107830.7109 - val_loss: 121033.8516\n",
      "Epoch 115/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107753.8281 - val_loss: 120973.7969\n",
      "Epoch 116/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107675.3359 - val_loss: 120913.2344\n",
      "Epoch 117/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107594.5781 - val_loss: 120850.4844\n",
      "Epoch 118/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107509.8750 - val_loss: 120785.8750\n",
      "Epoch 119/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107425.7266 - val_loss: 120719.3281\n",
      "Epoch 120/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107341.1641 - val_loss: 120651.9766\n",
      "Epoch 121/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107249.7500 - val_loss: 120582.7734\n",
      "Epoch 122/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107158.4609 - val_loss: 120512.3984\n",
      "Epoch 123/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 107066.3906 - val_loss: 120441.2656\n",
      "Epoch 124/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106971.7266 - val_loss: 120367.7344\n",
      "Epoch 125/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106874.8281 - val_loss: 120293.5859\n",
      "Epoch 126/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106774.8516 - val_loss: 120217.0469\n",
      "Epoch 127/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106676.7344 - val_loss: 120139.4766\n",
      "Epoch 128/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106575.1250 - val_loss: 120058.9141\n",
      "Epoch 129/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106465.9375 - val_loss: 119977.5781\n",
      "Epoch 130/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106361.5781 - val_loss: 119894.1719\n",
      "Epoch 131/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106250.8516 - val_loss: 119809.5000\n",
      "Epoch 132/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106138.7734 - val_loss: 119724.3516\n",
      "Epoch 133/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 106025.4531 - val_loss: 119635.2109\n",
      "Epoch 134/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 105909.7656 - val_loss: 119545.7734\n",
      "Epoch 135/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 105790.6719 - val_loss: 119455.5625\n",
      "Epoch 136/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 105668.7656 - val_loss: 119362.1016\n",
      "Epoch 137/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 105547.5469 - val_loss: 119267.6875\n",
      "Epoch 138/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 105423.8906 - val_loss: 119169.1016\n",
      "Epoch 139/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 105292.8750 - val_loss: 119071.5156\n",
      "Epoch 140/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 105165.0391 - val_loss: 118971.5469\n",
      "Epoch 141/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 105033.2266 - val_loss: 118869.3750\n",
      "Epoch 142/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 104896.8359 - val_loss: 118763.3984\n",
      "Epoch 143/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 104762.0391 - val_loss: 118659.6719\n",
      "Epoch 144/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 104621.3594 - val_loss: 118551.9844\n",
      "Epoch 145/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 104476.6406 - val_loss: 118443.5000\n",
      "Epoch 146/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 104335.9062 - val_loss: 118329.6719\n",
      "Epoch 147/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 104187.8906 - val_loss: 118218.5234\n",
      "Epoch 148/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 104035.1172 - val_loss: 118102.1719\n",
      "Epoch 149/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 103888.5703 - val_loss: 117984.0781\n",
      "Epoch 150/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 103728.9453 - val_loss: 117866.8984\n",
      "Epoch 151/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 103570.9531 - val_loss: 117744.9531\n",
      "Epoch 152/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 103412.4375 - val_loss: 117620.8750\n",
      "Epoch 153/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 103248.2891 - val_loss: 117493.1406\n",
      "Epoch 154/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 103081.0391 - val_loss: 117366.7266\n",
      "Epoch 155/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 102912.3906 - val_loss: 117235.7969\n",
      "Epoch 156/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 102737.0000 - val_loss: 117104.0781\n",
      "Epoch 157/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 102570.0000 - val_loss: 116971.1484\n",
      "Epoch 158/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 102389.3281 - val_loss: 116837.2500\n",
      "Epoch 159/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 102211.6484 - val_loss: 116695.1484\n",
      "Epoch 160/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 102026.4609 - val_loss: 116555.2656\n",
      "Epoch 161/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 101840.3906 - val_loss: 116414.6016\n",
      "Epoch 162/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 101648.0469 - val_loss: 116269.4844\n",
      "Epoch 163/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 101467.3438 - val_loss: 116126.9609\n",
      "Epoch 164/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 101297.4609 - val_loss: 115984.4141\n",
      "Epoch 165/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 101138.9453 - val_loss: 115836.4766\n",
      "Epoch 166/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 100961.2891 - val_loss: 115691.2500\n",
      "Epoch 167/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 100790.6016 - val_loss: 115546.2891\n",
      "Epoch 168/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 100611.6094 - val_loss: 115398.6094\n",
      "Epoch 169/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 100437.8516 - val_loss: 115243.3984\n",
      "Epoch 170/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 100256.2031 - val_loss: 115092.7656\n",
      "Epoch 171/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 100072.4219 - val_loss: 114937.6484\n",
      "Epoch 172/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 99894.6094 - val_loss: 114778.5000\n",
      "Epoch 173/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 99704.7891 - val_loss: 114616.7969\n",
      "Epoch 174/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 99510.6484 - val_loss: 114455.2031\n",
      "Epoch 175/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 99319.5703 - val_loss: 114293.6719\n",
      "Epoch 176/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 99136.9375 - val_loss: 114124.6250\n",
      "Epoch 177/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 98927.2422 - val_loss: 113957.0234\n",
      "Epoch 178/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 98732.4844 - val_loss: 113782.8359\n",
      "Epoch 179/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 98526.7109 - val_loss: 113608.4375\n",
      "Epoch 180/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 98319.6719 - val_loss: 113434.0156\n",
      "Epoch 181/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 98109.5625 - val_loss: 113257.6875\n",
      "Epoch 182/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 97899.5391 - val_loss: 113076.4219\n",
      "Epoch 183/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 97686.1719 - val_loss: 112890.3281\n",
      "Epoch 184/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 97473.2812 - val_loss: 112703.6406\n",
      "Epoch 185/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 97249.0547 - val_loss: 112516.4219\n",
      "Epoch 186/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 97024.9297 - val_loss: 112322.2656\n",
      "Epoch 187/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 96794.7422 - val_loss: 112131.5156\n",
      "Epoch 188/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 96570.2109 - val_loss: 111939.1719\n",
      "Epoch 189/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 96336.2500 - val_loss: 111742.4141\n",
      "Epoch 190/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 96098.5312 - val_loss: 111542.6016\n",
      "Epoch 191/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 95870.2188 - val_loss: 111333.6641\n",
      "Epoch 192/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 95629.9141 - val_loss: 111127.8984\n",
      "Epoch 193/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 95379.4766 - val_loss: 110925.4141\n",
      "Epoch 194/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 95133.0781 - val_loss: 110715.7266\n",
      "Epoch 195/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 94887.2969 - val_loss: 110498.8125\n",
      "Epoch 196/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 94639.4922 - val_loss: 110280.1250\n",
      "Epoch 197/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 94379.8906 - val_loss: 110060.3359\n",
      "Epoch 198/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 94115.7422 - val_loss: 109837.9609\n",
      "Epoch 199/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 93845.5938 - val_loss: 109618.2656\n",
      "Epoch 200/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 93590.7891 - val_loss: 109392.8359\n",
      "Epoch 201/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 93323.7969 - val_loss: 109163.9141\n",
      "Epoch 202/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 93044.7266 - val_loss: 108934.4844\n",
      "Epoch 203/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 92780.8438 - val_loss: 108693.9844\n",
      "Epoch 204/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 92504.1484 - val_loss: 108455.5156\n",
      "Epoch 205/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 92213.6953 - val_loss: 108213.6250\n",
      "Epoch 206/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 91932.1641 - val_loss: 107971.3281\n",
      "Epoch 207/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 91645.2656 - val_loss: 107723.0234\n",
      "Epoch 208/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 91354.3359 - val_loss: 107475.6484\n",
      "Epoch 209/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 91062.8906 - val_loss: 107220.9219\n",
      "Epoch 210/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 90756.3516 - val_loss: 106968.7031\n",
      "Epoch 211/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 90465.8281 - val_loss: 106709.3516\n",
      "Epoch 212/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 90170.8750 - val_loss: 106443.6250\n",
      "Epoch 213/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 89851.2656 - val_loss: 106176.9141\n",
      "Epoch 214/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 89536.6406 - val_loss: 105911.2500\n",
      "Epoch 215/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 89226.6562 - val_loss: 105643.4609\n",
      "Epoch 216/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 88901.7031 - val_loss: 105379.1406\n",
      "Epoch 217/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 88587.3672 - val_loss: 105106.2734\n",
      "Epoch 218/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 88263.4609 - val_loss: 104826.6641\n",
      "Epoch 219/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 87937.8828 - val_loss: 104543.7812\n",
      "Epoch 220/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 87623.5078 - val_loss: 104254.0703\n",
      "Epoch 221/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 87264.3125 - val_loss: 103969.7734\n",
      "Epoch 222/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 86935.5938 - val_loss: 103681.6406\n",
      "Epoch 223/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 86595.6016 - val_loss: 103390.3828\n",
      "Epoch 224/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 86276.2188 - val_loss: 103099.4844\n",
      "Epoch 225/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 85969.8594 - val_loss: 102818.8594\n",
      "Epoch 226/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 85666.7109 - val_loss: 102536.2969\n",
      "Epoch 227/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 85376.0938 - val_loss: 102245.8594\n",
      "Epoch 228/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 85073.4766 - val_loss: 101957.1875\n",
      "Epoch 229/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 84772.9219 - val_loss: 101659.0156\n",
      "Epoch 230/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 84454.1562 - val_loss: 101367.8125\n",
      "Epoch 231/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 84150.3438 - val_loss: 101070.3906\n",
      "Epoch 232/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 83837.4531 - val_loss: 100769.4844\n",
      "Epoch 233/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 83519.2656 - val_loss: 100473.5156\n",
      "Epoch 234/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 83212.2891 - val_loss: 100149.7656\n",
      "Epoch 235/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 82870.1719 - val_loss: 99844.3125\n",
      "Epoch 236/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 82559.0625 - val_loss: 99532.6875\n",
      "Epoch 237/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 82217.7188 - val_loss: 99218.7734\n",
      "Epoch 238/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 81884.5781 - val_loss: 98899.4141\n",
      "Epoch 239/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 81583.9375 - val_loss: 98580.8516\n",
      "Epoch 240/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 81262.1719 - val_loss: 98277.4531\n",
      "Epoch 241/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 80965.4766 - val_loss: 97963.1641\n",
      "Epoch 242/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 80651.8359 - val_loss: 97664.1719\n",
      "Epoch 243/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 80355.7578 - val_loss: 97341.8906\n",
      "Epoch 244/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 80051.9844 - val_loss: 97019.5703\n",
      "Epoch 245/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 79721.3359 - val_loss: 96712.0234\n",
      "Epoch 246/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 79426.5391 - val_loss: 96386.1094\n",
      "Epoch 247/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 79087.6094 - val_loss: 96060.6016\n",
      "Epoch 248/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 78757.7969 - val_loss: 95749.3438\n",
      "Epoch 249/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 78450.1719 - val_loss: 95410.3516\n",
      "Epoch 250/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 78110.5703 - val_loss: 95079.5234\n",
      "Epoch 251/2000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77792.1875 - val_loss: 94736.5781\n",
      "Epoch 252/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 77444.9219 - val_loss: 94399.8516\n",
      "Epoch 253/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 77104.9844 - val_loss: 94062.2969\n",
      "Epoch 254/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 76764.7109 - val_loss: 93725.2188\n",
      "Epoch 255/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 76421.6719 - val_loss: 93376.8984\n",
      "Epoch 256/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 76076.8828 - val_loss: 93021.5625\n",
      "Epoch 257/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 75729.3047 - val_loss: 92654.7969\n",
      "Epoch 258/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 75370.2812 - val_loss: 92297.2344\n",
      "Epoch 259/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 75008.3594 - val_loss: 91936.1719\n",
      "Epoch 260/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 74661.7109 - val_loss: 91563.7109\n",
      "Epoch 261/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 74275.8047 - val_loss: 91200.1641\n",
      "Epoch 262/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 73924.3516 - val_loss: 90824.7969\n",
      "Epoch 263/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 73539.5625 - val_loss: 90459.4844\n",
      "Epoch 264/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 73159.7422 - val_loss: 90093.2031\n",
      "Epoch 265/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 72792.2891 - val_loss: 89704.5000\n",
      "Epoch 266/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 72403.9453 - val_loss: 89331.1094\n",
      "Epoch 267/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 72029.3906 - val_loss: 88944.3125\n",
      "Epoch 268/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 71637.5703 - val_loss: 88555.0000\n",
      "Epoch 269/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 71256.2188 - val_loss: 88175.4766\n",
      "Epoch 270/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 70923.4375 - val_loss: 87785.5156\n",
      "Epoch 271/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 70589.1250 - val_loss: 87392.6719\n",
      "Epoch 272/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 70232.4922 - val_loss: 87010.1406\n",
      "Epoch 273/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 69881.6484 - val_loss: 86638.8750\n",
      "Epoch 274/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 69541.5312 - val_loss: 86253.9766\n",
      "Epoch 275/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 69188.2891 - val_loss: 85874.2969\n",
      "Epoch 276/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 68857.2109 - val_loss: 85469.8594\n",
      "Epoch 277/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 68527.5781 - val_loss: 85049.2969\n",
      "Epoch 278/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 68129.7891 - val_loss: 84664.5703\n",
      "Epoch 279/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 67760.3125 - val_loss: 84285.7500\n",
      "Epoch 280/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 67437.3125 - val_loss: 83856.0312\n",
      "Epoch 281/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 67052.0078 - val_loss: 83449.7812\n",
      "Epoch 282/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 66681.0469 - val_loss: 83041.6562\n",
      "Epoch 283/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 66293.7969 - val_loss: 82646.4609\n",
      "Epoch 284/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 65955.4609 - val_loss: 82210.0234\n",
      "Epoch 285/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 65590.6875 - val_loss: 81757.6875\n",
      "Epoch 286/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 65170.9062 - val_loss: 81342.5078\n",
      "Epoch 287/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 64801.5195 - val_loss: 80917.8750\n",
      "Epoch 288/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 64407.7422 - val_loss: 80493.8750\n",
      "Epoch 289/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 64023.0312 - val_loss: 80061.2812\n",
      "Epoch 290/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 63638.8828 - val_loss: 79621.3516\n",
      "Epoch 291/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 63247.4805 - val_loss: 79165.4453\n",
      "Epoch 292/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 62859.9375 - val_loss: 78717.9688\n",
      "Epoch 293/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 62480.7578 - val_loss: 78285.8672\n",
      "Epoch 294/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 62117.1680 - val_loss: 77872.4219\n",
      "Epoch 295/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 61763.1758 - val_loss: 77443.9844\n",
      "Epoch 296/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 61399.8945 - val_loss: 77017.5781\n",
      "Epoch 297/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 61035.5234 - val_loss: 76579.6641\n",
      "Epoch 298/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 60667.1758 - val_loss: 76145.6641\n",
      "Epoch 299/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 60295.9453 - val_loss: 75714.1094\n",
      "Epoch 300/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 59904.7617 - val_loss: 75282.6797\n",
      "Epoch 301/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 59524.8984 - val_loss: 74864.0547\n",
      "Epoch 302/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 59173.9766 - val_loss: 74402.3906\n",
      "Epoch 303/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 58778.5859 - val_loss: 73960.9141\n",
      "Epoch 304/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 58394.4492 - val_loss: 73512.1328\n",
      "Epoch 305/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 58037.5000 - val_loss: 73041.5391\n",
      "Epoch 306/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 57691.2383 - val_loss: 72583.4922\n",
      "Epoch 307/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 57322.9141 - val_loss: 72145.2656\n",
      "Epoch 308/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 56952.4453 - val_loss: 71720.6484\n",
      "Epoch 309/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 56615.3359 - val_loss: 71283.6094\n",
      "Epoch 310/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 56287.0703 - val_loss: 70805.7109\n",
      "Epoch 311/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 55911.6328 - val_loss: 70362.3438\n",
      "Epoch 312/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 55535.4062 - val_loss: 69927.5156\n",
      "Epoch 313/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 55192.1758 - val_loss: 69469.0781\n",
      "Epoch 314/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 54809.6680 - val_loss: 69032.9844\n",
      "Epoch 315/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 54454.4766 - val_loss: 68567.6016\n",
      "Epoch 316/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 54070.0312 - val_loss: 68161.6250\n",
      "Epoch 317/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 53769.4492 - val_loss: 67698.3594\n",
      "Epoch 318/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 53415.4609 - val_loss: 67255.0938\n",
      "Epoch 319/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 53059.9688 - val_loss: 66819.0234\n",
      "Epoch 320/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 52710.5742 - val_loss: 66399.0781\n",
      "Epoch 321/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 52376.6367 - val_loss: 65960.2031\n",
      "Epoch 322/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 52036.4219 - val_loss: 65490.9297\n",
      "Epoch 323/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 51651.8555 - val_loss: 65050.7617\n",
      "Epoch 324/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 51318.2695 - val_loss: 64586.8125\n",
      "Epoch 325/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 50962.4531 - val_loss: 64104.9141\n",
      "Epoch 326/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 50587.3594 - val_loss: 63655.4180\n",
      "Epoch 327/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 50217.9531 - val_loss: 63201.8008\n",
      "Epoch 328/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 49855.1602 - val_loss: 62744.3359\n",
      "Epoch 329/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 49513.2031 - val_loss: 62236.8867\n",
      "Epoch 330/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 49108.2539 - val_loss: 61777.8359\n",
      "Epoch 331/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 48785.7812 - val_loss: 61261.8203\n",
      "Epoch 332/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 48345.7188 - val_loss: 60828.9805\n",
      "Epoch 333/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 47992.4805 - val_loss: 60347.6992\n",
      "Epoch 334/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 47613.8672 - val_loss: 59890.1875\n",
      "Epoch 335/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 47278.6719 - val_loss: 59408.7500\n",
      "Epoch 336/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 46930.1562 - val_loss: 58931.7266\n",
      "Epoch 337/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 46546.3516 - val_loss: 58491.5234\n",
      "Epoch 338/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 46207.7578 - val_loss: 58015.2109\n",
      "Epoch 339/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 45856.9141 - val_loss: 57513.0195\n",
      "Epoch 340/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 45484.7383 - val_loss: 57043.9258\n",
      "Epoch 341/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 45113.9297 - val_loss: 56572.4062\n",
      "Epoch 342/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 44759.9297 - val_loss: 56072.5234\n",
      "Epoch 343/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 44361.6562 - val_loss: 55608.0195\n",
      "Epoch 344/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 43996.1211 - val_loss: 55123.1875\n",
      "Epoch 345/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 43637.9844 - val_loss: 54617.7617\n",
      "Epoch 346/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 43262.8281 - val_loss: 54099.1992\n",
      "Epoch 347/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 42888.0703 - val_loss: 53592.1641\n",
      "Epoch 348/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 42506.6484 - val_loss: 53113.1016\n",
      "Epoch 349/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 42109.3945 - val_loss: 52695.3555\n",
      "Epoch 350/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 41789.0820 - val_loss: 52256.0586\n",
      "Epoch 351/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 41438.9102 - val_loss: 51917.6562\n",
      "Epoch 352/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 41094.4336 - val_loss: 51544.0273\n",
      "Epoch 353/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 40783.3984 - val_loss: 51178.0078\n",
      "Epoch 354/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 40463.3320 - val_loss: 50853.4062\n",
      "Epoch 355/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 40179.8398 - val_loss: 50497.3320\n",
      "Epoch 356/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 39891.7773 - val_loss: 50173.3867\n",
      "Epoch 357/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 39581.7500 - val_loss: 49934.5156\n",
      "Epoch 358/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 39305.4883 - val_loss: 49695.4570\n",
      "Epoch 359/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 38989.5000 - val_loss: 49464.1172\n",
      "Epoch 360/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 38705.0156 - val_loss: 49228.2422\n",
      "Epoch 361/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 38384.6914 - val_loss: 48985.1914\n",
      "Epoch 362/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 38092.1562 - val_loss: 48742.0391\n",
      "Epoch 363/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 37772.3203 - val_loss: 48500.9453\n",
      "Epoch 364/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 37482.8750 - val_loss: 48244.5234\n",
      "Epoch 365/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 37195.2422 - val_loss: 48015.0898\n",
      "Epoch 366/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 36927.0508 - val_loss: 47778.2578\n",
      "Epoch 367/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 36696.4180 - val_loss: 47520.4883\n",
      "Epoch 368/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 36431.1562 - val_loss: 47278.0703\n",
      "Epoch 369/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 36163.3008 - val_loss: 47048.4688\n",
      "Epoch 370/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 35913.9023 - val_loss: 46802.9922\n",
      "Epoch 371/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 35678.8867 - val_loss: 46549.6367\n",
      "Epoch 372/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 35396.9531 - val_loss: 46312.4375\n",
      "Epoch 373/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 35162.1875 - val_loss: 46103.8203\n",
      "Epoch 374/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 34935.5938 - val_loss: 45874.2227\n",
      "Epoch 375/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 34711.8555 - val_loss: 45626.1211\n",
      "Epoch 376/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 34474.5547 - val_loss: 45387.3047\n",
      "Epoch 377/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 34207.0469 - val_loss: 45171.9258\n",
      "Epoch 378/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 33968.9492 - val_loss: 44965.3359\n",
      "Epoch 379/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 33748.7148 - val_loss: 44734.0234\n",
      "Epoch 380/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 33514.1328 - val_loss: 44490.2734\n",
      "Epoch 381/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 33300.9258 - val_loss: 44277.5938\n",
      "Epoch 382/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 33100.5547 - val_loss: 44086.5117\n",
      "Epoch 383/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 32921.2617 - val_loss: 43894.9141\n",
      "Epoch 384/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 32736.7246 - val_loss: 43687.2852\n",
      "Epoch 385/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 32548.9219 - val_loss: 43479.7383\n",
      "Epoch 386/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 32356.2090 - val_loss: 43280.5508\n",
      "Epoch 387/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 32172.8379 - val_loss: 43067.9297\n",
      "Epoch 388/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 31996.2969 - val_loss: 42866.1445\n",
      "Epoch 389/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 31797.4629 - val_loss: 42649.9922\n",
      "Epoch 390/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 31605.4121 - val_loss: 42438.0430\n",
      "Epoch 391/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 31404.4590 - val_loss: 42226.1250\n",
      "Epoch 392/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 31220.4492 - val_loss: 42011.9336\n",
      "Epoch 393/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 31027.5117 - val_loss: 41792.3398\n",
      "Epoch 394/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 30820.2305 - val_loss: 41597.9102\n",
      "Epoch 395/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 30639.6562 - val_loss: 41387.0391\n",
      "Epoch 396/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 30478.1191 - val_loss: 41139.8516\n",
      "Epoch 397/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 30259.5840 - val_loss: 40914.6172\n",
      "Epoch 398/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 30049.1445 - val_loss: 40695.9375\n",
      "Epoch 399/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29841.6055 - val_loss: 40488.0352\n",
      "Epoch 400/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29654.8848 - val_loss: 40278.8672\n",
      "Epoch 401/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29496.7910 - val_loss: 40057.0391\n",
      "Epoch 402/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29344.5684 - val_loss: 39833.2266\n",
      "Epoch 403/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29162.7090 - val_loss: 39694.0781\n",
      "Epoch 404/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29000.8711 - val_loss: 39557.7812\n",
      "Epoch 405/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 28833.2910 - val_loss: 39427.6641\n",
      "Epoch 406/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 28703.5195 - val_loss: 39294.5625\n",
      "Epoch 407/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 28541.3945 - val_loss: 39157.3242\n",
      "Epoch 408/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 28365.7773 - val_loss: 39013.1797\n",
      "Epoch 409/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 28195.5879 - val_loss: 38873.6016\n",
      "Epoch 410/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 28056.8496 - val_loss: 38732.2969\n",
      "Epoch 411/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27884.5664 - val_loss: 38614.2422\n",
      "Epoch 412/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27757.8027 - val_loss: 38490.6367\n",
      "Epoch 413/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27624.0879 - val_loss: 38374.8516\n",
      "Epoch 414/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27524.2129 - val_loss: 38266.8750\n",
      "Epoch 415/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27422.8594 - val_loss: 38153.6953\n",
      "Epoch 416/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27343.4316 - val_loss: 38028.5156\n",
      "Epoch 417/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27237.7539 - val_loss: 37931.5195\n",
      "Epoch 418/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27175.7773 - val_loss: 37830.5625\n",
      "Epoch 419/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27093.7617 - val_loss: 37714.5195\n",
      "Epoch 420/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27003.3125 - val_loss: 37604.6172\n",
      "Epoch 421/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26928.6289 - val_loss: 37499.7148\n",
      "Epoch 422/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26845.4961 - val_loss: 37376.7734\n",
      "Epoch 423/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26760.7383 - val_loss: 37252.4375\n",
      "Epoch 424/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26674.7129 - val_loss: 37142.5039\n",
      "Epoch 425/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26602.5820 - val_loss: 37042.3945\n",
      "Epoch 426/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26522.1934 - val_loss: 36914.2461\n",
      "Epoch 427/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26434.2910 - val_loss: 36788.9922\n",
      "Epoch 428/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26342.6445 - val_loss: 36686.2539\n",
      "Epoch 429/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26271.7910 - val_loss: 36569.2930\n",
      "Epoch 430/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26188.0293 - val_loss: 36455.1914\n",
      "Epoch 431/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26104.1816 - val_loss: 36323.0508\n",
      "Epoch 432/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26018.0352 - val_loss: 36215.9375\n",
      "Epoch 433/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25943.0000 - val_loss: 36111.6719\n",
      "Epoch 434/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25858.7598 - val_loss: 36003.3867\n",
      "Epoch 435/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25787.0469 - val_loss: 35868.9922\n",
      "Epoch 436/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25684.8984 - val_loss: 35758.3672\n",
      "Epoch 437/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25610.1250 - val_loss: 35650.8047\n",
      "Epoch 438/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25538.5332 - val_loss: 35525.9141\n",
      "Epoch 439/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25451.6523 - val_loss: 35425.0078\n",
      "Epoch 440/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25385.3555 - val_loss: 35289.7500\n",
      "Epoch 441/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25274.0000 - val_loss: 35182.1992\n",
      "Epoch 442/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25204.3164 - val_loss: 35053.5508\n",
      "Epoch 443/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 25116.7773 - val_loss: 34942.7344\n",
      "Epoch 444/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25034.5410 - val_loss: 34822.8828\n",
      "Epoch 445/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24946.0117 - val_loss: 34710.3828\n",
      "Epoch 446/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24873.9238 - val_loss: 34580.4180\n",
      "Epoch 447/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24780.1426 - val_loss: 34467.8945\n",
      "Epoch 448/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24718.6777 - val_loss: 34353.7812\n",
      "Epoch 449/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24668.6602 - val_loss: 34259.6758\n",
      "Epoch 450/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24598.4141 - val_loss: 34161.5859\n",
      "Epoch 451/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24541.5547 - val_loss: 34084.1367\n",
      "Epoch 452/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24487.2109 - val_loss: 33971.0898\n",
      "Epoch 453/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24428.9023 - val_loss: 33887.1484\n",
      "Epoch 454/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24361.2539 - val_loss: 33774.2148\n",
      "Epoch 455/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24308.4727 - val_loss: 33682.6016\n",
      "Epoch 456/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24259.3125 - val_loss: 33564.9727\n",
      "Epoch 457/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24192.3867 - val_loss: 33476.2617\n",
      "Epoch 458/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24125.9668 - val_loss: 33389.5156\n",
      "Epoch 459/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24071.9785 - val_loss: 33292.9141\n",
      "Epoch 460/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24022.7402 - val_loss: 33181.8945\n",
      "Epoch 461/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23957.5801 - val_loss: 33081.7500\n",
      "Epoch 462/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23899.2422 - val_loss: 33003.5742\n",
      "Epoch 463/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23841.2148 - val_loss: 32894.9609\n",
      "Epoch 464/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23785.4746 - val_loss: 32791.2578\n",
      "Epoch 465/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23731.6953 - val_loss: 32700.0117\n",
      "Epoch 466/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23673.9707 - val_loss: 32596.7539\n",
      "Epoch 467/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23610.7070 - val_loss: 32504.4746\n",
      "Epoch 468/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23553.0625 - val_loss: 32422.0625\n",
      "Epoch 469/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23497.2676 - val_loss: 32320.4590\n",
      "Epoch 470/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23442.1465 - val_loss: 32217.7773\n",
      "Epoch 471/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23394.0156 - val_loss: 32103.1133\n",
      "Epoch 472/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23322.2949 - val_loss: 32003.2461\n",
      "Epoch 473/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23269.0352 - val_loss: 31926.5527\n",
      "Epoch 474/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23211.8789 - val_loss: 31835.9902\n",
      "Epoch 475/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23162.4785 - val_loss: 31735.6504\n",
      "Epoch 476/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23118.0273 - val_loss: 31610.6621\n",
      "Epoch 477/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23041.2480 - val_loss: 31524.0527\n",
      "Epoch 478/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22986.0781 - val_loss: 31421.3184\n",
      "Epoch 479/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22924.9473 - val_loss: 31342.2305\n",
      "Epoch 480/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22872.7578 - val_loss: 31232.1562\n",
      "Epoch 481/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22818.5996 - val_loss: 31126.3086\n",
      "Epoch 482/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22756.3633 - val_loss: 31058.7090\n",
      "Epoch 483/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22703.2188 - val_loss: 30969.6191\n",
      "Epoch 484/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22648.8789 - val_loss: 30862.1211\n",
      "Epoch 485/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22595.6680 - val_loss: 30756.1406\n",
      "Epoch 486/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22542.8555 - val_loss: 30678.1348\n",
      "Epoch 487/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22475.2383 - val_loss: 30608.3086\n",
      "Epoch 488/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22423.2852 - val_loss: 30531.2129\n",
      "Epoch 489/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22364.7637 - val_loss: 30460.4375\n",
      "Epoch 490/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22306.3086 - val_loss: 30381.7305\n",
      "Epoch 491/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22257.2129 - val_loss: 30307.3125\n",
      "Epoch 492/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22199.3125 - val_loss: 30235.1094\n",
      "Epoch 493/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22143.8105 - val_loss: 30168.8633\n",
      "Epoch 494/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22098.6758 - val_loss: 30099.8379\n",
      "Epoch 495/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22053.2070 - val_loss: 30022.6680\n",
      "Epoch 496/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22005.2129 - val_loss: 29969.9629\n",
      "Epoch 497/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21963.4023 - val_loss: 29900.7871\n",
      "Epoch 498/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21913.0938 - val_loss: 29830.1289\n",
      "Epoch 499/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21861.9766 - val_loss: 29768.7090\n",
      "Epoch 500/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21812.4141 - val_loss: 29693.3164\n",
      "Epoch 501/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21774.6230 - val_loss: 29629.0996\n",
      "Epoch 502/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21722.8516 - val_loss: 29568.4414\n",
      "Epoch 503/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21673.5273 - val_loss: 29506.4648\n",
      "Epoch 504/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21637.0898 - val_loss: 29428.4961\n",
      "Epoch 505/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21585.4336 - val_loss: 29362.6816\n",
      "Epoch 506/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21542.4648 - val_loss: 29294.0312\n",
      "Epoch 507/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21484.4180 - val_loss: 29232.6055\n",
      "Epoch 508/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21440.8164 - val_loss: 29167.7383\n",
      "Epoch 509/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21395.9219 - val_loss: 29096.8750\n",
      "Epoch 510/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21349.9512 - val_loss: 29028.0195\n",
      "Epoch 511/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21295.5039 - val_loss: 28969.6660\n",
      "Epoch 512/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21256.7617 - val_loss: 28892.1465\n",
      "Epoch 513/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21207.8477 - val_loss: 28830.4961\n",
      "Epoch 514/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21160.1445 - val_loss: 28759.8594\n",
      "Epoch 515/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21113.0508 - val_loss: 28681.5098\n",
      "Epoch 516/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21058.2148 - val_loss: 28622.5879\n",
      "Epoch 517/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 21021.1953 - val_loss: 28550.9805\n",
      "Epoch 518/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20975.8965 - val_loss: 28474.7070\n",
      "Epoch 519/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20921.6250 - val_loss: 28408.0508\n",
      "Epoch 520/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20878.9238 - val_loss: 28341.0586\n",
      "Epoch 521/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20827.1562 - val_loss: 28274.7715\n",
      "Epoch 522/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20781.5039 - val_loss: 28206.5059\n",
      "Epoch 523/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20737.4961 - val_loss: 28139.7715\n",
      "Epoch 524/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20686.2422 - val_loss: 28068.4844\n",
      "Epoch 525/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20653.5430 - val_loss: 28003.8809\n",
      "Epoch 526/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20594.5605 - val_loss: 27928.6309\n",
      "Epoch 527/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20540.9609 - val_loss: 27860.4004\n",
      "Epoch 528/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20502.4805 - val_loss: 27780.4375\n",
      "Epoch 529/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20454.0449 - val_loss: 27717.8438\n",
      "Epoch 530/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20405.2773 - val_loss: 27648.9746\n",
      "Epoch 531/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20375.1816 - val_loss: 27585.9844\n",
      "Epoch 532/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20320.7695 - val_loss: 27514.5586\n",
      "Epoch 533/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20275.0137 - val_loss: 27439.2500\n",
      "Epoch 534/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20234.4648 - val_loss: 27379.0254\n",
      "Epoch 535/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20198.1992 - val_loss: 27309.2871\n",
      "Epoch 536/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20162.9258 - val_loss: 27243.3398\n",
      "Epoch 537/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20116.9336 - val_loss: 27184.7930\n",
      "Epoch 538/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20078.9023 - val_loss: 27119.0273\n",
      "Epoch 539/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20046.9180 - val_loss: 27056.9062\n",
      "Epoch 540/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20008.5605 - val_loss: 26982.1992\n",
      "Epoch 541/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19972.2734 - val_loss: 26921.9004\n",
      "Epoch 542/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19940.0996 - val_loss: 26842.3965\n",
      "Epoch 543/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19889.4727 - val_loss: 26784.7930\n",
      "Epoch 544/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19866.8398 - val_loss: 26721.9883\n",
      "Epoch 545/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19816.4824 - val_loss: 26676.1191\n",
      "Epoch 546/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19774.7734 - val_loss: 26610.6836\n",
      "Epoch 547/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19749.2637 - val_loss: 26532.1367\n",
      "Epoch 548/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19710.2402 - val_loss: 26470.5840\n",
      "Epoch 549/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19666.0801 - val_loss: 26412.9219\n",
      "Epoch 550/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19629.7656 - val_loss: 26345.7754\n",
      "Epoch 551/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19596.9805 - val_loss: 26274.3379\n",
      "Epoch 552/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19551.4277 - val_loss: 26203.0469\n",
      "Epoch 553/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19511.3867 - val_loss: 26154.6230\n",
      "Epoch 554/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19477.1699 - val_loss: 26086.5840\n",
      "Epoch 555/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19451.6152 - val_loss: 26022.3008\n",
      "Epoch 556/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19396.2520 - val_loss: 25972.0547\n",
      "Epoch 557/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19360.1582 - val_loss: 25915.0898\n",
      "Epoch 558/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19327.6504 - val_loss: 25838.2188\n",
      "Epoch 559/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19284.7695 - val_loss: 25773.0742\n",
      "Epoch 560/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19243.2656 - val_loss: 25722.9336\n",
      "Epoch 561/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19207.2715 - val_loss: 25659.3145\n",
      "Epoch 562/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19174.2695 - val_loss: 25591.9961\n",
      "Epoch 563/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19134.2695 - val_loss: 25512.8750\n",
      "Epoch 564/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19094.7422 - val_loss: 25455.1914\n",
      "Epoch 565/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19062.9785 - val_loss: 25383.1504\n",
      "Epoch 566/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19014.0820 - val_loss: 25320.9062\n",
      "Epoch 567/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18978.5801 - val_loss: 25259.6406\n",
      "Epoch 568/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18939.6172 - val_loss: 25191.8125\n",
      "Epoch 569/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18898.3125 - val_loss: 25130.1250\n",
      "Epoch 570/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18866.2539 - val_loss: 25065.2930\n",
      "Epoch 571/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18825.0117 - val_loss: 25001.6133\n",
      "Epoch 572/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18794.9590 - val_loss: 24922.6250\n",
      "Epoch 573/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18753.8047 - val_loss: 24885.1055\n",
      "Epoch 574/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18716.2520 - val_loss: 24824.4355\n",
      "Epoch 575/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18685.0410 - val_loss: 24759.9609\n",
      "Epoch 576/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18649.5742 - val_loss: 24692.7715\n",
      "Epoch 577/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18620.9785 - val_loss: 24632.5117\n",
      "Epoch 578/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18585.2090 - val_loss: 24559.5410\n",
      "Epoch 579/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18546.2500 - val_loss: 24500.8242\n",
      "Epoch 580/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18518.2227 - val_loss: 24448.0664\n",
      "Epoch 581/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18477.1152 - val_loss: 24389.4629\n",
      "Epoch 582/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18445.7930 - val_loss: 24316.7930\n",
      "Epoch 583/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18407.5430 - val_loss: 24263.7578\n",
      "Epoch 584/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18372.2871 - val_loss: 24211.1934\n",
      "Epoch 585/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18343.1523 - val_loss: 24150.4375\n",
      "Epoch 586/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18320.3535 - val_loss: 24089.9492\n",
      "Epoch 587/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18277.8594 - val_loss: 24025.1602\n",
      "Epoch 588/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18240.2070 - val_loss: 23954.8164\n",
      "Epoch 589/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18210.5039 - val_loss: 23902.7969\n",
      "Epoch 590/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18169.0449 - val_loss: 23842.2285\n",
      "Epoch 591/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 18138.9512 - val_loss: 23773.6055\n",
      "Epoch 592/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18105.1367 - val_loss: 23712.8242\n",
      "Epoch 593/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18079.5977 - val_loss: 23647.8867\n",
      "Epoch 594/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18047.8945 - val_loss: 23587.0469\n",
      "Epoch 595/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18003.6523 - val_loss: 23528.3809\n",
      "Epoch 596/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17974.9336 - val_loss: 23470.1465\n",
      "Epoch 597/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17931.3066 - val_loss: 23415.0566\n",
      "Epoch 598/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17931.5039 - val_loss: 23333.0039\n",
      "Epoch 599/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17878.8398 - val_loss: 23281.9199\n",
      "Epoch 600/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17839.0039 - val_loss: 23231.3125\n",
      "Epoch 601/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17801.4590 - val_loss: 23174.3320\n",
      "Epoch 602/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17767.6660 - val_loss: 23108.0781\n",
      "Epoch 603/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17744.7031 - val_loss: 23047.6465\n",
      "Epoch 604/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17711.4277 - val_loss: 23007.8730\n",
      "Epoch 605/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17673.4414 - val_loss: 22946.6504\n",
      "Epoch 606/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17638.2422 - val_loss: 22871.8223\n",
      "Epoch 607/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17601.2500 - val_loss: 22816.8320\n",
      "Epoch 608/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17571.8945 - val_loss: 22755.2129\n",
      "Epoch 609/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17533.7852 - val_loss: 22701.0352\n",
      "Epoch 610/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17502.5352 - val_loss: 22657.3867\n",
      "Epoch 611/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17463.0312 - val_loss: 22614.6973\n",
      "Epoch 612/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17438.9121 - val_loss: 22546.0020\n",
      "Epoch 613/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17408.3906 - val_loss: 22498.3320\n",
      "Epoch 614/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17367.3457 - val_loss: 22459.7344\n",
      "Epoch 615/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17342.5723 - val_loss: 22395.2852\n",
      "Epoch 616/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17306.8477 - val_loss: 22331.8281\n",
      "Epoch 617/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17270.3262 - val_loss: 22292.1777\n",
      "Epoch 618/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17242.3633 - val_loss: 22263.0195\n",
      "Epoch 619/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17204.2305 - val_loss: 22192.7305\n",
      "Epoch 620/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17170.8320 - val_loss: 22155.5371\n",
      "Epoch 621/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17146.4727 - val_loss: 22108.3008\n",
      "Epoch 622/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17102.3730 - val_loss: 22037.6406\n",
      "Epoch 623/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17077.7383 - val_loss: 22006.0742\n",
      "Epoch 624/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17052.1934 - val_loss: 21904.6406\n",
      "Epoch 625/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17007.6602 - val_loss: 21872.6992\n",
      "Epoch 626/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16970.4277 - val_loss: 21824.0996\n",
      "Epoch 627/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16946.2402 - val_loss: 21760.5410\n",
      "Epoch 628/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16911.1035 - val_loss: 21723.7148\n",
      "Epoch 629/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16873.9023 - val_loss: 21677.6680\n",
      "Epoch 630/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16849.9961 - val_loss: 21616.6309\n",
      "Epoch 631/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16814.4805 - val_loss: 21602.2793\n",
      "Epoch 632/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16785.6777 - val_loss: 21572.1348\n",
      "Epoch 633/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16754.1758 - val_loss: 21533.7031\n",
      "Epoch 634/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16721.8906 - val_loss: 21506.4785\n",
      "Epoch 635/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16694.6836 - val_loss: 21472.5195\n",
      "Epoch 636/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16661.6289 - val_loss: 21409.8652\n",
      "Epoch 637/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16640.4922 - val_loss: 21397.1348\n",
      "Epoch 638/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16597.6914 - val_loss: 21327.0117\n",
      "Epoch 639/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16569.4277 - val_loss: 21283.0762\n",
      "Epoch 640/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16537.9258 - val_loss: 21251.9883\n",
      "Epoch 641/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16507.1855 - val_loss: 21211.6719\n",
      "Epoch 642/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16471.8613 - val_loss: 21191.6152\n",
      "Epoch 643/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16451.8320 - val_loss: 21160.8965\n",
      "Epoch 644/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16419.0508 - val_loss: 21113.5039\n",
      "Epoch 645/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16386.7695 - val_loss: 21087.8242\n",
      "Epoch 646/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16352.4453 - val_loss: 21059.6602\n",
      "Epoch 647/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16313.8887 - val_loss: 21012.6406\n",
      "Epoch 648/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16293.1875 - val_loss: 20958.2969\n",
      "Epoch 649/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16263.8340 - val_loss: 20926.1113\n",
      "Epoch 650/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16220.7373 - val_loss: 20906.8340\n",
      "Epoch 651/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16194.5469 - val_loss: 20879.3691\n",
      "Epoch 652/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16168.7988 - val_loss: 20808.1367\n",
      "Epoch 653/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16132.7061 - val_loss: 20782.3281\n",
      "Epoch 654/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16099.4277 - val_loss: 20769.1504\n",
      "Epoch 655/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16071.4062 - val_loss: 20724.1211\n",
      "Epoch 656/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16037.4014 - val_loss: 20678.6465\n",
      "Epoch 657/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15999.7441 - val_loss: 20649.4258\n",
      "Epoch 658/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15973.2734 - val_loss: 20620.9219\n",
      "Epoch 659/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15938.4248 - val_loss: 20570.7930\n",
      "Epoch 660/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15928.6953 - val_loss: 20500.5078\n",
      "Epoch 661/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15874.3691 - val_loss: 20484.6367\n",
      "Epoch 662/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15866.5752 - val_loss: 20480.7383\n",
      "Epoch 663/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15826.8574 - val_loss: 20429.3086\n",
      "Epoch 664/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15797.2871 - val_loss: 20409.6289\n",
      "Epoch 665/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 15763.2451 - val_loss: 20345.3789\n",
      "Epoch 666/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15743.3809 - val_loss: 20325.5625\n",
      "Epoch 667/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15711.4160 - val_loss: 20315.8379\n",
      "Epoch 668/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15698.5449 - val_loss: 20316.3281\n",
      "Epoch 669/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15683.7480 - val_loss: 20239.0820\n",
      "Epoch 670/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15648.6250 - val_loss: 20238.3379\n",
      "Epoch 671/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15626.2549 - val_loss: 20230.4219\n",
      "Epoch 672/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15594.6777 - val_loss: 20192.9883\n",
      "Epoch 673/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15574.4404 - val_loss: 20160.9121\n",
      "Epoch 674/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15557.3047 - val_loss: 20162.3379\n",
      "Epoch 675/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15535.0576 - val_loss: 20125.9688\n",
      "Epoch 676/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15508.4238 - val_loss: 20129.2871\n",
      "Epoch 677/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15492.7832 - val_loss: 20069.8809\n",
      "Epoch 678/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15483.1504 - val_loss: 20026.6133\n",
      "Epoch 679/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15457.1846 - val_loss: 20029.4512\n",
      "Epoch 680/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15441.7314 - val_loss: 20022.2461\n",
      "Epoch 681/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15414.7139 - val_loss: 19970.6719\n",
      "Epoch 682/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15402.5527 - val_loss: 19960.3203\n",
      "Epoch 683/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15387.2861 - val_loss: 19956.8711\n",
      "Epoch 684/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15361.2266 - val_loss: 19921.0410\n",
      "Epoch 685/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15342.8027 - val_loss: 19904.0703\n",
      "Epoch 686/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15323.9004 - val_loss: 19874.3164\n",
      "Epoch 687/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15320.0000 - val_loss: 19817.6660\n",
      "Epoch 688/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15288.8438 - val_loss: 19817.9590\n",
      "Epoch 689/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15275.1904 - val_loss: 19819.8809\n",
      "Epoch 690/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15260.6152 - val_loss: 19777.5625\n",
      "Epoch 691/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15233.6484 - val_loss: 19770.3242\n",
      "Epoch 692/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15221.5879 - val_loss: 19721.2695\n",
      "Epoch 693/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15204.7002 - val_loss: 19719.8965\n",
      "Epoch 694/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15184.6406 - val_loss: 19706.7227\n",
      "Epoch 695/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15164.5361 - val_loss: 19674.5195\n",
      "Epoch 696/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15147.1045 - val_loss: 19636.1523\n",
      "Epoch 697/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15127.6016 - val_loss: 19616.9727\n",
      "Epoch 698/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15116.6406 - val_loss: 19629.5098\n",
      "Epoch 699/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15098.2295 - val_loss: 19598.9473\n",
      "Epoch 700/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15067.5889 - val_loss: 19556.4727\n",
      "Epoch 701/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15057.7217 - val_loss: 19541.3770\n",
      "Epoch 702/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15038.4561 - val_loss: 19514.7949\n",
      "Epoch 703/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15015.5957 - val_loss: 19509.4473\n",
      "Epoch 704/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 15001.6816 - val_loss: 19498.4023\n",
      "Epoch 705/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14984.0498 - val_loss: 19453.2598\n",
      "Epoch 706/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14963.8145 - val_loss: 19423.5664\n",
      "Epoch 707/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14950.4941 - val_loss: 19414.3672\n",
      "Epoch 708/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14934.6113 - val_loss: 19373.2949\n",
      "Epoch 709/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14912.2764 - val_loss: 19357.2812\n",
      "Epoch 710/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14889.7266 - val_loss: 19354.1738\n",
      "Epoch 711/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14881.6533 - val_loss: 19330.2754\n",
      "Epoch 712/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14860.0342 - val_loss: 19273.1348\n",
      "Epoch 713/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14852.1768 - val_loss: 19294.0039\n",
      "Epoch 714/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14822.1846 - val_loss: 19262.7559\n",
      "Epoch 715/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14806.9736 - val_loss: 19223.9570\n",
      "Epoch 716/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14798.4629 - val_loss: 19172.6660\n",
      "Epoch 717/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14772.1855 - val_loss: 19179.6973\n",
      "Epoch 718/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14750.6406 - val_loss: 19183.1973\n",
      "Epoch 719/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14739.7734 - val_loss: 19153.8223\n",
      "Epoch 720/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14714.5371 - val_loss: 19138.2539\n",
      "Epoch 721/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14697.9199 - val_loss: 19094.8379\n",
      "Epoch 722/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14685.2559 - val_loss: 19057.3867\n",
      "Epoch 723/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14663.2090 - val_loss: 19055.4727\n",
      "Epoch 724/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14644.9121 - val_loss: 19046.3535\n",
      "Epoch 725/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14623.7705 - val_loss: 19008.2031\n",
      "Epoch 726/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14614.6719 - val_loss: 18984.6855\n",
      "Epoch 727/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14587.8340 - val_loss: 18940.6562\n",
      "Epoch 728/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14568.7402 - val_loss: 18947.4629\n",
      "Epoch 729/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14556.1406 - val_loss: 18923.2656\n",
      "Epoch 730/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14536.5293 - val_loss: 18917.3398\n",
      "Epoch 731/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14520.2656 - val_loss: 18894.0996\n",
      "Epoch 732/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14502.7295 - val_loss: 18835.5547\n",
      "Epoch 733/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14486.1221 - val_loss: 18828.8477\n",
      "Epoch 734/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14463.7295 - val_loss: 18815.9648\n",
      "Epoch 735/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14445.4785 - val_loss: 18786.0215\n",
      "Epoch 736/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14436.1309 - val_loss: 18770.0527\n",
      "Epoch 737/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14415.6592 - val_loss: 18732.1758\n",
      "Epoch 738/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14395.7910 - val_loss: 18742.7539\n",
      "Epoch 739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 14378.3125 - val_loss: 18709.0215\n",
      "Epoch 740/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14351.0215 - val_loss: 18659.7129\n",
      "Epoch 741/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14349.4824 - val_loss: 18656.0977\n",
      "Epoch 742/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14325.7158 - val_loss: 18652.7441\n",
      "Epoch 743/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14301.7754 - val_loss: 18607.5938\n",
      "Epoch 744/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14285.5049 - val_loss: 18577.5938\n",
      "Epoch 745/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14269.0566 - val_loss: 18563.0820\n",
      "Epoch 746/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14252.1201 - val_loss: 18545.7969\n",
      "Epoch 747/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14231.6543 - val_loss: 18537.4121\n",
      "Epoch 748/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14214.2715 - val_loss: 18519.9531\n",
      "Epoch 749/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14199.3691 - val_loss: 18488.9727\n",
      "Epoch 750/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14179.9326 - val_loss: 18468.9316\n",
      "Epoch 751/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14168.8613 - val_loss: 18453.3652\n",
      "Epoch 752/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14145.3936 - val_loss: 18411.9316\n",
      "Epoch 753/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14128.9395 - val_loss: 18413.3379\n",
      "Epoch 754/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14116.1484 - val_loss: 18380.8281\n",
      "Epoch 755/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14092.0596 - val_loss: 18349.8379\n",
      "Epoch 756/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14088.3828 - val_loss: 18320.7188\n",
      "Epoch 757/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14060.2266 - val_loss: 18321.8555\n",
      "Epoch 758/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14042.0938 - val_loss: 18299.4102\n",
      "Epoch 759/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14021.6797 - val_loss: 18268.1465\n",
      "Epoch 760/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14007.4785 - val_loss: 18232.4297\n",
      "Epoch 761/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13991.2998 - val_loss: 18222.6465\n",
      "Epoch 762/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13981.0723 - val_loss: 18236.5898\n",
      "Epoch 763/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13962.1152 - val_loss: 18182.1328\n",
      "Epoch 764/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13934.4082 - val_loss: 18161.5098\n",
      "Epoch 765/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13922.6074 - val_loss: 18148.0879\n",
      "Epoch 766/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13903.6973 - val_loss: 18119.3867\n",
      "Epoch 767/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13884.7812 - val_loss: 18109.3086\n",
      "Epoch 768/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13870.0596 - val_loss: 18049.9121\n",
      "Epoch 769/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13853.6201 - val_loss: 18054.7871\n",
      "Epoch 770/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13828.5840 - val_loss: 18003.4219\n",
      "Epoch 771/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13815.3262 - val_loss: 17961.1504\n",
      "Epoch 772/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13797.4268 - val_loss: 17969.1777\n",
      "Epoch 773/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13771.1270 - val_loss: 17931.1992\n",
      "Epoch 774/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13765.8721 - val_loss: 17930.5879\n",
      "Epoch 775/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13740.3496 - val_loss: 17890.7598\n",
      "Epoch 776/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13728.2285 - val_loss: 17859.0723\n",
      "Epoch 777/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13704.2656 - val_loss: 17877.3945\n",
      "Epoch 778/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13685.5156 - val_loss: 17849.9414\n",
      "Epoch 779/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13679.0283 - val_loss: 17790.8770\n",
      "Epoch 780/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13658.6436 - val_loss: 17823.0195\n",
      "Epoch 781/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13632.9658 - val_loss: 17779.6055\n",
      "Epoch 782/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13613.0098 - val_loss: 17747.6543\n",
      "Epoch 783/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13597.7842 - val_loss: 17698.4844\n",
      "Epoch 784/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13585.6855 - val_loss: 17703.2188\n",
      "Epoch 785/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13560.0156 - val_loss: 17676.8340\n",
      "Epoch 786/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13540.8359 - val_loss: 17652.8535\n",
      "Epoch 787/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13523.9482 - val_loss: 17631.3242\n",
      "Epoch 788/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13500.8516 - val_loss: 17610.3867\n",
      "Epoch 789/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13502.9219 - val_loss: 17557.1348\n",
      "Epoch 790/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13474.4355 - val_loss: 17567.2207\n",
      "Epoch 791/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13455.9199 - val_loss: 17546.8633\n",
      "Epoch 792/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13435.0420 - val_loss: 17504.3398\n",
      "Epoch 793/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13415.1094 - val_loss: 17498.3438\n",
      "Epoch 794/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13393.1299 - val_loss: 17472.4121\n",
      "Epoch 795/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13378.9590 - val_loss: 17444.5273\n",
      "Epoch 796/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13359.6328 - val_loss: 17445.4316\n",
      "Epoch 797/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13345.1748 - val_loss: 17400.3340\n",
      "Epoch 798/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13324.0029 - val_loss: 17374.5410\n",
      "Epoch 799/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13314.4873 - val_loss: 17370.2090\n",
      "Epoch 800/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13299.3076 - val_loss: 17315.9844\n",
      "Epoch 801/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13277.1465 - val_loss: 17280.0430\n",
      "Epoch 802/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13259.6875 - val_loss: 17294.3320\n",
      "Epoch 803/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13240.6221 - val_loss: 17253.8496\n",
      "Epoch 804/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13218.7422 - val_loss: 17249.1094\n",
      "Epoch 805/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13200.6035 - val_loss: 17205.3633\n",
      "Epoch 806/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13181.9736 - val_loss: 17186.8789\n",
      "Epoch 807/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13166.2441 - val_loss: 17161.3867\n",
      "Epoch 808/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13142.2422 - val_loss: 17150.7617\n",
      "Epoch 809/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13133.6582 - val_loss: 17134.0938\n",
      "Epoch 810/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13106.8975 - val_loss: 17099.7227\n",
      "Epoch 811/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13097.7754 - val_loss: 17055.2598\n",
      "Epoch 812/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13077.0918 - val_loss: 17049.7871\n",
      "Epoch 813/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 13061.9951 - val_loss: 17006.5566\n",
      "Epoch 814/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13044.0166 - val_loss: 16990.6699\n",
      "Epoch 815/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13022.4736 - val_loss: 16997.7246\n",
      "Epoch 816/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13004.4092 - val_loss: 16953.2812\n",
      "Epoch 817/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12991.9961 - val_loss: 16900.9980\n",
      "Epoch 818/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12975.7754 - val_loss: 16892.4590\n",
      "Epoch 819/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12948.6436 - val_loss: 16886.2539\n",
      "Epoch 820/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12932.3721 - val_loss: 16854.0312\n",
      "Epoch 821/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12912.5957 - val_loss: 16835.2461\n",
      "Epoch 822/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12900.0938 - val_loss: 16811.7090\n",
      "Epoch 823/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12878.7051 - val_loss: 16791.0352\n",
      "Epoch 824/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12862.6357 - val_loss: 16762.3594\n",
      "Epoch 825/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12869.4414 - val_loss: 16695.0430\n",
      "Epoch 826/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12831.7725 - val_loss: 16706.0039\n",
      "Epoch 827/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12810.2441 - val_loss: 16689.3945\n",
      "Epoch 828/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12789.7646 - val_loss: 16657.7441\n",
      "Epoch 829/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12770.4941 - val_loss: 16642.3867\n",
      "Epoch 830/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12752.0273 - val_loss: 16593.2754\n",
      "Epoch 831/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12737.9287 - val_loss: 16577.3652\n",
      "Epoch 832/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12717.8525 - val_loss: 16586.7148\n",
      "Epoch 833/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12702.0605 - val_loss: 16553.6836\n",
      "Epoch 834/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12679.5498 - val_loss: 16531.0508\n",
      "Epoch 835/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12665.2295 - val_loss: 16523.0723\n",
      "Epoch 836/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12651.6191 - val_loss: 16480.1758\n",
      "Epoch 837/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12628.2920 - val_loss: 16426.3125\n",
      "Epoch 838/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12610.2295 - val_loss: 16404.5527\n",
      "Epoch 839/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12593.8457 - val_loss: 16387.3613\n",
      "Epoch 840/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12575.4951 - val_loss: 16375.4531\n",
      "Epoch 841/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12559.9043 - val_loss: 16336.9473\n",
      "Epoch 842/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12549.6445 - val_loss: 16364.7939\n",
      "Epoch 843/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12532.7168 - val_loss: 16316.3809\n",
      "Epoch 844/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12504.7607 - val_loss: 16297.5371\n",
      "Epoch 845/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12488.0029 - val_loss: 16277.2217\n",
      "Epoch 846/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12473.2578 - val_loss: 16222.0518\n",
      "Epoch 847/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12448.9248 - val_loss: 16213.3340\n",
      "Epoch 848/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12434.8184 - val_loss: 16184.0762\n",
      "Epoch 849/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12409.0127 - val_loss: 16177.1270\n",
      "Epoch 850/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12392.7344 - val_loss: 16159.5332\n",
      "Epoch 851/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12376.1729 - val_loss: 16125.2344\n",
      "Epoch 852/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12360.7021 - val_loss: 16118.3408\n",
      "Epoch 853/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12342.6514 - val_loss: 16059.1816\n",
      "Epoch 854/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12323.6738 - val_loss: 16043.1230\n",
      "Epoch 855/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12316.7900 - val_loss: 16033.4688\n",
      "Epoch 856/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12286.9668 - val_loss: 15983.0186\n",
      "Epoch 857/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12271.6865 - val_loss: 15970.5127\n",
      "Epoch 858/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12248.7783 - val_loss: 15951.1094\n",
      "Epoch 859/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12248.3848 - val_loss: 15945.1855\n",
      "Epoch 860/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12210.8594 - val_loss: 15901.0254\n",
      "Epoch 861/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12203.3721 - val_loss: 15855.9707\n",
      "Epoch 862/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12182.5918 - val_loss: 15840.0059\n",
      "Epoch 863/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12182.7188 - val_loss: 15859.2373\n",
      "Epoch 864/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12145.8721 - val_loss: 15802.1611\n",
      "Epoch 865/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12126.4365 - val_loss: 15761.0137\n",
      "Epoch 866/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12113.2461 - val_loss: 15728.9316\n",
      "Epoch 867/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12090.4502 - val_loss: 15711.4902\n",
      "Epoch 868/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12072.6279 - val_loss: 15707.0723\n",
      "Epoch 869/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12049.4160 - val_loss: 15673.5312\n",
      "Epoch 870/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12034.7197 - val_loss: 15635.6875\n",
      "Epoch 871/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12020.3232 - val_loss: 15645.1719\n",
      "Epoch 872/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11994.0781 - val_loss: 15591.2500\n",
      "Epoch 873/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11974.3594 - val_loss: 15565.7158\n",
      "Epoch 874/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11952.2129 - val_loss: 15559.5156\n",
      "Epoch 875/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11936.8887 - val_loss: 15543.5938\n",
      "Epoch 876/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11913.3428 - val_loss: 15504.7910\n",
      "Epoch 877/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11901.0234 - val_loss: 15476.0215\n",
      "Epoch 878/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11880.1445 - val_loss: 15468.3184\n",
      "Epoch 879/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11861.6562 - val_loss: 15445.5371\n",
      "Epoch 880/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11843.4092 - val_loss: 15406.7783\n",
      "Epoch 881/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11823.3223 - val_loss: 15369.2012\n",
      "Epoch 882/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11801.7334 - val_loss: 15349.1748\n",
      "Epoch 883/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11782.0811 - val_loss: 15342.8721\n",
      "Epoch 884/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11764.8115 - val_loss: 15311.9893\n",
      "Epoch 885/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11743.0146 - val_loss: 15279.3936\n",
      "Epoch 886/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11729.0332 - val_loss: 15252.5420\n",
      "Epoch 887/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 11711.7266 - val_loss: 15224.1455\n",
      "Epoch 888/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11689.8301 - val_loss: 15222.2168\n",
      "Epoch 889/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11675.6973 - val_loss: 15183.5781\n",
      "Epoch 890/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11657.4111 - val_loss: 15131.6328\n",
      "Epoch 891/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11640.5840 - val_loss: 15125.2285\n",
      "Epoch 892/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11617.3203 - val_loss: 15091.7393\n",
      "Epoch 893/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11592.9814 - val_loss: 15088.9160\n",
      "Epoch 894/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11580.8066 - val_loss: 15043.7217\n",
      "Epoch 895/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11560.5557 - val_loss: 15007.2363\n",
      "Epoch 896/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11542.4375 - val_loss: 15016.0449\n",
      "Epoch 897/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11519.4551 - val_loss: 14982.5625\n",
      "Epoch 898/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11508.5420 - val_loss: 14927.6514\n",
      "Epoch 899/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11483.1953 - val_loss: 14929.6934\n",
      "Epoch 900/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11463.6201 - val_loss: 14884.1826\n",
      "Epoch 901/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11444.3936 - val_loss: 14859.8877\n",
      "Epoch 902/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11427.5605 - val_loss: 14837.4346\n",
      "Epoch 903/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11401.9980 - val_loss: 14795.9844\n",
      "Epoch 904/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11387.3135 - val_loss: 14782.2871\n",
      "Epoch 905/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11368.6309 - val_loss: 14763.0811\n",
      "Epoch 906/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11347.4717 - val_loss: 14722.3066\n",
      "Epoch 907/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11331.2441 - val_loss: 14692.0059\n",
      "Epoch 908/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11316.0000 - val_loss: 14666.8750\n",
      "Epoch 909/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11292.5996 - val_loss: 14615.2734\n",
      "Epoch 910/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11271.5303 - val_loss: 14591.8848\n",
      "Epoch 911/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11256.6826 - val_loss: 14552.3467\n",
      "Epoch 912/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11237.9844 - val_loss: 14513.1641\n",
      "Epoch 913/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11211.1826 - val_loss: 14509.0996\n",
      "Epoch 914/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11198.8242 - val_loss: 14472.4160\n",
      "Epoch 915/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11184.1738 - val_loss: 14472.3105\n",
      "Epoch 916/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11159.0371 - val_loss: 14428.5137\n",
      "Epoch 917/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11139.3857 - val_loss: 14386.5186\n",
      "Epoch 918/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11122.6973 - val_loss: 14350.4561\n",
      "Epoch 919/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11114.5312 - val_loss: 14358.1279\n",
      "Epoch 920/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11094.1904 - val_loss: 14301.1719\n",
      "Epoch 921/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11069.2939 - val_loss: 14287.9873\n",
      "Epoch 922/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11053.2637 - val_loss: 14238.6533\n",
      "Epoch 923/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11040.7705 - val_loss: 14257.6377\n",
      "Epoch 924/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11018.3174 - val_loss: 14217.0078\n",
      "Epoch 925/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10993.0488 - val_loss: 14177.6777\n",
      "Epoch 926/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10979.1094 - val_loss: 14125.2246\n",
      "Epoch 927/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10971.5742 - val_loss: 14104.2656\n",
      "Epoch 928/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10949.2324 - val_loss: 14055.4717\n",
      "Epoch 929/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10926.8770 - val_loss: 14045.9238\n",
      "Epoch 930/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10908.5840 - val_loss: 14024.0996\n",
      "Epoch 931/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10905.4580 - val_loss: 14030.3574\n",
      "Epoch 932/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10882.9131 - val_loss: 13969.3623\n",
      "Epoch 933/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10860.2559 - val_loss: 13942.8750\n",
      "Epoch 934/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10831.4531 - val_loss: 13911.2842\n",
      "Epoch 935/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10823.9707 - val_loss: 13897.4453\n",
      "Epoch 936/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10802.6377 - val_loss: 13870.1279\n",
      "Epoch 937/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10784.3418 - val_loss: 13824.7080\n",
      "Epoch 938/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10765.5781 - val_loss: 13790.1611\n",
      "Epoch 939/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10751.5771 - val_loss: 13749.2090\n",
      "Epoch 940/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10730.7178 - val_loss: 13734.8311\n",
      "Epoch 941/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10710.8340 - val_loss: 13728.0957\n",
      "Epoch 942/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10696.6904 - val_loss: 13702.4951\n",
      "Epoch 943/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10685.2148 - val_loss: 13663.4141\n",
      "Epoch 944/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10672.0166 - val_loss: 13633.1406\n",
      "Epoch 945/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10645.9512 - val_loss: 13583.8125\n",
      "Epoch 946/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10632.7402 - val_loss: 13566.0703\n",
      "Epoch 947/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10624.7266 - val_loss: 13514.7764\n",
      "Epoch 948/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10594.9062 - val_loss: 13518.7754\n",
      "Epoch 949/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10583.7568 - val_loss: 13497.0342\n",
      "Epoch 950/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10563.7812 - val_loss: 13463.6592\n",
      "Epoch 951/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10549.7344 - val_loss: 13442.0518\n",
      "Epoch 952/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10538.9609 - val_loss: 13385.8096\n",
      "Epoch 953/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10517.6973 - val_loss: 13367.3184\n",
      "Epoch 954/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10509.3633 - val_loss: 13369.9502\n",
      "Epoch 955/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10485.2441 - val_loss: 13312.9004\n",
      "Epoch 956/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10466.6602 - val_loss: 13278.0342\n",
      "Epoch 957/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10446.9590 - val_loss: 13257.3691\n",
      "Epoch 958/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10433.7793 - val_loss: 13251.8965\n",
      "Epoch 959/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10416.9561 - val_loss: 13205.8486\n",
      "Epoch 960/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10404.5137 - val_loss: 13185.2471\n",
      "Epoch 961/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 10383.2910 - val_loss: 13154.7910\n",
      "Epoch 962/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10374.3184 - val_loss: 13145.8281\n",
      "Epoch 963/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10351.0049 - val_loss: 13084.3145\n",
      "Epoch 964/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10333.0205 - val_loss: 13037.0820\n",
      "Epoch 965/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10319.1514 - val_loss: 12985.3418\n",
      "Epoch 966/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10297.1406 - val_loss: 12972.7412\n",
      "Epoch 967/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10282.7715 - val_loss: 12963.9375\n",
      "Epoch 968/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10262.9473 - val_loss: 12926.8145\n",
      "Epoch 969/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10254.1211 - val_loss: 12920.8379\n",
      "Epoch 970/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10231.6973 - val_loss: 12858.0801\n",
      "Epoch 971/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10218.3145 - val_loss: 12820.2197\n",
      "Epoch 972/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10198.2500 - val_loss: 12795.0078\n",
      "Epoch 973/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10181.5381 - val_loss: 12768.2686\n",
      "Epoch 974/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10166.6504 - val_loss: 12759.8652\n",
      "Epoch 975/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10144.8076 - val_loss: 12732.9521\n",
      "Epoch 976/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10134.6045 - val_loss: 12682.6182\n",
      "Epoch 977/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10109.5156 - val_loss: 12674.8867\n",
      "Epoch 978/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10093.9629 - val_loss: 12632.9629\n",
      "Epoch 979/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10079.8945 - val_loss: 12580.9346\n",
      "Epoch 980/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10068.9385 - val_loss: 12597.9385\n",
      "Epoch 981/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10057.4365 - val_loss: 12530.8115\n",
      "Epoch 982/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10030.8330 - val_loss: 12494.3018\n",
      "Epoch 983/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10010.4531 - val_loss: 12454.5479\n",
      "Epoch 984/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9997.5127 - val_loss: 12413.9473\n",
      "Epoch 985/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9973.0957 - val_loss: 12400.5215\n",
      "Epoch 986/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9967.2158 - val_loss: 12376.7246\n",
      "Epoch 987/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9945.1074 - val_loss: 12320.8867\n",
      "Epoch 988/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9938.7695 - val_loss: 12279.3877\n",
      "Epoch 989/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9911.0889 - val_loss: 12238.0137\n",
      "Epoch 990/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9893.1289 - val_loss: 12238.8926\n",
      "Epoch 991/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9875.5967 - val_loss: 12209.8965\n",
      "Epoch 992/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9872.2637 - val_loss: 12132.4004\n",
      "Epoch 993/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9847.4775 - val_loss: 12148.5439\n",
      "Epoch 994/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9843.0771 - val_loss: 12131.4443\n",
      "Epoch 995/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9815.8369 - val_loss: 12074.2441\n",
      "Epoch 996/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9806.2285 - val_loss: 12042.3311\n",
      "Epoch 997/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9787.8066 - val_loss: 12027.1221\n",
      "Epoch 998/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9784.9033 - val_loss: 12036.7324\n",
      "Epoch 999/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9752.7510 - val_loss: 11978.1934\n",
      "Epoch 1000/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9752.9678 - val_loss: 11977.7285\n",
      "Epoch 1001/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9723.2520 - val_loss: 11956.7314\n",
      "Epoch 1002/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9709.7998 - val_loss: 11902.9453\n",
      "Epoch 1003/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9711.9590 - val_loss: 11880.5938\n",
      "Epoch 1004/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9679.6660 - val_loss: 11880.7969\n",
      "Epoch 1005/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9671.1777 - val_loss: 11872.3096\n",
      "Epoch 1006/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9653.8311 - val_loss: 11816.9209\n",
      "Epoch 1007/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9641.6230 - val_loss: 11811.0752\n",
      "Epoch 1008/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9633.5586 - val_loss: 11794.7920\n",
      "Epoch 1009/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9605.8945 - val_loss: 11749.7500\n",
      "Epoch 1010/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9594.4707 - val_loss: 11749.0312\n",
      "Epoch 1011/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9578.1035 - val_loss: 11723.1865\n",
      "Epoch 1012/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9568.6895 - val_loss: 11699.8164\n",
      "Epoch 1013/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9551.8965 - val_loss: 11655.4326\n",
      "Epoch 1014/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9542.1230 - val_loss: 11655.8594\n",
      "Epoch 1015/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9517.4639 - val_loss: 11641.5439\n",
      "Epoch 1016/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9507.9824 - val_loss: 11582.2080\n",
      "Epoch 1017/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9497.7119 - val_loss: 11596.4561\n",
      "Epoch 1018/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9473.1299 - val_loss: 11572.8564\n",
      "Epoch 1019/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9462.2363 - val_loss: 11538.5654\n",
      "Epoch 1020/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9441.0293 - val_loss: 11519.8994\n",
      "Epoch 1021/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9435.0107 - val_loss: 11501.5469\n",
      "Epoch 1022/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9411.4824 - val_loss: 11473.2236\n",
      "Epoch 1023/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9403.2705 - val_loss: 11460.0088\n",
      "Epoch 1024/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9388.7441 - val_loss: 11441.5166\n",
      "Epoch 1025/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9370.7217 - val_loss: 11414.2725\n",
      "Epoch 1026/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9356.8389 - val_loss: 11394.5254\n",
      "Epoch 1027/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9348.6357 - val_loss: 11405.9473\n",
      "Epoch 1028/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9331.7490 - val_loss: 11355.9844\n",
      "Epoch 1029/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9329.3877 - val_loss: 11323.2207\n",
      "Epoch 1030/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9308.8066 - val_loss: 11341.9316\n",
      "Epoch 1031/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9291.9004 - val_loss: 11327.4551\n",
      "Epoch 1032/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9279.3574 - val_loss: 11291.3457\n",
      "Epoch 1033/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9271.1094 - val_loss: 11262.5127\n",
      "Epoch 1034/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9252.0547 - val_loss: 11281.3984\n",
      "Epoch 1035/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9246.8936 - val_loss: 11212.8652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1036/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9235.4570 - val_loss: 11196.9160\n",
      "Epoch 1037/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9213.5879 - val_loss: 11197.0020\n",
      "Epoch 1038/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9196.2734 - val_loss: 11177.0244\n",
      "Epoch 1039/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9183.7471 - val_loss: 11169.1904\n",
      "Epoch 1040/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9171.7275 - val_loss: 11116.5957\n",
      "Epoch 1041/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9166.4551 - val_loss: 11124.9307\n",
      "Epoch 1042/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9155.6729 - val_loss: 11131.8965\n",
      "Epoch 1043/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9138.6250 - val_loss: 11072.2949\n",
      "Epoch 1044/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9127.5518 - val_loss: 11068.4570\n",
      "Epoch 1045/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9121.4707 - val_loss: 11058.9160\n",
      "Epoch 1046/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9108.9668 - val_loss: 11059.5225\n",
      "Epoch 1047/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9101.0342 - val_loss: 11057.9258\n",
      "Epoch 1048/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9095.7344 - val_loss: 11026.4131\n",
      "Epoch 1049/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9092.2158 - val_loss: 11009.3809\n",
      "Epoch 1050/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9068.6963 - val_loss: 11069.0293\n",
      "Epoch 1051/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9080.5488 - val_loss: 11062.7324\n",
      "Epoch 1052/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9061.0947 - val_loss: 11017.0059\n",
      "Epoch 1053/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9058.8301 - val_loss: 10971.3262\n",
      "Epoch 1054/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9040.4141 - val_loss: 10965.9258\n",
      "Epoch 1055/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9032.2939 - val_loss: 10973.4727\n",
      "Epoch 1056/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9023.0918 - val_loss: 10972.0469\n",
      "Epoch 1057/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9009.6914 - val_loss: 10937.3438\n",
      "Epoch 1058/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9007.3457 - val_loss: 10925.4512\n",
      "Epoch 1059/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8996.7949 - val_loss: 10916.0293\n",
      "Epoch 1060/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8986.9482 - val_loss: 10904.8291\n",
      "Epoch 1061/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8975.6855 - val_loss: 10899.7285\n",
      "Epoch 1062/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8969.5117 - val_loss: 10878.4668\n",
      "Epoch 1063/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8961.9473 - val_loss: 10871.6143\n",
      "Epoch 1064/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8955.0020 - val_loss: 10876.9639\n",
      "Epoch 1065/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8941.4824 - val_loss: 10869.2363\n",
      "Epoch 1066/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8942.2119 - val_loss: 10859.0400\n",
      "Epoch 1067/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8926.0068 - val_loss: 10828.3047\n",
      "Epoch 1068/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8930.5996 - val_loss: 10838.3057\n",
      "Epoch 1069/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8914.4326 - val_loss: 10838.5859\n",
      "Epoch 1070/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8919.8643 - val_loss: 10821.4619\n",
      "Epoch 1071/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8901.1689 - val_loss: 10854.6709\n",
      "Epoch 1072/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8890.3418 - val_loss: 10840.9678\n",
      "Epoch 1073/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8894.2275 - val_loss: 10859.6533\n",
      "Epoch 1074/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8875.6523 - val_loss: 10837.9971\n",
      "Epoch 1075/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8880.0947 - val_loss: 10800.4434\n",
      "Epoch 1076/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8866.3887 - val_loss: 10852.6152\n",
      "Epoch 1077/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8858.0967 - val_loss: 10845.9414\n",
      "Epoch 1078/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8857.1475 - val_loss: 10799.6924\n",
      "Epoch 1079/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8836.9023 - val_loss: 10821.7012\n",
      "Epoch 1080/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8830.6475 - val_loss: 10805.2285\n",
      "Epoch 1081/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8820.5225 - val_loss: 10807.8691\n",
      "Epoch 1082/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8815.3877 - val_loss: 10804.5576\n",
      "Epoch 1083/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8802.9541 - val_loss: 10807.9668\n",
      "Epoch 1084/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8793.2188 - val_loss: 10819.9902\n",
      "Epoch 1085/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8797.1230 - val_loss: 10798.9551\n",
      "Epoch 1086/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8781.4902 - val_loss: 10814.7988\n",
      "Epoch 1087/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8778.0703 - val_loss: 10788.1621\n",
      "Epoch 1088/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8765.0752 - val_loss: 10780.4424\n",
      "Epoch 1089/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8753.9541 - val_loss: 10785.6777\n",
      "Epoch 1090/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8747.8662 - val_loss: 10769.6465\n",
      "Epoch 1091/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8744.2217 - val_loss: 10783.8457\n",
      "Epoch 1092/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8740.3340 - val_loss: 10782.6309\n",
      "Epoch 1093/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8737.3857 - val_loss: 10768.0273\n",
      "Epoch 1094/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8723.0986 - val_loss: 10796.4629\n",
      "Epoch 1095/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8712.9434 - val_loss: 10756.1543\n",
      "Epoch 1096/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8705.0293 - val_loss: 10764.7051\n",
      "Epoch 1097/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8692.0264 - val_loss: 10775.2080\n",
      "Epoch 1098/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8698.6260 - val_loss: 10792.2822\n",
      "Epoch 1099/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8681.8223 - val_loss: 10757.4443\n",
      "Epoch 1100/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8683.7109 - val_loss: 10735.3857\n",
      "Epoch 1101/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8661.9961 - val_loss: 10761.9785\n",
      "Epoch 1102/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8664.0215 - val_loss: 10758.3066\n",
      "Epoch 1103/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8652.7588 - val_loss: 10732.0557\n",
      "Epoch 1104/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8639.5596 - val_loss: 10737.1680\n",
      "Epoch 1105/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8633.4023 - val_loss: 10730.2617\n",
      "Epoch 1106/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8627.9922 - val_loss: 10753.6797\n",
      "Epoch 1107/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8623.2539 - val_loss: 10722.0264\n",
      "Epoch 1108/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8610.9248 - val_loss: 10682.9141\n",
      "Epoch 1109/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8612.2637 - val_loss: 10700.9160\n",
      "Epoch 1110/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 8592.0000 - val_loss: 10713.8838\n",
      "Epoch 1111/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8584.4482 - val_loss: 10700.1699\n",
      "Epoch 1112/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8579.3848 - val_loss: 10687.2988\n",
      "Epoch 1113/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8566.5645 - val_loss: 10670.9238\n",
      "Epoch 1114/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8572.4287 - val_loss: 10690.9209\n",
      "Epoch 1115/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8562.0996 - val_loss: 10654.6816\n",
      "Epoch 1116/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8546.3955 - val_loss: 10668.8906\n",
      "Epoch 1117/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8544.2764 - val_loss: 10682.0059\n",
      "Epoch 1118/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8544.9512 - val_loss: 10653.3691\n",
      "Epoch 1119/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8529.2861 - val_loss: 10672.2793\n",
      "Epoch 1120/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8526.1016 - val_loss: 10634.0439\n",
      "Epoch 1121/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8517.5293 - val_loss: 10637.2539\n",
      "Epoch 1122/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8510.2520 - val_loss: 10655.7480\n",
      "Epoch 1123/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8506.3906 - val_loss: 10655.4385\n",
      "Epoch 1124/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8493.2129 - val_loss: 10642.4199\n",
      "Epoch 1125/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8490.6904 - val_loss: 10660.3535\n",
      "Epoch 1126/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8481.7949 - val_loss: 10650.5283\n",
      "Epoch 1127/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8470.3975 - val_loss: 10625.1035\n",
      "Epoch 1128/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8462.5742 - val_loss: 10612.2344\n",
      "Epoch 1129/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8455.3223 - val_loss: 10617.7617\n",
      "Epoch 1130/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8448.6777 - val_loss: 10604.5830\n",
      "Epoch 1131/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8444.2480 - val_loss: 10604.5244\n",
      "Epoch 1132/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8438.4590 - val_loss: 10610.4355\n",
      "Epoch 1133/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8431.2676 - val_loss: 10608.5879\n",
      "Epoch 1134/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8419.1123 - val_loss: 10597.6631\n",
      "Epoch 1135/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8413.9980 - val_loss: 10574.9707\n",
      "Epoch 1136/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8400.9893 - val_loss: 10587.2070\n",
      "Epoch 1137/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8408.9951 - val_loss: 10600.2793\n",
      "Epoch 1138/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8405.8604 - val_loss: 10546.0322\n",
      "Epoch 1139/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8399.6221 - val_loss: 10611.1484\n",
      "Epoch 1140/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8380.1416 - val_loss: 10609.8867\n",
      "Epoch 1141/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8371.7383 - val_loss: 10594.9453\n",
      "Epoch 1142/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8392.2539 - val_loss: 10529.5918\n",
      "Epoch 1143/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8363.1689 - val_loss: 10542.0596\n",
      "Epoch 1144/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8350.9111 - val_loss: 10604.3896\n",
      "Epoch 1145/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8356.2559 - val_loss: 10605.3770\n",
      "Epoch 1146/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8346.0127 - val_loss: 10579.0742\n",
      "Epoch 1147/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8332.1982 - val_loss: 10529.6777\n",
      "Epoch 1148/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8325.0537 - val_loss: 10537.2812\n",
      "Epoch 1149/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8317.8828 - val_loss: 10557.9443\n",
      "Epoch 1150/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8305.2324 - val_loss: 10544.3115\n",
      "Epoch 1151/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8320.4609 - val_loss: 10528.0068\n",
      "Epoch 1152/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8307.0508 - val_loss: 10569.8555\n",
      "Epoch 1153/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8281.1348 - val_loss: 10533.6182\n",
      "Epoch 1154/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8277.3604 - val_loss: 10489.2432\n",
      "Epoch 1155/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8282.6113 - val_loss: 10491.1318\n",
      "Epoch 1156/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8265.0244 - val_loss: 10540.6582\n",
      "Epoch 1157/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8261.2441 - val_loss: 10519.8223\n",
      "Epoch 1158/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8250.7773 - val_loss: 10497.3730\n",
      "Epoch 1159/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8248.0674 - val_loss: 10528.5488\n",
      "Epoch 1160/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8239.9395 - val_loss: 10509.1924\n",
      "Epoch 1161/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8229.0605 - val_loss: 10494.6074\n",
      "Epoch 1162/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8222.6797 - val_loss: 10470.2041\n",
      "Epoch 1163/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8213.4316 - val_loss: 10491.5508\n",
      "Epoch 1164/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8209.9893 - val_loss: 10483.7637\n",
      "Epoch 1165/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8202.9795 - val_loss: 10475.1953\n",
      "Epoch 1166/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8202.9814 - val_loss: 10458.8223\n",
      "Epoch 1167/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8185.6367 - val_loss: 10452.0352\n",
      "Epoch 1168/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8182.2368 - val_loss: 10479.0703\n",
      "Epoch 1169/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8178.8242 - val_loss: 10443.6807\n",
      "Epoch 1170/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8169.9985 - val_loss: 10437.0498\n",
      "Epoch 1171/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8160.7124 - val_loss: 10448.0195\n",
      "Epoch 1172/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8150.5000 - val_loss: 10454.8184\n",
      "Epoch 1173/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8157.1797 - val_loss: 10417.9551\n",
      "Epoch 1174/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8140.6040 - val_loss: 10438.4033\n",
      "Epoch 1175/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8134.1680 - val_loss: 10448.5732\n",
      "Epoch 1176/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8132.2554 - val_loss: 10420.0332\n",
      "Epoch 1177/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8114.4326 - val_loss: 10414.6113\n",
      "Epoch 1178/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8112.6890 - val_loss: 10433.7354\n",
      "Epoch 1179/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8098.2407 - val_loss: 10432.8379\n",
      "Epoch 1180/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8101.1875 - val_loss: 10395.7939\n",
      "Epoch 1181/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8084.6982 - val_loss: 10419.4375\n",
      "Epoch 1182/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8078.9814 - val_loss: 10431.8545\n",
      "Epoch 1183/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8073.8491 - val_loss: 10411.4463\n",
      "Epoch 1184/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 8056.5068 - val_loss: 10372.0928\n",
      "Epoch 1185/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8054.5967 - val_loss: 10387.3242\n",
      "Epoch 1186/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8044.5327 - val_loss: 10365.5908\n",
      "Epoch 1187/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8044.2734 - val_loss: 10424.4707\n",
      "Epoch 1188/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8033.7266 - val_loss: 10382.7988\n",
      "Epoch 1189/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8024.4092 - val_loss: 10380.4824\n",
      "Epoch 1190/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8024.6577 - val_loss: 10350.9023\n",
      "Epoch 1191/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8004.6616 - val_loss: 10363.6211\n",
      "Epoch 1192/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7995.8774 - val_loss: 10370.4434\n",
      "Epoch 1193/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7983.9561 - val_loss: 10357.3770\n",
      "Epoch 1194/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7981.4702 - val_loss: 10380.2451\n",
      "Epoch 1195/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7975.5811 - val_loss: 10335.8545\n",
      "Epoch 1196/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7985.8423 - val_loss: 10405.6299\n",
      "Epoch 1197/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7966.2407 - val_loss: 10389.2246\n",
      "Epoch 1198/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7949.7798 - val_loss: 10338.9746\n",
      "Epoch 1199/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7942.1250 - val_loss: 10338.8613\n",
      "Epoch 1200/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7929.5322 - val_loss: 10342.1855\n",
      "Epoch 1201/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7935.6260 - val_loss: 10352.2168\n",
      "Epoch 1202/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7919.8506 - val_loss: 10315.3145\n",
      "Epoch 1203/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7903.1079 - val_loss: 10331.6182\n",
      "Epoch 1204/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7905.9751 - val_loss: 10319.7822\n",
      "Epoch 1205/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7896.5850 - val_loss: 10308.8711\n",
      "Epoch 1206/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7887.0859 - val_loss: 10314.4316\n",
      "Epoch 1207/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7885.0171 - val_loss: 10323.9150\n",
      "Epoch 1208/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7877.6445 - val_loss: 10302.4980\n",
      "Epoch 1209/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7871.0508 - val_loss: 10320.8867\n",
      "Epoch 1210/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7872.2939 - val_loss: 10304.7148\n",
      "Epoch 1211/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7858.5498 - val_loss: 10337.1768\n",
      "Epoch 1212/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7855.9336 - val_loss: 10335.4502\n",
      "Epoch 1213/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7848.5103 - val_loss: 10320.1230\n",
      "Epoch 1214/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7842.4468 - val_loss: 10335.2236\n",
      "Epoch 1215/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7835.9912 - val_loss: 10341.7051\n",
      "Epoch 1216/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7857.0049 - val_loss: 10376.0547\n",
      "Epoch 1217/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7828.2705 - val_loss: 10308.8291\n",
      "Epoch 1218/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7814.7827 - val_loss: 10327.4883\n",
      "Epoch 1219/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7813.3687 - val_loss: 10327.5068\n",
      "Epoch 1220/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7806.7256 - val_loss: 10335.5635\n",
      "Epoch 1221/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7799.6821 - val_loss: 10343.6885\n",
      "Epoch 1222/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7799.3462 - val_loss: 10336.3672\n",
      "Epoch 1223/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7793.7334 - val_loss: 10304.6152\n",
      "Epoch 1224/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7785.7944 - val_loss: 10322.1309\n",
      "Epoch 1225/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7781.8491 - val_loss: 10313.9863\n",
      "Epoch 1226/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7771.0415 - val_loss: 10319.3574\n",
      "Epoch 1227/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7766.6172 - val_loss: 10295.3809\n",
      "Epoch 1228/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7755.8608 - val_loss: 10296.5361\n",
      "Epoch 1229/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7752.1030 - val_loss: 10314.0059\n",
      "Epoch 1230/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7741.8726 - val_loss: 10286.4004\n",
      "Epoch 1231/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7737.4463 - val_loss: 10305.7480\n",
      "Epoch 1232/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7735.1616 - val_loss: 10287.9883\n",
      "Epoch 1233/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7725.2627 - val_loss: 10284.7627\n",
      "Epoch 1234/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7715.7134 - val_loss: 10285.7529\n",
      "Epoch 1235/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7709.6318 - val_loss: 10259.9316\n",
      "Epoch 1236/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7709.1226 - val_loss: 10268.3340\n",
      "Epoch 1237/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7700.3701 - val_loss: 10243.6611\n",
      "Epoch 1238/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7691.3857 - val_loss: 10266.3008\n",
      "Epoch 1239/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7689.7061 - val_loss: 10240.1162\n",
      "Epoch 1240/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7686.5400 - val_loss: 10265.3730\n",
      "Epoch 1241/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7671.6899 - val_loss: 10240.5547\n",
      "Epoch 1242/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7664.2549 - val_loss: 10244.7432\n",
      "Epoch 1243/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7655.1851 - val_loss: 10217.7510\n",
      "Epoch 1244/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7664.8867 - val_loss: 10204.8701\n",
      "Epoch 1245/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7662.3140 - val_loss: 10248.4297\n",
      "Epoch 1246/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7647.9507 - val_loss: 10194.9609\n",
      "Epoch 1247/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7657.4600 - val_loss: 10155.8809\n",
      "Epoch 1248/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7639.2446 - val_loss: 10180.7695\n",
      "Epoch 1249/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7629.3452 - val_loss: 10201.7754\n",
      "Epoch 1250/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7628.4717 - val_loss: 10187.8887\n",
      "Epoch 1251/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7616.6265 - val_loss: 10169.8066\n",
      "Epoch 1252/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7615.8193 - val_loss: 10177.6807\n",
      "Epoch 1253/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7611.1748 - val_loss: 10160.8008\n",
      "Epoch 1254/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7612.2725 - val_loss: 10172.7051\n",
      "Epoch 1255/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7599.4780 - val_loss: 10157.1846\n",
      "Epoch 1256/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7595.4541 - val_loss: 10157.3965\n",
      "Epoch 1257/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7589.8467 - val_loss: 10144.0498\n",
      "Epoch 1258/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 7588.6865 - val_loss: 10153.4434\n",
      "Epoch 1259/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7607.0469 - val_loss: 10085.9688\n",
      "Epoch 1260/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7591.9712 - val_loss: 10139.4277\n",
      "Epoch 1261/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7588.1797 - val_loss: 10154.4160\n",
      "Epoch 1262/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7571.4321 - val_loss: 10098.8740\n",
      "Epoch 1263/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7568.6602 - val_loss: 10091.4219\n",
      "Epoch 1264/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7570.1069 - val_loss: 10080.7832\n",
      "Epoch 1265/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7561.6748 - val_loss: 10097.9766\n",
      "Epoch 1266/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7563.4985 - val_loss: 10073.4199\n",
      "Epoch 1267/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7566.0938 - val_loss: 10085.4043\n",
      "Epoch 1268/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7539.2500 - val_loss: 10054.0615\n",
      "Epoch 1269/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7537.6885 - val_loss: 10063.3652\n",
      "Epoch 1270/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7529.7642 - val_loss: 10040.7285\n",
      "Epoch 1271/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7536.5923 - val_loss: 10065.0693\n",
      "Epoch 1272/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7519.1616 - val_loss: 10019.4521\n",
      "Epoch 1273/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7524.6157 - val_loss: 10030.3994\n",
      "Epoch 1274/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7509.4038 - val_loss: 10051.4502\n",
      "Epoch 1275/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7519.6836 - val_loss: 10047.0527\n",
      "Epoch 1276/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7506.2783 - val_loss: 9984.8262\n",
      "Epoch 1277/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7513.7861 - val_loss: 9997.6543\n",
      "Epoch 1278/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7501.4736 - val_loss: 10047.2324\n",
      "Epoch 1279/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7496.7344 - val_loss: 10006.5127\n",
      "Epoch 1280/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7481.1436 - val_loss: 9977.0898\n",
      "Epoch 1281/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7487.3374 - val_loss: 9979.6963\n",
      "Epoch 1282/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7469.7446 - val_loss: 10003.7432\n",
      "Epoch 1283/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7480.2876 - val_loss: 9995.8037\n",
      "Epoch 1284/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7470.6963 - val_loss: 9929.7842\n",
      "Epoch 1285/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7470.2305 - val_loss: 9925.1152\n",
      "Epoch 1286/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7456.2251 - val_loss: 9975.6035\n",
      "Epoch 1287/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7466.3018 - val_loss: 9969.3965\n",
      "Epoch 1288/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7452.0342 - val_loss: 9919.6270\n",
      "Epoch 1289/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7459.0664 - val_loss: 9941.1855\n",
      "Epoch 1290/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7441.9678 - val_loss: 9931.4316\n",
      "Epoch 1291/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7436.1016 - val_loss: 9925.8604\n",
      "Epoch 1292/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7429.9736 - val_loss: 9920.9150\n",
      "Epoch 1293/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7422.2744 - val_loss: 9924.7959\n",
      "Epoch 1294/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7415.9492 - val_loss: 9921.8730\n",
      "Epoch 1295/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7433.8164 - val_loss: 9928.7676\n",
      "Epoch 1296/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7411.8545 - val_loss: 9876.2598\n",
      "Epoch 1297/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7416.1860 - val_loss: 9920.4258\n",
      "Epoch 1298/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7406.3188 - val_loss: 9882.6943\n",
      "Epoch 1299/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7399.7593 - val_loss: 9853.3691\n",
      "Epoch 1300/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7391.3257 - val_loss: 9893.8652\n",
      "Epoch 1301/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7392.0000 - val_loss: 9896.6582\n",
      "Epoch 1302/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7382.3828 - val_loss: 9866.4766\n",
      "Epoch 1303/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7381.2549 - val_loss: 9876.6660\n",
      "Epoch 1304/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7374.9756 - val_loss: 9872.2012\n",
      "Epoch 1305/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7375.5469 - val_loss: 9843.8730\n",
      "Epoch 1306/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7377.8154 - val_loss: 9864.2246\n",
      "Epoch 1307/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7359.8569 - val_loss: 9866.4502\n",
      "Epoch 1308/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7361.6826 - val_loss: 9848.1123\n",
      "Epoch 1309/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7350.8306 - val_loss: 9877.8643\n",
      "Epoch 1310/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7358.0283 - val_loss: 9878.1523\n",
      "Epoch 1311/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7347.0986 - val_loss: 9855.9531\n",
      "Epoch 1312/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7338.2632 - val_loss: 9861.8936\n",
      "Epoch 1313/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7341.9531 - val_loss: 9856.4434\n",
      "Epoch 1314/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7340.8735 - val_loss: 9852.1309\n",
      "Epoch 1315/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7334.9580 - val_loss: 9865.4092\n",
      "Epoch 1316/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7329.9561 - val_loss: 9859.8652\n",
      "Epoch 1317/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7332.6313 - val_loss: 9826.3691\n",
      "Epoch 1318/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7326.5225 - val_loss: 9865.0576\n",
      "Epoch 1319/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7316.6143 - val_loss: 9845.9746\n",
      "Epoch 1320/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7323.3057 - val_loss: 9829.0361\n",
      "Epoch 1321/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7315.3369 - val_loss: 9848.8711\n",
      "Epoch 1322/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7306.6963 - val_loss: 9868.4277\n",
      "Epoch 1323/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7307.3213 - val_loss: 9822.7910\n",
      "Epoch 1324/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7310.5171 - val_loss: 9837.7578\n",
      "Epoch 1325/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7294.4639 - val_loss: 9882.7236\n",
      "Epoch 1326/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7300.8760 - val_loss: 9833.2744\n",
      "Epoch 1327/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7291.1719 - val_loss: 9830.9307\n",
      "Epoch 1328/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7292.2920 - val_loss: 9835.9512\n",
      "Epoch 1329/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7282.4702 - val_loss: 9871.0488\n",
      "Epoch 1330/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7277.8022 - val_loss: 9873.5596\n",
      "Epoch 1331/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7269.0679 - val_loss: 9866.7598\n",
      "Epoch 1332/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7270.3096 - val_loss: 9837.9092\n",
      "Epoch 1333/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 7270.8008 - val_loss: 9857.9590\n",
      "Epoch 1334/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7259.9814 - val_loss: 9857.6328\n",
      "Epoch 1335/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7256.2969 - val_loss: 9871.0938\n",
      "Epoch 1336/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7261.2837 - val_loss: 9848.8535\n",
      "Epoch 1337/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7258.1587 - val_loss: 9888.1807\n",
      "Epoch 1338/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7248.1680 - val_loss: 9869.5996\n",
      "Epoch 1339/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7241.4297 - val_loss: 9865.8457\n",
      "Epoch 1340/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7237.0820 - val_loss: 9860.4902\n",
      "Epoch 1341/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7238.7344 - val_loss: 9889.5957\n",
      "Epoch 1342/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7230.4321 - val_loss: 9867.7910\n",
      "Epoch 1343/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7238.4165 - val_loss: 9875.7207\n",
      "Epoch 1344/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7230.7236 - val_loss: 9865.5264\n",
      "Epoch 1345/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7220.6494 - val_loss: 9868.8887\n",
      "Epoch 1346/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7215.8359 - val_loss: 9864.7900\n",
      "Epoch 1347/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7212.9155 - val_loss: 9874.4746\n",
      "Epoch 1348/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7213.2471 - val_loss: 9866.4668\n",
      "Epoch 1349/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7211.1890 - val_loss: 9854.5332\n",
      "Epoch 1350/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7209.5674 - val_loss: 9837.4541\n",
      "Epoch 1351/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7195.2202 - val_loss: 9861.4893\n",
      "Epoch 1352/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7192.2305 - val_loss: 9876.9971\n",
      "Epoch 1353/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7188.3540 - val_loss: 9894.2109\n",
      "Epoch 1354/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7186.2695 - val_loss: 9879.6191\n",
      "Epoch 1355/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7179.4399 - val_loss: 9889.7891\n",
      "Epoch 1356/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7187.7251 - val_loss: 9868.0967\n",
      "Epoch 1357/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7194.6787 - val_loss: 9816.6484\n",
      "Epoch 1358/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7178.6694 - val_loss: 9854.7412\n",
      "Epoch 1359/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7174.4624 - val_loss: 9899.0459\n",
      "Epoch 1360/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7185.1416 - val_loss: 9845.6621\n",
      "Epoch 1361/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7163.2437 - val_loss: 9871.4473\n",
      "Epoch 1362/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7156.8408 - val_loss: 9894.3926\n",
      "Epoch 1363/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7155.2646 - val_loss: 9852.5371\n",
      "Epoch 1364/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7154.9414 - val_loss: 9851.5186\n",
      "Epoch 1365/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7147.9858 - val_loss: 9862.0068\n",
      "Epoch 1366/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7146.4404 - val_loss: 9890.6162\n",
      "Epoch 1367/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7144.7393 - val_loss: 9885.7656\n",
      "Epoch 1368/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7139.2451 - val_loss: 9860.0078\n",
      "Epoch 1369/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7132.1890 - val_loss: 9880.1602\n",
      "Epoch 1370/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7124.7720 - val_loss: 9888.3135\n",
      "Epoch 1371/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7121.8608 - val_loss: 9877.7627\n",
      "Epoch 1372/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7118.8843 - val_loss: 9883.3535\n",
      "Epoch 1373/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7118.6641 - val_loss: 9891.4404\n",
      "Epoch 1374/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7116.6289 - val_loss: 9885.9795\n",
      "Epoch 1375/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7109.9595 - val_loss: 9858.1416\n",
      "Epoch 1376/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7110.2905 - val_loss: 9873.9971\n",
      "Epoch 1377/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7098.9922 - val_loss: 9889.6035\n",
      "Epoch 1378/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7097.0352 - val_loss: 9894.4121\n",
      "Epoch 1379/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7093.2266 - val_loss: 9879.3564\n",
      "Epoch 1380/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7089.3828 - val_loss: 9860.7021\n",
      "Epoch 1381/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7086.3101 - val_loss: 9883.7129\n",
      "Epoch 1382/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7085.6201 - val_loss: 9898.2578\n",
      "Epoch 1383/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7080.4478 - val_loss: 9875.8848\n",
      "Epoch 1384/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7077.6475 - val_loss: 9919.7793\n",
      "Epoch 1385/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7075.1670 - val_loss: 9889.5479\n",
      "Epoch 1386/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7071.3096 - val_loss: 9897.9268\n",
      "Epoch 1387/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7066.3735 - val_loss: 9908.9521\n",
      "Epoch 1388/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7073.6045 - val_loss: 9892.7480\n",
      "Epoch 1389/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7061.2124 - val_loss: 9875.4014\n",
      "Epoch 1390/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7069.9375 - val_loss: 9855.8770\n",
      "Epoch 1391/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7060.3218 - val_loss: 9898.8926\n",
      "Epoch 1392/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7044.9985 - val_loss: 9850.7822\n",
      "Epoch 1393/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7050.1299 - val_loss: 9856.5742\n",
      "Epoch 1394/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7039.9751 - val_loss: 9850.3994\n",
      "Epoch 1395/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7038.8062 - val_loss: 9883.4668\n",
      "Epoch 1396/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7031.0674 - val_loss: 9869.4932\n",
      "Epoch 1397/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7030.0186 - val_loss: 9901.7715\n",
      "Epoch 1398/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7021.9424 - val_loss: 9855.4316\n",
      "Epoch 1399/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7023.9502 - val_loss: 9857.3877\n",
      "Epoch 1400/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7023.7021 - val_loss: 9880.2432\n",
      "Epoch 1401/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7010.9141 - val_loss: 9858.0879\n",
      "Epoch 1402/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7008.7134 - val_loss: 9863.4912\n",
      "Epoch 1403/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7013.3818 - val_loss: 9886.3896\n",
      "Epoch 1404/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7006.3960 - val_loss: 9852.2441\n",
      "Epoch 1405/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6999.1250 - val_loss: 9890.4697\n",
      "Epoch 1406/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6999.3936 - val_loss: 9864.4395\n",
      "Epoch 1407/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6989.4312 - val_loss: 9850.2295\n",
      "Epoch 1408/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 6982.9985 - val_loss: 9881.1074\n",
      "Epoch 1409/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6989.3657 - val_loss: 9886.9199\n",
      "Epoch 1410/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6977.8975 - val_loss: 9870.1328\n",
      "Epoch 1411/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6974.5015 - val_loss: 9874.3174\n",
      "Epoch 1412/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6972.3608 - val_loss: 9900.5137\n",
      "Epoch 1413/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6966.6001 - val_loss: 9882.0938\n",
      "Epoch 1414/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6969.9438 - val_loss: 9870.5303\n",
      "Epoch 1415/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6958.2632 - val_loss: 9877.1934\n",
      "Epoch 1416/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6955.1914 - val_loss: 9901.8945\n",
      "Epoch 1417/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6951.3994 - val_loss: 9893.6445\n",
      "Epoch 1418/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6945.1226 - val_loss: 9880.1436\n",
      "Epoch 1419/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6941.3569 - val_loss: 9883.8105\n",
      "Epoch 1420/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6940.7358 - val_loss: 9905.8896\n",
      "Epoch 1421/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6932.8623 - val_loss: 9885.0039\n",
      "Epoch 1422/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6940.0820 - val_loss: 9902.1162\n",
      "Epoch 1423/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6932.6045 - val_loss: 9860.6230\n",
      "Epoch 1424/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6951.7046 - val_loss: 9853.2783\n",
      "Epoch 1425/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6929.1968 - val_loss: 9883.6699\n",
      "Epoch 1426/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6913.5874 - val_loss: 9833.9277\n",
      "Epoch 1427/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6915.4717 - val_loss: 9855.2441\n",
      "Epoch 1428/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6912.6655 - val_loss: 9849.0908\n",
      "Epoch 1429/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6900.0454 - val_loss: 9842.3154\n",
      "Epoch 1430/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6906.5635 - val_loss: 9854.9053\n",
      "Epoch 1431/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6897.9868 - val_loss: 9836.9102\n",
      "Epoch 1432/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6893.6670 - val_loss: 9844.4277\n",
      "Epoch 1433/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6896.0635 - val_loss: 9843.6426\n",
      "Epoch 1434/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6902.7920 - val_loss: 9872.1240\n",
      "Epoch 1435/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6893.1240 - val_loss: 9827.2295\n",
      "Epoch 1436/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6885.5264 - val_loss: 9875.2090\n",
      "Epoch 1437/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6885.4321 - val_loss: 9838.1094\n",
      "Epoch 1438/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6876.4678 - val_loss: 9869.0195\n",
      "Epoch 1439/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6873.3594 - val_loss: 9855.3867\n",
      "Epoch 1440/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6864.7266 - val_loss: 9861.7207\n",
      "Epoch 1441/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6862.5024 - val_loss: 9865.4551\n",
      "Epoch 1442/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6866.8188 - val_loss: 9852.2549\n",
      "Epoch 1443/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6854.3945 - val_loss: 9875.1504\n",
      "Epoch 1444/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6855.6416 - val_loss: 9858.7100\n",
      "Epoch 1445/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6852.3267 - val_loss: 9850.4707\n",
      "Epoch 1446/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6849.8760 - val_loss: 9874.1943\n",
      "Epoch 1447/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6848.2344 - val_loss: 9867.8652\n",
      "Epoch 1448/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6841.6523 - val_loss: 9857.7588\n",
      "Epoch 1449/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6835.6260 - val_loss: 9872.6201\n",
      "Epoch 1450/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6833.2695 - val_loss: 9891.2344\n",
      "Epoch 1451/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6835.5156 - val_loss: 9893.6787\n",
      "Epoch 1452/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6841.7812 - val_loss: 9847.4502\n",
      "Epoch 1453/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6836.7549 - val_loss: 9891.3867\n",
      "Epoch 1454/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6833.1992 - val_loss: 9900.7881\n",
      "Epoch 1455/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6824.5742 - val_loss: 9854.0957\n",
      "Epoch 1456/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6834.1494 - val_loss: 9852.6641\n",
      "Epoch 1457/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6835.0781 - val_loss: 9893.0176\n",
      "Epoch 1458/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6828.6890 - val_loss: 9840.0596\n",
      "Epoch 1459/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6807.1729 - val_loss: 9871.7559\n",
      "Epoch 1460/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6817.0576 - val_loss: 9866.6367\n",
      "Epoch 1461/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6820.2905 - val_loss: 9887.4443\n",
      "Epoch 1462/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6805.7891 - val_loss: 9874.8926\n",
      "Epoch 1463/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6804.3555 - val_loss: 9864.7656\n",
      "Epoch 1464/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6799.0054 - val_loss: 9875.7939\n",
      "Epoch 1465/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6793.1250 - val_loss: 9895.7588\n",
      "Epoch 1466/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6796.2407 - val_loss: 9888.9336\n",
      "Epoch 1467/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6790.8916 - val_loss: 9887.7539\n",
      "Epoch 1468/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6783.7432 - val_loss: 9886.2920\n",
      "Epoch 1469/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6786.1357 - val_loss: 9890.0322\n",
      "Epoch 1470/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6776.5283 - val_loss: 9881.6846\n",
      "Epoch 1471/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6780.1865 - val_loss: 9901.1553\n",
      "Epoch 1472/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6775.2251 - val_loss: 9904.3096\n",
      "Epoch 1473/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6776.1143 - val_loss: 9902.8564\n",
      "Epoch 1474/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6775.1069 - val_loss: 9880.5234\n",
      "Epoch 1475/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6785.0874 - val_loss: 9933.6914\n",
      "Epoch 1476/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6770.9116 - val_loss: 9899.5225\n",
      "Epoch 1477/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6764.6719 - val_loss: 9928.2822\n",
      "Epoch 1478/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6769.6338 - val_loss: 9920.5879\n",
      "Epoch 1479/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6759.2783 - val_loss: 9902.6191\n",
      "Epoch 1480/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6754.4658 - val_loss: 9881.7031\n",
      "Epoch 1481/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6752.6187 - val_loss: 9897.1963\n",
      "Epoch 1482/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6761.6943 - val_loss: 9877.4434\n",
      "Epoch 1483/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 6760.2046 - val_loss: 9934.2695\n",
      "Epoch 1484/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6749.7197 - val_loss: 9892.0156\n",
      "Epoch 1485/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6744.7178 - val_loss: 9884.7842\n",
      "Epoch 1486/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6741.3525 - val_loss: 9902.4473\n",
      "Epoch 1487/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6731.9858 - val_loss: 9895.8311\n",
      "Epoch 1488/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6729.5820 - val_loss: 9906.7998\n",
      "Epoch 1489/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6730.0342 - val_loss: 9892.3408\n",
      "Epoch 1490/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6725.6460 - val_loss: 9915.2715\n",
      "Epoch 1491/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6744.8057 - val_loss: 9943.5469\n",
      "Epoch 1492/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6725.8516 - val_loss: 9872.0840\n",
      "Epoch 1493/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6733.2061 - val_loss: 9893.0205\n",
      "Epoch 1494/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6720.5537 - val_loss: 9932.6699\n",
      "Epoch 1495/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6711.4521 - val_loss: 9894.5801\n",
      "Epoch 1496/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6723.1069 - val_loss: 9908.7568\n",
      "Epoch 1497/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6705.3330 - val_loss: 9918.1475\n",
      "Epoch 1498/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6701.1890 - val_loss: 9905.7949\n",
      "Epoch 1499/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6706.9790 - val_loss: 9927.9658\n",
      "Epoch 1500/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6694.2827 - val_loss: 9884.1201\n",
      "Epoch 1501/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6714.1143 - val_loss: 9881.7959\n",
      "Epoch 1502/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6705.4351 - val_loss: 9910.7383\n",
      "Epoch 1503/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6689.2002 - val_loss: 9884.1963\n",
      "Epoch 1504/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6696.4326 - val_loss: 9916.6504\n",
      "Epoch 1505/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6691.5610 - val_loss: 9910.7090\n",
      "Epoch 1506/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6692.4751 - val_loss: 9879.5469\n",
      "Epoch 1507/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6676.8218 - val_loss: 9905.2402\n",
      "Epoch 1508/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6683.8643 - val_loss: 9877.7002\n",
      "Epoch 1509/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6685.6729 - val_loss: 9910.3936\n",
      "Epoch 1510/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6678.0781 - val_loss: 9888.4629\n",
      "Epoch 1511/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6667.4805 - val_loss: 9916.8232\n",
      "Epoch 1512/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6668.7407 - val_loss: 9892.1504\n",
      "Epoch 1513/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6662.7695 - val_loss: 9923.3848\n",
      "Epoch 1514/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6661.2852 - val_loss: 9904.2744\n",
      "Epoch 1515/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6662.1235 - val_loss: 9882.0693\n",
      "Epoch 1516/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6666.0166 - val_loss: 9918.8584\n",
      "Epoch 1517/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6654.6069 - val_loss: 9875.2588\n",
      "Epoch 1518/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6653.5210 - val_loss: 9873.4033\n",
      "Epoch 1519/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6652.5093 - val_loss: 9875.1475\n",
      "Epoch 1520/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6655.5889 - val_loss: 9916.5049\n",
      "Epoch 1521/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6648.9795 - val_loss: 9865.7637\n",
      "Epoch 1522/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6636.9165 - val_loss: 9896.8154\n",
      "Epoch 1523/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6633.3179 - val_loss: 9885.7656\n",
      "Epoch 1524/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6638.4326 - val_loss: 9898.1523\n",
      "Epoch 1525/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6625.4053 - val_loss: 9895.8623\n",
      "Epoch 1526/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6624.3789 - val_loss: 9904.1641\n",
      "Epoch 1527/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6622.9346 - val_loss: 9896.6592\n",
      "Epoch 1528/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6618.3037 - val_loss: 9890.1055\n",
      "Epoch 1529/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6620.2617 - val_loss: 9906.1074\n",
      "Epoch 1530/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6635.0522 - val_loss: 9925.3789\n",
      "Epoch 1531/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6623.1055 - val_loss: 9856.7715\n",
      "Epoch 1532/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6624.9468 - val_loss: 9859.8008\n",
      "Epoch 1533/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6616.1904 - val_loss: 9858.1660\n",
      "Epoch 1534/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6598.6064 - val_loss: 9883.5430\n",
      "Epoch 1535/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6606.6406 - val_loss: 9884.5137\n",
      "Epoch 1536/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6608.0142 - val_loss: 9843.1348\n",
      "Epoch 1537/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6605.2485 - val_loss: 9883.6807\n",
      "Epoch 1538/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6596.0967 - val_loss: 9844.7129\n",
      "Epoch 1539/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6590.1514 - val_loss: 9849.6152\n",
      "Epoch 1540/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6592.4180 - val_loss: 9845.9629\n",
      "Epoch 1541/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6591.8271 - val_loss: 9859.5605\n",
      "Epoch 1542/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6583.2139 - val_loss: 9855.9648\n",
      "Epoch 1543/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6580.5249 - val_loss: 9874.9043\n",
      "Epoch 1544/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6578.7046 - val_loss: 9866.7090\n",
      "Epoch 1545/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6581.2656 - val_loss: 9858.4473\n",
      "Epoch 1546/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6591.6748 - val_loss: 9897.6719\n",
      "Epoch 1547/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6570.5376 - val_loss: 9864.6221\n",
      "Epoch 1548/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6567.6616 - val_loss: 9864.8525\n",
      "Epoch 1549/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6561.8447 - val_loss: 9879.3896\n",
      "Epoch 1550/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6558.3037 - val_loss: 9868.1680\n",
      "Epoch 1551/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6564.2764 - val_loss: 9872.5654\n",
      "Epoch 1552/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6556.7695 - val_loss: 9866.3252\n",
      "Epoch 1553/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6553.5317 - val_loss: 9849.5957\n",
      "Epoch 1554/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6549.6240 - val_loss: 9872.1094\n",
      "Epoch 1555/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6555.6157 - val_loss: 9876.6357\n",
      "Epoch 1556/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6545.2227 - val_loss: 9849.1445\n",
      "Epoch 1557/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6546.5132 - val_loss: 9852.1777\n",
      "Epoch 1558/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 6557.5938 - val_loss: 9838.9648\n",
      "Epoch 1559/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6535.4634 - val_loss: 9874.0850\n",
      "Epoch 1560/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6534.8657 - val_loss: 9862.1973\n",
      "Epoch 1561/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6529.8105 - val_loss: 9857.0664\n",
      "Epoch 1562/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6528.5435 - val_loss: 9859.9980\n",
      "Epoch 1563/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6534.0205 - val_loss: 9843.7324\n",
      "Epoch 1564/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6526.8711 - val_loss: 9879.7734\n",
      "Epoch 1565/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6520.5742 - val_loss: 9844.1094\n",
      "Epoch 1566/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6523.2056 - val_loss: 9830.7021\n",
      "Epoch 1567/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6511.2295 - val_loss: 9866.3555\n",
      "Epoch 1568/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6518.6572 - val_loss: 9852.9043\n",
      "Epoch 1569/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6515.4858 - val_loss: 9820.8887\n",
      "Epoch 1570/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6504.6553 - val_loss: 9850.4648\n",
      "Epoch 1571/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6513.1416 - val_loss: 9867.7598\n",
      "Epoch 1572/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6499.5337 - val_loss: 9840.2402\n",
      "Epoch 1573/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6501.0356 - val_loss: 9852.3379\n",
      "Epoch 1574/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6496.5908 - val_loss: 9835.9912\n",
      "Epoch 1575/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6493.9873 - val_loss: 9853.4766\n",
      "Epoch 1576/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6508.0532 - val_loss: 9884.0293\n",
      "Epoch 1577/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6486.9727 - val_loss: 9801.9590\n",
      "Epoch 1578/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6503.6348 - val_loss: 9800.4482\n",
      "Epoch 1579/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6486.3423 - val_loss: 9835.2607\n",
      "Epoch 1580/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6485.6592 - val_loss: 9785.1465\n",
      "Epoch 1581/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6491.2759 - val_loss: 9789.7520\n",
      "Epoch 1582/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6476.4741 - val_loss: 9846.2510\n",
      "Epoch 1583/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6476.7603 - val_loss: 9816.9277\n",
      "Epoch 1584/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6471.2061 - val_loss: 9806.3906\n",
      "Epoch 1585/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6473.4126 - val_loss: 9788.2686\n",
      "Epoch 1586/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6471.9873 - val_loss: 9832.1377\n",
      "Epoch 1587/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6464.9561 - val_loss: 9784.6699\n",
      "Epoch 1588/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6466.2354 - val_loss: 9793.3848\n",
      "Epoch 1589/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6462.1787 - val_loss: 9796.8848\n",
      "Epoch 1590/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6471.1729 - val_loss: 9764.6631\n",
      "Epoch 1591/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6468.5083 - val_loss: 9823.7695\n",
      "Epoch 1592/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6456.8911 - val_loss: 9771.2227\n",
      "Epoch 1593/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6452.0332 - val_loss: 9788.5361\n",
      "Epoch 1594/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6447.6670 - val_loss: 9809.2031\n",
      "Epoch 1595/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6450.9604 - val_loss: 9761.0137\n",
      "Epoch 1596/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6444.9912 - val_loss: 9799.5518\n",
      "Epoch 1597/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6436.0044 - val_loss: 9759.5820\n",
      "Epoch 1598/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6447.4150 - val_loss: 9778.9375\n",
      "Epoch 1599/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6434.7319 - val_loss: 9788.1230\n",
      "Epoch 1600/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6432.3813 - val_loss: 9766.3301\n",
      "Epoch 1601/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6428.0522 - val_loss: 9784.8604\n",
      "Epoch 1602/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6422.5605 - val_loss: 9775.8857\n",
      "Epoch 1603/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6424.0215 - val_loss: 9786.9277\n",
      "Epoch 1604/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6420.0181 - val_loss: 9774.5371\n",
      "Epoch 1605/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6414.3320 - val_loss: 9768.9082\n",
      "Epoch 1606/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6416.4336 - val_loss: 9764.1963\n",
      "Epoch 1607/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6404.7471 - val_loss: 9771.5527\n",
      "Epoch 1608/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6407.7334 - val_loss: 9756.2422\n",
      "Epoch 1609/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6412.5850 - val_loss: 9771.6221\n",
      "Epoch 1610/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6398.1470 - val_loss: 9758.1406\n",
      "Epoch 1611/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6400.0088 - val_loss: 9761.0596\n",
      "Epoch 1612/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6394.4355 - val_loss: 9787.6934\n",
      "Epoch 1613/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6394.8550 - val_loss: 9774.9648\n",
      "Epoch 1614/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6387.5439 - val_loss: 9770.6758\n",
      "Epoch 1615/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6394.4937 - val_loss: 9780.0547\n",
      "Epoch 1616/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6407.3423 - val_loss: 9802.1133\n",
      "Epoch 1617/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6415.8311 - val_loss: 9721.7881\n",
      "Epoch 1618/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6382.8838 - val_loss: 9764.2637\n",
      "Epoch 1619/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6393.4468 - val_loss: 9773.6299\n",
      "Epoch 1620/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6381.6328 - val_loss: 9727.3887\n",
      "Epoch 1621/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6377.6484 - val_loss: 9745.9551\n",
      "Epoch 1622/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6374.0537 - val_loss: 9737.9473\n",
      "Epoch 1623/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6373.2217 - val_loss: 9725.6523\n",
      "Epoch 1624/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6366.1133 - val_loss: 9730.4346\n",
      "Epoch 1625/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6366.5234 - val_loss: 9749.9297\n",
      "Epoch 1626/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6362.9946 - val_loss: 9708.8887\n",
      "Epoch 1627/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6377.7656 - val_loss: 9763.0498\n",
      "Epoch 1628/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6365.6704 - val_loss: 9762.1436\n",
      "Epoch 1629/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6373.8428 - val_loss: 9736.0068\n",
      "Epoch 1630/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6351.7681 - val_loss: 9760.2969\n",
      "Epoch 1631/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6348.6035 - val_loss: 9758.6201\n",
      "Epoch 1632/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6351.4082 - val_loss: 9702.8857\n",
      "Epoch 1633/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 6351.2451 - val_loss: 9737.3076\n",
      "Epoch 1634/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6340.5933 - val_loss: 9739.6494\n",
      "Epoch 1635/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6342.7290 - val_loss: 9745.2852\n",
      "Epoch 1636/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6343.0718 - val_loss: 9731.7607\n",
      "Epoch 1637/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6338.2720 - val_loss: 9749.4893\n",
      "Epoch 1638/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6341.0874 - val_loss: 9749.4971\n",
      "Epoch 1639/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6345.3037 - val_loss: 9751.1406\n",
      "Epoch 1640/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6333.0640 - val_loss: 9735.8672\n",
      "Epoch 1641/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6340.0693 - val_loss: 9747.8662\n",
      "Epoch 1642/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6349.4780 - val_loss: 9737.9580\n",
      "Epoch 1643/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6337.5713 - val_loss: 9724.3154\n",
      "Epoch 1644/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6337.1143 - val_loss: 9755.3965\n",
      "Epoch 1645/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6331.3560 - val_loss: 9722.8594\n",
      "Epoch 1646/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6338.3486 - val_loss: 9740.8379\n",
      "Epoch 1647/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6333.2744 - val_loss: 9735.9434\n",
      "Epoch 1648/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6339.8115 - val_loss: 9696.7861\n",
      "Epoch 1649/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6327.1924 - val_loss: 9736.5332\n",
      "Epoch 1650/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6336.9722 - val_loss: 9713.7188\n",
      "Epoch 1651/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6335.1357 - val_loss: 9700.4590\n",
      "Epoch 1652/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6334.3525 - val_loss: 9707.0049\n",
      "Epoch 1653/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6321.4463 - val_loss: 9734.0459\n",
      "Epoch 1654/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6339.6294 - val_loss: 9716.3809\n",
      "Epoch 1655/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6327.2021 - val_loss: 9675.7676\n",
      "Epoch 1656/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6336.4707 - val_loss: 9707.1855\n",
      "Epoch 1657/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6333.5225 - val_loss: 9717.8145\n",
      "Epoch 1658/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6340.1777 - val_loss: 9692.2900\n",
      "Epoch 1659/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6316.1943 - val_loss: 9762.4941\n",
      "Epoch 1660/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6346.9990 - val_loss: 9747.3818\n",
      "Epoch 1661/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6324.8506 - val_loss: 9685.9346\n",
      "Epoch 1662/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6339.1846 - val_loss: 9704.7070\n",
      "Epoch 1663/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6327.5654 - val_loss: 9685.5098\n",
      "Epoch 1664/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6319.9443 - val_loss: 9702.6729\n",
      "Epoch 1665/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6319.4385 - val_loss: 9696.6270\n",
      "Epoch 1666/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6325.2114 - val_loss: 9694.5947\n",
      "Epoch 1667/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6323.2451 - val_loss: 9661.3623\n",
      "Epoch 1668/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6327.6274 - val_loss: 9721.5723\n",
      "Epoch 1669/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6343.1577 - val_loss: 9654.8457\n",
      "Epoch 1670/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6324.3472 - val_loss: 9713.5391\n",
      "Epoch 1671/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6334.5044 - val_loss: 9665.5752\n",
      "Epoch 1672/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6323.1182 - val_loss: 9649.4355\n",
      "Epoch 1673/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6308.8271 - val_loss: 9700.3691\n",
      "Epoch 1674/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6339.0850 - val_loss: 9646.6270\n",
      "Epoch 1675/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6314.1753 - val_loss: 9672.4912\n",
      "Epoch 1676/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6311.8682 - val_loss: 9670.1611\n",
      "Epoch 1677/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6315.9468 - val_loss: 9694.8730\n",
      "Epoch 1678/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6312.2954 - val_loss: 9685.9854\n",
      "Epoch 1679/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6312.8818 - val_loss: 9682.2246\n",
      "Epoch 1680/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6313.4922 - val_loss: 9691.3945\n",
      "Epoch 1681/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6307.5063 - val_loss: 9678.6074\n",
      "Epoch 1682/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6308.7388 - val_loss: 9685.4902\n",
      "Epoch 1683/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6308.4326 - val_loss: 9699.9756\n",
      "Epoch 1684/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6303.8101 - val_loss: 9696.2910\n",
      "Epoch 1685/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6313.5454 - val_loss: 9680.6445\n",
      "Epoch 1686/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6309.8398 - val_loss: 9693.6357\n",
      "Epoch 1687/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6305.5425 - val_loss: 9661.0693\n",
      "Epoch 1688/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6301.1924 - val_loss: 9693.9678\n",
      "Epoch 1689/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6309.1577 - val_loss: 9694.1172\n",
      "Epoch 1690/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6296.7139 - val_loss: 9642.4395\n",
      "Epoch 1691/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6317.2529 - val_loss: 9658.7559\n",
      "Epoch 1692/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6305.8867 - val_loss: 9676.8340\n",
      "Epoch 1693/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6299.2251 - val_loss: 9649.5996\n",
      "Epoch 1694/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6302.3896 - val_loss: 9644.5469\n",
      "Epoch 1695/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6296.1943 - val_loss: 9666.1523\n",
      "Epoch 1696/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6302.5146 - val_loss: 9683.5078\n",
      "Epoch 1697/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6293.8096 - val_loss: 9653.9219\n",
      "Epoch 1698/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6305.4702 - val_loss: 9662.9717\n",
      "Epoch 1699/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6308.3555 - val_loss: 9737.4160\n",
      "Epoch 1700/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6323.7651 - val_loss: 9689.9277\n",
      "Epoch 1701/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6289.8335 - val_loss: 9665.5156\n",
      "Epoch 1702/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6292.0649 - val_loss: 9670.8193\n",
      "Epoch 1703/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6290.0376 - val_loss: 9663.3867\n",
      "Epoch 1704/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6301.8818 - val_loss: 9636.0332\n",
      "Epoch 1705/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6296.0669 - val_loss: 9663.3857\n",
      "Epoch 1706/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6295.3115 - val_loss: 9657.4863\n",
      "Epoch 1707/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6299.1538 - val_loss: 9652.0879\n",
      "Epoch 1708/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 6287.5078 - val_loss: 9660.7500\n",
      "Epoch 1709/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6292.0283 - val_loss: 9660.5049\n",
      "Epoch 1710/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6292.4351 - val_loss: 9638.2217\n",
      "Epoch 1711/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6290.5757 - val_loss: 9640.8496\n",
      "Epoch 1712/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6285.4233 - val_loss: 9641.8350\n",
      "Epoch 1713/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6284.9209 - val_loss: 9663.9795\n",
      "Epoch 1714/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6289.2393 - val_loss: 9628.8926\n",
      "Epoch 1715/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6283.5039 - val_loss: 9668.7256\n",
      "Epoch 1716/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6283.2095 - val_loss: 9661.2715\n",
      "Epoch 1717/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6284.7773 - val_loss: 9634.9756\n",
      "Epoch 1718/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6285.8604 - val_loss: 9627.9746\n",
      "Epoch 1719/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6277.7539 - val_loss: 9637.5254\n",
      "Epoch 1720/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6280.4111 - val_loss: 9652.2725\n",
      "Epoch 1721/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6279.7246 - val_loss: 9646.4932\n",
      "Epoch 1722/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6277.5503 - val_loss: 9647.0293\n",
      "Epoch 1723/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6278.6616 - val_loss: 9636.0762\n",
      "Epoch 1724/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6278.9717 - val_loss: 9659.2607\n",
      "Epoch 1725/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6278.9819 - val_loss: 9640.7490\n",
      "Epoch 1726/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6270.3301 - val_loss: 9637.6426\n",
      "Epoch 1727/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6275.8418 - val_loss: 9652.3848\n",
      "Epoch 1728/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6274.0884 - val_loss: 9643.3418\n",
      "Epoch 1729/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6283.2964 - val_loss: 9610.6270\n",
      "Epoch 1730/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6274.6089 - val_loss: 9632.9785\n",
      "Epoch 1731/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6273.9268 - val_loss: 9611.6885\n",
      "Epoch 1732/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6273.0117 - val_loss: 9647.4971\n",
      "Epoch 1733/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6272.3545 - val_loss: 9649.7549\n",
      "Epoch 1734/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6266.9453 - val_loss: 9639.9541\n",
      "Epoch 1735/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6276.7798 - val_loss: 9613.8643\n",
      "Epoch 1736/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6265.0098 - val_loss: 9628.2432\n",
      "Epoch 1737/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6267.6445 - val_loss: 9641.3320\n",
      "Epoch 1738/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6264.1123 - val_loss: 9607.2168\n",
      "Epoch 1739/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6273.3447 - val_loss: 9618.2207\n",
      "Epoch 1740/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6258.2666 - val_loss: 9636.9443\n",
      "Epoch 1741/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6269.6968 - val_loss: 9628.3867\n",
      "Epoch 1742/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6263.0234 - val_loss: 9614.9990\n",
      "Epoch 1743/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6269.6104 - val_loss: 9597.4727\n",
      "Epoch 1744/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6260.6265 - val_loss: 9623.6074\n",
      "Epoch 1745/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6269.3896 - val_loss: 9637.0361\n",
      "Epoch 1746/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6262.1890 - val_loss: 9574.6816\n",
      "Epoch 1747/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6265.5498 - val_loss: 9611.6924\n",
      "Epoch 1748/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6262.1602 - val_loss: 9633.6699\n",
      "Epoch 1749/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6258.3022 - val_loss: 9617.7207\n",
      "Epoch 1750/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6260.4438 - val_loss: 9603.8994\n",
      "Epoch 1751/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6256.2993 - val_loss: 9630.4541\n",
      "Epoch 1752/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6255.5303 - val_loss: 9616.9648\n",
      "Epoch 1753/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6259.9199 - val_loss: 9616.4473\n",
      "Epoch 1754/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6258.0039 - val_loss: 9619.6475\n",
      "Epoch 1755/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6253.1006 - val_loss: 9607.2324\n",
      "Epoch 1756/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6255.7905 - val_loss: 9625.6074\n",
      "Epoch 1757/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6249.0522 - val_loss: 9597.5254\n",
      "Epoch 1758/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6267.0234 - val_loss: 9562.7754\n",
      "Epoch 1759/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6268.9717 - val_loss: 9615.6182\n",
      "Epoch 1760/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6242.4844 - val_loss: 9589.9893\n",
      "Epoch 1761/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6247.9180 - val_loss: 9601.2598\n",
      "Epoch 1762/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6248.9131 - val_loss: 9589.0137\n",
      "Epoch 1763/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6246.1396 - val_loss: 9576.9775\n",
      "Epoch 1764/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6250.6196 - val_loss: 9579.9365\n",
      "Epoch 1765/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6258.8672 - val_loss: 9620.4141\n",
      "Epoch 1766/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6253.9546 - val_loss: 9596.8564\n",
      "Epoch 1767/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6246.1729 - val_loss: 9591.6504\n",
      "Epoch 1768/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6258.7661 - val_loss: 9610.9023\n",
      "Epoch 1769/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6243.8135 - val_loss: 9573.1631\n",
      "Epoch 1770/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6251.8330 - val_loss: 9561.7520\n",
      "Epoch 1771/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6247.1782 - val_loss: 9618.4922\n",
      "Epoch 1772/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6252.5107 - val_loss: 9574.9648\n",
      "Epoch 1773/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6249.1431 - val_loss: 9571.0957\n",
      "Epoch 1774/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6241.3789 - val_loss: 9573.2168\n",
      "Epoch 1775/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6246.2139 - val_loss: 9598.7158\n",
      "Epoch 1776/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6242.3047 - val_loss: 9567.6934\n",
      "Epoch 1777/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6245.7515 - val_loss: 9575.9414\n",
      "Epoch 1778/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6236.2134 - val_loss: 9588.0947\n",
      "Epoch 1779/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6241.6265 - val_loss: 9609.7051\n",
      "Epoch 1780/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6228.3350 - val_loss: 9578.0537\n",
      "Epoch 1781/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6244.0254 - val_loss: 9566.9463\n",
      "Epoch 1782/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6242.4736 - val_loss: 9617.0771\n",
      "Epoch 1783/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 6237.5029 - val_loss: 9606.6562\n",
      "Epoch 1784/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6237.0220 - val_loss: 9571.0518\n",
      "Epoch 1785/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6231.5889 - val_loss: 9590.8955\n",
      "Epoch 1786/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6238.3018 - val_loss: 9595.5645\n",
      "Epoch 1787/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6232.1040 - val_loss: 9609.1885\n",
      "Epoch 1788/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6230.9961 - val_loss: 9583.3008\n",
      "Epoch 1789/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6228.2393 - val_loss: 9592.1631\n",
      "Epoch 1790/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6232.7842 - val_loss: 9564.7588\n",
      "Epoch 1791/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6230.3257 - val_loss: 9576.3379\n",
      "Epoch 1792/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6226.7212 - val_loss: 9570.5566\n",
      "Epoch 1793/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6230.9438 - val_loss: 9582.9629\n",
      "Epoch 1794/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6227.3657 - val_loss: 9541.6475\n",
      "Epoch 1795/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6233.6035 - val_loss: 9561.2861\n",
      "Epoch 1796/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6235.4756 - val_loss: 9610.0859\n",
      "Epoch 1797/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6223.5991 - val_loss: 9566.0371\n",
      "Epoch 1798/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6230.1729 - val_loss: 9583.4150\n",
      "Epoch 1799/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6225.9629 - val_loss: 9610.3379\n",
      "Epoch 1800/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6230.8574 - val_loss: 9565.1006\n",
      "Epoch 1801/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6227.9268 - val_loss: 9575.5527\n",
      "Epoch 1802/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6225.5156 - val_loss: 9593.4131\n",
      "Epoch 1803/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6221.8843 - val_loss: 9558.4062\n",
      "Epoch 1804/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6214.1562 - val_loss: 9583.6465\n",
      "Epoch 1805/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6224.2617 - val_loss: 9582.4258\n",
      "Epoch 1806/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6217.0679 - val_loss: 9538.4795\n",
      "Epoch 1807/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6234.7378 - val_loss: 9553.0566\n",
      "Epoch 1808/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6214.6304 - val_loss: 9573.4414\n",
      "Epoch 1809/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6215.6025 - val_loss: 9552.7949\n",
      "Epoch 1810/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6216.3096 - val_loss: 9576.5908\n",
      "Epoch 1811/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6220.0562 - val_loss: 9580.3467\n",
      "Epoch 1812/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6221.7217 - val_loss: 9556.6436\n",
      "Epoch 1813/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6208.8267 - val_loss: 9562.8955\n",
      "Epoch 1814/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6211.7876 - val_loss: 9555.0098\n",
      "Epoch 1815/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6223.6035 - val_loss: 9525.6855\n",
      "Epoch 1816/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6226.7041 - val_loss: 9586.3730\n",
      "Epoch 1817/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6227.5322 - val_loss: 9548.2119\n",
      "Epoch 1818/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6210.1768 - val_loss: 9569.6426\n",
      "Epoch 1819/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6225.9600 - val_loss: 9518.0059\n",
      "Epoch 1820/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6210.5205 - val_loss: 9561.7832\n",
      "Epoch 1821/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6207.4033 - val_loss: 9543.0068\n",
      "Epoch 1822/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6202.2358 - val_loss: 9554.7012\n",
      "Epoch 1823/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6202.4165 - val_loss: 9546.7129\n",
      "Epoch 1824/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6206.3345 - val_loss: 9528.0146\n",
      "Epoch 1825/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6206.3818 - val_loss: 9546.1973\n",
      "Epoch 1826/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6214.0117 - val_loss: 9577.3691\n",
      "Epoch 1827/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6203.2173 - val_loss: 9539.0635\n",
      "Epoch 1828/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6206.5615 - val_loss: 9556.0420\n",
      "Epoch 1829/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6196.4922 - val_loss: 9562.7031\n",
      "Epoch 1830/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6202.0859 - val_loss: 9533.9062\n",
      "Epoch 1831/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6203.1133 - val_loss: 9525.4492\n",
      "Epoch 1832/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6210.3862 - val_loss: 9562.5293\n",
      "Epoch 1833/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6203.0811 - val_loss: 9526.5049\n",
      "Epoch 1834/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6197.5635 - val_loss: 9558.2793\n",
      "Epoch 1835/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6202.2119 - val_loss: 9544.2285\n",
      "Epoch 1836/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6202.2607 - val_loss: 9545.9375\n",
      "Epoch 1837/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6211.1865 - val_loss: 9565.3184\n",
      "Epoch 1838/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6192.1885 - val_loss: 9514.4648\n",
      "Epoch 1839/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6216.2368 - val_loss: 9496.6924\n",
      "Epoch 1840/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6187.6470 - val_loss: 9522.8408\n",
      "Epoch 1841/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6195.0264 - val_loss: 9538.5762\n",
      "Epoch 1842/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6191.8203 - val_loss: 9518.6914\n",
      "Epoch 1843/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6196.6978 - val_loss: 9527.2676\n",
      "Epoch 1844/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6192.2422 - val_loss: 9562.6758\n",
      "Epoch 1845/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6194.4761 - val_loss: 9537.2227\n",
      "Epoch 1846/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6189.6992 - val_loss: 9512.8750\n",
      "Epoch 1847/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6184.4893 - val_loss: 9531.5537\n",
      "Epoch 1848/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6196.1689 - val_loss: 9552.2871\n",
      "Epoch 1849/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6192.3564 - val_loss: 9510.8623\n",
      "Epoch 1850/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6181.8662 - val_loss: 9529.9316\n",
      "Epoch 1851/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6185.8447 - val_loss: 9527.2451\n",
      "Epoch 1852/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6191.5688 - val_loss: 9526.6230\n",
      "Epoch 1853/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6184.9360 - val_loss: 9472.6768\n",
      "Epoch 1854/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6200.0986 - val_loss: 9479.8740\n",
      "Epoch 1855/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6215.2417 - val_loss: 9571.4287\n",
      "Epoch 1856/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6188.6978 - val_loss: 9525.6318\n",
      "Epoch 1857/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6180.2334 - val_loss: 9468.6924\n",
      "Epoch 1858/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 6187.2432 - val_loss: 9490.0947\n",
      "Epoch 1859/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6180.0239 - val_loss: 9534.6963\n",
      "Epoch 1860/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6183.6870 - val_loss: 9514.8379\n",
      "Epoch 1861/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6178.0957 - val_loss: 9506.5537\n",
      "Epoch 1862/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6172.6655 - val_loss: 9491.5557\n",
      "Epoch 1863/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6180.0225 - val_loss: 9493.9004\n",
      "Epoch 1864/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6173.8618 - val_loss: 9505.3008\n",
      "Epoch 1865/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6175.4609 - val_loss: 9488.0713\n",
      "Epoch 1866/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6175.7354 - val_loss: 9480.7393\n",
      "Epoch 1867/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6179.2197 - val_loss: 9505.5176\n",
      "Epoch 1868/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6179.8125 - val_loss: 9478.4863\n",
      "Epoch 1869/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6172.7031 - val_loss: 9475.0811\n",
      "Epoch 1870/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6178.7510 - val_loss: 9515.4336\n",
      "Epoch 1871/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6170.0132 - val_loss: 9480.6396\n",
      "Epoch 1872/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6177.7656 - val_loss: 9478.4863\n",
      "Epoch 1873/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6170.7295 - val_loss: 9501.0156\n",
      "Epoch 1874/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6170.4697 - val_loss: 9491.7168\n",
      "Epoch 1875/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6165.3350 - val_loss: 9472.4189\n",
      "Epoch 1876/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6183.7471 - val_loss: 9452.4199\n",
      "Epoch 1877/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6170.5430 - val_loss: 9483.0342\n",
      "Epoch 1878/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6162.9199 - val_loss: 9478.6094\n",
      "Epoch 1879/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6160.5264 - val_loss: 9452.3291\n",
      "Epoch 1880/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6169.1064 - val_loss: 9485.2568\n",
      "Epoch 1881/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6164.5684 - val_loss: 9507.2695\n",
      "Epoch 1882/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6163.3970 - val_loss: 9496.2529\n",
      "Epoch 1883/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6157.7080 - val_loss: 9498.8154\n",
      "Epoch 1884/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6195.2070 - val_loss: 9527.3262\n",
      "Epoch 1885/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6160.2148 - val_loss: 9476.1289\n",
      "Epoch 1886/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6164.7144 - val_loss: 9487.2207\n",
      "Epoch 1887/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6158.7656 - val_loss: 9520.2695\n",
      "Epoch 1888/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6160.8975 - val_loss: 9488.6465\n",
      "Epoch 1889/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6155.0991 - val_loss: 9478.5967\n",
      "Epoch 1890/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6159.0576 - val_loss: 9477.5117\n",
      "Epoch 1891/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6154.5688 - val_loss: 9493.6143\n",
      "Epoch 1892/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6159.0376 - val_loss: 9471.9043\n",
      "Epoch 1893/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6154.1069 - val_loss: 9491.4746\n",
      "Epoch 1894/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6152.2393 - val_loss: 9488.0225\n",
      "Epoch 1895/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6155.1890 - val_loss: 9486.9316\n",
      "Epoch 1896/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6153.9146 - val_loss: 9456.3838\n",
      "Epoch 1897/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6163.6787 - val_loss: 9454.8926\n",
      "Epoch 1898/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6151.2896 - val_loss: 9497.6855\n",
      "Epoch 1899/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6162.2163 - val_loss: 9468.0801\n",
      "Epoch 1900/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6148.3955 - val_loss: 9423.2861\n",
      "Epoch 1901/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6152.4795 - val_loss: 9440.7676\n",
      "Epoch 1902/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6143.2451 - val_loss: 9462.5703\n",
      "Epoch 1903/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6143.5859 - val_loss: 9482.1230\n",
      "Epoch 1904/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6148.7354 - val_loss: 9481.1260\n",
      "Epoch 1905/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6149.6445 - val_loss: 9458.1836\n",
      "Epoch 1906/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6146.1973 - val_loss: 9476.7676\n",
      "Epoch 1907/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6151.1870 - val_loss: 9483.1318\n",
      "Epoch 1908/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6146.0054 - val_loss: 9447.2852\n",
      "Epoch 1909/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6144.0518 - val_loss: 9460.7529\n",
      "Epoch 1910/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6142.4238 - val_loss: 9450.4893\n",
      "Epoch 1911/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6139.4062 - val_loss: 9441.9277\n",
      "Epoch 1912/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6140.6348 - val_loss: 9448.5527\n",
      "Epoch 1913/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6143.0986 - val_loss: 9460.4258\n",
      "Epoch 1914/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6134.0806 - val_loss: 9443.8848\n",
      "Epoch 1915/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6142.0352 - val_loss: 9470.4385\n",
      "Epoch 1916/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6139.8027 - val_loss: 9472.3027\n",
      "Epoch 1917/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6134.4907 - val_loss: 9463.2578\n",
      "Epoch 1918/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6134.7412 - val_loss: 9466.4355\n",
      "Epoch 1919/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6135.0596 - val_loss: 9452.5127\n",
      "Epoch 1920/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6131.0830 - val_loss: 9482.5967\n",
      "Epoch 1921/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6137.1870 - val_loss: 9456.3711\n",
      "Epoch 1922/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6141.2505 - val_loss: 9451.6826\n",
      "Epoch 1923/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6125.8350 - val_loss: 9461.0283\n",
      "Epoch 1924/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6142.5361 - val_loss: 9462.8535\n",
      "Epoch 1925/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6143.3174 - val_loss: 9409.3438\n",
      "Epoch 1926/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6142.2041 - val_loss: 9425.1074\n",
      "Epoch 1927/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6127.5303 - val_loss: 9427.9717\n",
      "Epoch 1928/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6135.1602 - val_loss: 9445.8984\n",
      "Epoch 1929/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6125.1582 - val_loss: 9426.1719\n",
      "Epoch 1930/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6124.0186 - val_loss: 9402.9854\n",
      "Epoch 1931/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6125.4834 - val_loss: 9413.7510\n",
      "Epoch 1932/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6123.2500 - val_loss: 9416.2129\n",
      "Epoch 1933/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 6125.0796 - val_loss: 9403.0166\n",
      "Epoch 1934/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6130.6372 - val_loss: 9426.1582\n",
      "Epoch 1935/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6133.8779 - val_loss: 9401.8564\n",
      "Epoch 1936/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6126.6182 - val_loss: 9432.5322\n",
      "Epoch 1937/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6134.3945 - val_loss: 9391.8066\n",
      "Epoch 1938/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6125.0620 - val_loss: 9428.8564\n",
      "Epoch 1939/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6118.9019 - val_loss: 9445.7148\n",
      "Epoch 1940/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6123.8979 - val_loss: 9432.5518\n",
      "Epoch 1941/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6119.1484 - val_loss: 9451.7471\n",
      "Epoch 1942/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6122.4390 - val_loss: 9424.6504\n",
      "Epoch 1943/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6121.6440 - val_loss: 9427.1670\n",
      "Epoch 1944/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6119.9326 - val_loss: 9429.6553\n",
      "Epoch 1945/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6117.7163 - val_loss: 9407.2578\n",
      "Epoch 1946/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6122.9736 - val_loss: 9433.4980\n",
      "Epoch 1947/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6115.8926 - val_loss: 9395.8242\n",
      "Epoch 1948/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6121.9365 - val_loss: 9460.4316\n",
      "Epoch 1949/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6118.3125 - val_loss: 9451.0303\n",
      "Epoch 1950/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6112.3857 - val_loss: 9440.7295\n",
      "Epoch 1951/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6113.9971 - val_loss: 9431.9199\n",
      "Epoch 1952/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6114.0283 - val_loss: 9426.8418\n",
      "Epoch 1953/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6116.8481 - val_loss: 9430.0859\n",
      "Epoch 1954/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6126.9932 - val_loss: 9403.8906\n",
      "Epoch 1955/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6117.4771 - val_loss: 9406.2803\n",
      "Epoch 1956/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6112.2588 - val_loss: 9449.5898\n",
      "Epoch 1957/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6116.0430 - val_loss: 9409.0771\n",
      "Epoch 1958/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6107.8501 - val_loss: 9425.0732\n",
      "Epoch 1959/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6129.5889 - val_loss: 9458.5703\n",
      "Epoch 1960/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6121.0239 - val_loss: 9404.7158\n",
      "Epoch 1961/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6126.2319 - val_loss: 9430.8252\n",
      "Epoch 1962/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6109.6641 - val_loss: 9417.0586\n",
      "Epoch 1963/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6102.3994 - val_loss: 9424.8477\n",
      "Epoch 1964/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6113.0376 - val_loss: 9429.6504\n",
      "Epoch 1965/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6106.9238 - val_loss: 9401.6572\n",
      "Epoch 1966/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6103.1221 - val_loss: 9409.8340\n",
      "Epoch 1967/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6107.0674 - val_loss: 9421.5918\n",
      "Epoch 1968/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6100.6514 - val_loss: 9416.7861\n",
      "Epoch 1969/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6111.6118 - val_loss: 9398.3232\n",
      "Epoch 1970/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6103.4307 - val_loss: 9417.6006\n",
      "Epoch 1971/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6103.0244 - val_loss: 9371.8721\n",
      "Epoch 1972/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6105.6729 - val_loss: 9388.2363\n",
      "Epoch 1973/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6100.4189 - val_loss: 9378.9316\n",
      "Epoch 1974/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6105.7085 - val_loss: 9367.6377\n",
      "Epoch 1975/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6100.6460 - val_loss: 9382.1709\n",
      "Epoch 1976/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6103.3062 - val_loss: 9376.7070\n",
      "Epoch 1977/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6105.7891 - val_loss: 9365.8818\n",
      "Epoch 1978/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6100.3906 - val_loss: 9364.4834\n",
      "Epoch 1979/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6102.7725 - val_loss: 9358.0293\n",
      "Epoch 1980/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6101.2158 - val_loss: 9392.6113\n",
      "Epoch 1981/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6102.5889 - val_loss: 9369.3848\n",
      "Epoch 1982/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6096.6538 - val_loss: 9360.0996\n",
      "Epoch 1983/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6093.6509 - val_loss: 9369.9141\n",
      "Epoch 1984/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6095.2256 - val_loss: 9356.2598\n",
      "Epoch 1985/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6108.1924 - val_loss: 9344.1895\n",
      "Epoch 1986/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6095.3408 - val_loss: 9380.8154\n",
      "Epoch 1987/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6099.1807 - val_loss: 9369.2949\n",
      "Epoch 1988/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6092.4092 - val_loss: 9362.8896\n",
      "Epoch 1989/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6093.0752 - val_loss: 9375.7988\n",
      "Epoch 1990/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6090.6084 - val_loss: 9361.7578\n",
      "Epoch 1991/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6092.7256 - val_loss: 9353.4316\n",
      "Epoch 1992/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6090.1890 - val_loss: 9365.7441\n",
      "Epoch 1993/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6088.9556 - val_loss: 9346.3301\n",
      "Epoch 1994/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6087.1357 - val_loss: 9349.1250\n",
      "Epoch 1995/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6087.8804 - val_loss: 9361.9922\n",
      "Epoch 1996/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6088.9556 - val_loss: 9364.5020\n",
      "Epoch 1997/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6094.1729 - val_loss: 9350.7988\n",
      "Epoch 1998/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6087.5767 - val_loss: 9366.9648\n",
      "Epoch 1999/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6092.7236 - val_loss: 9375.8018\n",
      "Epoch 2000/2000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6086.3506 - val_loss: 9339.0889\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train, batch_size=4, validation_data=(X_test,y_test), epochs=2000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('history: the CNN model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8975763317020801"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9339.08828125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131801614.57579955"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.070372067888231"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [100]\n",
    "y_pred = [98]\n",
    "mean_absolute_percentage_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1 = ct.transform([[66242, 182987, 119317,'Mumbai']])\n",
    "x1 = scaler.fit_transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = model.predict(x1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97389.35\n"
     ]
    }
   ],
   "source": [
    "print(y1[0][0])  #list value  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('w123.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(4, input_dim=6, activation='relu'))\n",
    "model2.add(Dense(10, activation='relu'))\n",
    "model2.add(Dense(5, activation='relu'))\n",
    "model2.add(Dense(1,activation='linear'))\n",
    "model2.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('w123.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/quantbruce/real-estate-price-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/swathiachath/kc-housesales-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
